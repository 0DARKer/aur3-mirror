diff -r -u vmnet-only/compat_netdevice.h vmnet-only/compat_netdevice.h
--- vmnet-only/compat_netdevice.h	2011-09-23 23:05:45.000000000 -0300
+++ vmnet-only/compat_netdevice.h	2012-02-15 13:40:03.000000000 -0300
@@ -47,6 +47,21 @@
 #   define net_device device
 #endif
 
+/* it looks like these have been removed from the kernel 3.1
+ * probably because the "transition" is considered complete.
+ * so to keep this source compatible we just redefine them like they were
+ * previously
+ */
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 41, 0) && LINUX_VERSION_CODE < KERNEL_VERSION(3, 0, 0)) || LINUX_VERSION_CODE >= KERNEL_VERSION(3, 1, 0)
+#define HAVE_ALLOC_NETDEV		/* feature macro: alloc_xxxdev
+					   functions are available. */
+#define HAVE_FREE_NETDEV		/* free_netdev() */
+#define HAVE_NETDEV_PRIV		/* netdev_priv() */
+#define HAVE_NETIF_QUEUE
+#define HAVE_NET_DEVICE_OPS
+#endif
+ 
+
 
 /*
  * SET_MODULE_OWNER appeared sometime during 2.3.x. It was setting
diff -r -u vmnet-only/driver.c vmnet-only/driver.c
--- vmnet-only/driver.c	2011-09-23 23:05:45.000000000 -0300
+++ vmnet-only/driver.c	2012-02-15 13:25:46.000000000 -0300
@@ -28,7 +28,6 @@
 #include <linux/poll.h>
 
 #include <linux/smp.h>
-#include <linux/smp_lock.h>
 
 #include <linux/netdevice.h>
 #include <linux/etherdevice.h>
@@ -105,7 +104,7 @@
  * not have vnetStructureMutex already acquired,
  * it is most certainly a bug.
  */
-static rwlock_t vnetPeerLock = RW_LOCK_UNLOCKED;
+static DEFINE_RWLOCK(vnetPeerLock);
 
 /*
  * All concurrent changes to the network structure are
@@ -115,6 +114,7 @@
  * vnetStructureMutex and vnetPeerLock for write.
  */
 compat_define_mutex(vnetStructureMutex);
+compat_define_mutex(vnetMutex);
 
 #if defined(VM_X86_64) && !defined(HAVE_COMPAT_IOCTL)
 /*
@@ -264,11 +264,11 @@
 			    struct file * filp)  // IN:
 {
    int ret = -ENOTTY;
-   lock_kernel();
+   compat_mutex_lock(&vnetMutex);
    if (filp && filp->f_op && filp->f_op->ioctl == VNetFileOpIoctl) {
       ret = VNetFileOpIoctl(filp->f_dentry->d_inode, filp, iocmd, ioarg);
    }
-   unlock_kernel();
+   compat_mutex_unlock(&vnetMutex);
    return ret;
 }
 
@@ -1134,9 +1134,9 @@
    if (filp && filp->f_dentry) {
       inode = filp->f_dentry->d_inode;
    }
-   lock_kernel();
+   compat_mutex_lock(&vnetMutex);
    err = VNetFileOpIoctl(inode, filp, iocmd, ioarg);
-   unlock_kernel();
+   compat_mutex_unlock(&vnetMutex);
    return err;
 }
 #endif
diff -r -u vmnet-only/filter.c vmnet-only/filter.c
--- vmnet-only/filter.c	2011-09-23 23:05:45.000000000 -0300
+++ vmnet-only/filter.c	2012-02-15 13:37:33.000000000 -0300
@@ -40,6 +40,9 @@
 #include "vnetFilterInt.h"
 #include "vnetInt.h"
 #include "vmnetInt.h"
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 2, 0)
+#include <linux/export.h>
+#endif
 
 // VNet_FilterLogPacket.action for dropped packets
 #define VNET_FILTER_ACTION_DRP         (1)
@@ -85,7 +88,7 @@
  * callbacks can be concurrently executing on multiple threads on multiple
  * CPUs, so we should revisit locking for allowing for that in the future.
  */
-spinlock_t activeRuleLock = SPIN_LOCK_UNLOCKED;
+DEFINE_SPINLOCK(activeRuleLock);
 
 /*
  * Logging.
diff -r -u vmnet-only/hub.c vmnet-only/hub.c
--- vmnet-only/hub.c	2011-09-23 23:05:45.000000000 -0300
+++ vmnet-only/hub.c	2012-02-15 13:25:46.000000000 -0300
@@ -81,7 +81,7 @@
  * so we use __attribute__((unused)) to quiet the compiler.
  */
 
-static spinlock_t vnetHubLock __attribute__((unused)) = SPIN_LOCK_UNLOCKED;
+static DEFINE_SPINLOCK(vnetHubLock);
 
 
 /*
diff -r -u vmnet-only/netif.c vmnet-only/netif.c
--- vmnet-only/netif.c	2011-09-23 23:05:45.000000000 -0300
+++ vmnet-only/netif.c	2012-02-15 13:43:43.000000000 -0300
@@ -62,7 +62,9 @@
 static int  VNetNetifStartXmit(struct sk_buff *skb, struct net_device *dev);
 static struct net_device_stats *VNetNetifGetStats(struct net_device *dev);
 static int  VNetNetifSetMAC(struct net_device *dev, void *addr);
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 42, 0) && LINUX_VERSION_CODE < KERNEL_VERSION(3, 0, 0)) || LINUX_VERSION_CODE >= KERNEL_VERSION(3, 2, 0)
 static void VNetNetifSetMulticast(struct net_device *dev);
+#endif
 #if 0
 static void VNetNetifTxTimeout(struct net_device *dev);
 #endif
@@ -131,7 +133,9 @@
       .ndo_stop = VNetNetifClose,
       .ndo_get_stats = VNetNetifGetStats,
       .ndo_set_mac_address = VNetNetifSetMAC,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(3, 2, 0)
       .ndo_set_multicast_list = VNetNetifSetMulticast,
+#endif
       /*
        * We cannot stuck... If someone will report problems under
        * low memory conditions or some such, we should enable it.
@@ -620,11 +624,12 @@
  *
  *----------------------------------------------------------------------
  */
-
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 42, 0) && LINUX_VERSION_CODE < KERNEL_VERSION(3, 0, 0)) || LINUX_VERSION_CODE >= KERNEL_VERSION(3, 2, 0)
 void
 VNetNetifSetMulticast(struct net_device *dev) // IN: unused
 {
 }
+#endif
 
 
 /*
diff -r -u vmnet-only/userif.c vmnet-only/userif.c
--- vmnet-only/userif.c	2011-09-23 23:05:45.000000000 -0300
+++ vmnet-only/userif.c	2012-02-15 13:32:33.000000000 -0300
@@ -572,10 +572,18 @@
 	 unsigned int tmpCsum;
 	 const void *vaddr;
 
-	 vaddr = kmap(frag->page);
-	 tmpCsum = csum_and_copy_to_user(vaddr + frag->page_offset,
-					 curr, frag->size, 0, &err);
-	 kunmap(frag->page);
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 42, 0) && LINUX_VERSION_CODE < KERNEL_VERSION(3, 0, 0)) || LINUX_VERSION_CODE >= KERNEL_VERSION(3, 2, 0)
+vaddr = kmap(skb_frag_page(frag));
+#else
+vaddr = kmap(frag->page);
+#endif
+tmpCsum = csum_and_copy_to_user(vaddr + frag->page_offset,
+curr, frag->size, 0, &err);
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2, 42, 0) && LINUX_VERSION_CODE < KERNEL_VERSION(3, 0, 0)) || LINUX_VERSION_CODE >= KERNEL_VERSION(3, 2, 0)
+kunmap(skb_frag_page(frag));
+#else
+kunmap(frag->page);
+#endif
 	 if (err) {
 	    return err;
 	 }
