# Maintainer: Tianjiao Yin <ytj000@gmail.com>
# Contributor: Mantas Vidutis <mantas.a.vidutis-at-gmail.com>
pkgname=hadoop
pkgver=1.0.3
pkgrel=4
pkgdesc="Hadoop - MapReduce implementation and distributed filesystem"
arch=('i686' 'x86_64')
url="http://hadoop.apache.org"
license=('apache')
depends=('java-environment' 'openssh')
install=hadoop.install
source=(
"http://www.eng.lsu.edu/mirrors/apache/hadoop/common/hadoop-1.0.3/hadoop-1.0.3.tar.gz"
"hadoop.profile"
"conf.diff"
"hadoop-all"
"src_fix.patch"
)
backup=(
etc/profile.d/hadoop.sh
etc/hadoop/capacity-scheduler.xml
etc/hadoop/configuration.xsl
etc/hadoop/core-site.xml
etc/hadoop/fair-scheduler.xml
etc/hadoop/hadoop-env.sh
etc/hadoop/hadoop-metrics2.properties
etc/hadoop/hadoop-policy.xml
etc/hadoop/hdfs-site.xml
etc/hadoop/log4j.properties
etc/hadoop/mapred-queue-acls.xml
etc/hadoop/mapred-site.xml
etc/hadoop/masters
etc/hadoop/slaves
etc/hadoop/ssl-client.xml.example
etc/hadoop/ssl-server.xml.example
etc/hadoop/taskcontroller.cfg
)

_usr_lib=$pkgdir/usr/lib/
_hadoop_real_home=$_usr_lib/$pkgname-$pkgver
_hadoop_link_home=$_usr_lib/$pkgname

if [ "$CARCH" = "i686" ]; then
    options=(!strip)
fi

compile() {
  cd $srcdir/$pkgname-$pkgver
  msg "Cleaning..."
  ant clean || return 1

  msg "Patching..."
  sed -i "s/${_devver}/${pkgver}/" build.xml
  sed -i "s|<ivysettings>|<ivysettings>\n<caches defaultCacheDir=\"${srcdir}/ivy_cache\"/>|" ivy/ivysettings.xml

  msg "Building..."
  ant -Dcompile.native=true bin-package || return 1
}

package() {
  mkdir -p $_usr_lib
  cp -r $srcdir/$pkgname-$pkgver $_usr_lib

  install -Dm755 ${srcdir}/hadoop-all ${pkgdir}/etc/rc.d/hadoop-all
  install -Dm755 ${srcdir}/hadoop.profile ${pkgdir}/etc/profile.d/hadoop.sh

  # we do not use soft link because we need put configures in backup array,
  # in order to preserve the conf when upgrade package.
  cp $_hadoop_real_home/conf $pkgdir/etc/hadoop -r
  mv $_hadoop_real_home/conf $_hadoop_real_home/orig_conf

  cd $pkgdir/etc/hadoop
  patch -p 1 < $srcdir/conf.diff

  mkdir -p $pkgdir/usr/bin
  echo -e '#!/bin/sh\n\n/usr/lib/hadoop/bin/hadoop "$@"' > $pkgdir/usr/bin/hadoop
  chmod 755 $pkgdir/usr/bin/hadoop

  cd $_usr_lib
  ln -s $pkgname-$pkgver $pkgname

  cd $_hadoop_real_home
  patch -p 0 < $srcdir/src_fix.patch

  ## Disable IPv6 (comment out to disable IPv6 support):
  # sed -i 's|_OPTS="-D|_OPTS="-Djava.net.preferIPv4Stack=true -D|' hadoop-env.sh

  ## fix native 
  # if [ "$CARCH" = "i686" ]; then
  #   rm -rf lib/native/Linux-amd64-64
  #   cd lib/native/Linux-i386-32
  #   sed -i "s|dependency_libs='|dependency_libs='-L/opt/java/jre/lib/i386/server |" libhadoop.la
  # fi

  # if [ "$CARCH" = "x86_64" ]; then
  #   rm -rf lib/native/Linux-i386-32
  #   cd lib/native/Linux-amd64-64
  #   sed -i "s|dependency_libs='|dependency_libs='-L/opt/java/jre/lib/amd64/server |" libhadoop.la
  # fi

  ## Create some links, so Hadoop's KFS jar could access KFS libraries properly
  ## (it is still fine if KFS is not installed)

  # msg "Creating KFS links..."

  # for lib in libkfsClient libkfsCommon libkfsEmulator libkfsIO libkfsMeta; do
  #   for ext in a so; do
  #     ln -s /usr/lib/${lib}.${ext}
  #   done
  # done

  # ln -s /usr/lib/libkfs_access.so
}
md5sums=('f42d05e5c7bb43f85119546b80296435'
         '1e853002b2c9c024af17f3011ad26404'
         '2766a95c1f77037f3f768a59d5c44044'
         '4c9d65349ee75d5b324fee8f8fadf88e'
         '95e046cc2414b9bf83f596dd941742f3')
