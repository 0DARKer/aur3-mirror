#Maintainer: Manuel Hoffmann <manuel@manuel-hoffmann.info>
# Contributor: Markus Holtermann <aur@markusholtermann.eu>
# Contributor: Mantas Vidutis <mantas.a.vidutis-at-gmail.com>
# Contributor: Tianjiao Yin <ytj000@gmail.com>
#
# Check this file for alternative mirrors!
pkgname=hadoop
pkgver=1.1.2
pkgrel=2
pkgdesc="Hadoop - MapReduce implementation and distributed filesystem"
arch=('i686' 'x86_64')
url="http://hadoop.apache.org"
license=('apache')
depends=('java-environment' 'openssh' 'apache-ant')
install=hadoop.install
source=(
#"http://www.eng.lsu.edu/mirrors/apache/hadoop/common/hadoop-$pkgver/hadoop-$pkgver.tar.gz"
# "http://mirror3.layerjet.com/apache/hadoop/common/hadoop-$pkgver/hadoop-$pkgver.tar.gz"
# "http://mirror.lwnetwork.org.uk/APACHE/hadoop/common/hadoop-$pkgver/hadoop-$pkgver.tar.gz"
 "http://apache.openmirror.de/hadoop/common/hadoop-$pkgver/hadoop-$pkgver.tar.gz"
# "http://mirror.serversupportforum.de/apache/hadoop/common/hadoop-$pkgver/hadoop-$pkgver.tar.gz"
# "http://mirror.arcor-online.net/www.apache.org/hadoop/common/hadoop-$pkgver/hadoop-$pkgver.tar.gz"
# "http://ftp-stud.hs-esslingen.de/pub/Mirrors/ftp.apache.org/dist/hadoop/common/hadoop-$pkgver/hadoop-$pkgver.tar.gz"
# "http://apache.imsam.info/hadoop/common/hadoop-$pkgver/hadoop-$pkgver.tar.gz"
# "http://apache.lehtivihrea.org/hadoop/common/hadoop-$pkgver/hadoop-$pkgver.tar.gz"
# "http://mirror.synyx.de/apache/hadoop/common/hadoop-$pkgver/hadoop-$pkgver.tar.gz"
# "http://artfiles.org/apache.org/hadoop/common/hadoop-$pkgver/hadoop-$pkgver.tar.gz"
# "http://apache.mirror.clusters.cc/hadoop/common/hadoop-$pkgver/hadoop-$pkgver.tar.gz"
# "http://apache.mirror.digionline.de/hadoop/common/hadoop-$pkgver/hadoop-$pkgver.tar.gz"
# "http://apache.lauf-forum.at/hadoop/common/hadoop-$pkgver/hadoop-$pkgver.tar.gz"
# "http://ftp.halifax.rwth-aachen.de/apache/hadoop/common/hadoop-$pkgver/hadoop-$pkgver.tar.gz"
# "http://mirror.netcologne.de/apache.org/hadoop/common/hadoop-$pkgver/hadoop-$pkgver.tar.gz"
# "http://mirror.softaculous.com/apache/hadoop/common/hadoop-$pkgver/hadoop-$pkgver.tar.gz"
# "http://mirror.derwebwolf.net/apache/hadoop/common/hadoop-$pkgver/hadoop-$pkgver.tar.gz"
# "http://apache.mirror.iphh.net/hadoop/common/hadoop-$pkgver/hadoop-$pkgver.tar.gz"
"hadoop.profile"
"conf.diff"
"src_fix.patch"
"hadoop-conf"
"hadoop.sh"
"hadoop-namenode.service"
"hadoop-datanode.service"
"hadoop-secondarynamenode.service"
"hadoop-jobtracker.service"
"hadoop-tasktracker.service"
)
backup=(
etc/conf.d/hadoop
etc/profile.d/hadoop.sh
etc/hadoop/capacity-scheduler.xml
etc/hadoop/configuration.xsl
etc/hadoop/core-site.xml
etc/hadoop/fair-scheduler.xml
etc/hadoop/hadoop-env.sh
etc/hadoop/hadoop-metrics2.properties
etc/hadoop/hadoop-policy.xml
etc/hadoop/hdfs-site.xml
etc/hadoop/log4j.properties
etc/hadoop/mapred-queue-acls.xml
etc/hadoop/mapred-site.xml
etc/hadoop/masters
etc/hadoop/slaves
etc/hadoop/ssl-client.xml.example
etc/hadoop/ssl-server.xml.example
etc/hadoop/taskcontroller.cfg
)

if [ "$CARCH" = "i686" ]; then
    options=(!strip)
fi

compile() {
  cd $srcdir/$pkgname-$pkgver
  msg "Cleaning..."
  ant clean || return 1

  msg "Patching..."
  sed -i "s/${_devver}/${pkgver}/" build.xml
  sed -i "s|<ivysettings>|<ivysettings>\n<caches defaultCacheDir=\"${srcdir}/ivy_cache\"/>|" ivy/ivysettings.xml

  msg "Building..."
  ant -Dcompile.native=true bin-package || return 1
}

package() {
  _usr_lib=$pkgdir/usr/lib/
  _hadoop_real_home=$_usr_lib/$pkgname-$pkgver
  _hadoop_link_home=$_usr_lib/$pkgname

  mkdir -p $_usr_lib $pkgdir/usr/lib/systemd/system
  cp -r $srcdir/$pkgname-$pkgver $_usr_lib

  #
  install -Dm755 ${srcdir}/hadoop-conf ${pkgdir}/etc/conf.d/hadoop
  install -Dm755 ${srcdir}/hadoop.profile ${pkgdir}/etc/profile.d/hadoop.sh
  install -Dm644 ${srcdir}/hadoop-*.service ${pkgdir}/usr/lib/systemd/system/


  # we do not use soft link because we need put configures in backup array,
  # in order to preserve the conf when upgrade package.
  cp $_hadoop_real_home/conf $pkgdir/etc/hadoop -r
  mv $_hadoop_real_home/conf $_hadoop_real_home/orig_conf

  cd $pkgdir/etc/hadoop
  patch -p 1 < $srcdir/conf.diff

  # todo: i need an own file :)
  mkdir -p $pkgdir/usr/bin
  echo -e '#!/bin/sh\n\nfor f in /etc/profile.d/*.sh\ndo\n. $f\ndone\n/usr/lib/hadoop/bin/hadoop "$@"' > $pkgdir/usr/bin/hadoop
  chmod 755 $pkgdir/usr/bin/hadoop

  cd $_usr_lib
  ln -s $pkgname-$pkgver $pkgname

  cd $_hadoop_real_home
  patch -p 0 < $srcdir/src_fix.patch

  ## Disable IPv6 (comment out to disable IPv6 support):
  # sed -i 's|_OPTS="-D|_OPTS="-Djava.net.preferIPv4Stack=true -D|' hadoop-env.sh

  ## fix native 
  # if [ "$CARCH" = "i686" ]; then
  #   rm -rf lib/native/Linux-amd64-64
  #   cd lib/native/Linux-i386-32
  #   sed -i "s|dependency_libs='|dependency_libs='-L/opt/java/jre/lib/i386/server |" libhadoop.la
  # fi

  # if [ "$CARCH" = "x86_64" ]; then
  #   rm -rf lib/native/Linux-i386-32
  #   cd lib/native/Linux-amd64-64
  #   sed -i "s|dependency_libs='|dependency_libs='-L/opt/java/jre/lib/amd64/server |" libhadoop.la
  # fi

  ## Create some links, so Hadoop's KFS jar could access KFS libraries properly
  ## (it is still fine if KFS is not installed)

  # msg "Creating KFS links..."

  # for lib in libkfsClient libkfsCommon libkfsEmulator libkfsIO libkfsMeta; do
  #   for ext in a so; do
  #     ln -s /usr/lib/${lib}.${ext}
  #   done
  # done

  # ln -s /usr/lib/libkfs_access.so
}

md5sums=('5557aa1089ab9073d2a5c35c775cccad' # [downloaded hadoop.tar]
         '77fad322bff1877b0c5b4e6d693c979a' # hadoop.profile
         '2766a95c1f77037f3f768a59d5c44044' # conf.diff
         '95e046cc2414b9bf83f596dd941742f3' # src_fix.patch
         '2b662c5d0548cae29538060bbea9e96b' # hadoop-conf
         '56a70b8c94de7c1fb236ec24d7c11e05' # hadoop.sh
         '4e96bfa974fb7701b5636379c02f8470' # hadoop-namenode.service
         '287feaae2d479042d7210ea5ef079a5e' # hadoop-datanode.service
         '4dc609ae8d536dbb278a7e89c523384f' # hadoop-secondarynamenode.service
         'dba52a72c925365bc50a2e443a38f7f4' # hadoop-jobtracker.service
         '8da68ae4b6f20a969df19945d359fc32' # hadoop-tasktracker.service
         )








