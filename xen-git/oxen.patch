diff -Naur xen/Config.mk xen-b/Config.mk
--- xen/Config.mk	2013-05-11 21:02:58.048147769 -0600
+++ xen-b/Config.mk	2013-05-12 06:30:26.754814436 -0600
@@ -7,7 +7,6 @@
 # fallback for older make
 realpath = $(wildcard $(foreach file,$(1),$(shell cd -P $(dir $(file)) && echo "$$PWD/$(notdir $(file))")))
 
--include $(XEN_ROOT)/.config
 
 # A debug build of Xen and tools?
 debug ?= y
@@ -29,7 +28,7 @@
 
 # Tools to run on system hosting the build
 HOSTCC      = gcc
-HOSTCFLAGS  = -Wall -Werror -Wstrict-prototypes -O2 -fomit-frame-pointer
+HOSTCFLAGS  = -Wstrict-prototypes -O2 -fomit-frame-pointer
 HOSTCFLAGS += -fno-strict-aliasing
 
 DISTDIR     ?= $(XEN_ROOT)/dist
@@ -165,7 +164,7 @@
 
 CFLAGS += -std=gnu99
 
-CFLAGS += -Wall -Wstrict-prototypes
+CFLAGS += -Wstrict-prototypes
 
 # Clang complains about macros that expand to 'if ( ( foo == bar ) ) ...'
 # and is over-zealous with the printf format lint
diff -Naur xen/extras/mini-os/lib/math.c xen-b/extras/mini-os/lib/math.c
--- xen/extras/mini-os/lib/math.c	2013-05-08 21:21:22.138147769 -0600
+++ xen-b/extras/mini-os/lib/math.c	2013-05-12 06:30:26.754814436 -0600
@@ -186,6 +186,7 @@
 	 * and thus
 	 *	m = 4 - n <= 2
 	 */
+	tmp.ul[H] = tmp.ul[L] = 0;
 	tmp.uq = uq;
 	u[0] = 0;
 	u[1] = HHALF(tmp.ul[H]);
diff -Naur xen/extras/mini-os/minios.mk xen-b/extras/mini-os/minios.mk
--- xen/extras/mini-os/minios.mk	2013-05-08 21:21:22.138147769 -0600
+++ xen-b/extras/mini-os/minios.mk	2013-05-12 06:30:26.754814436 -0600
@@ -6,7 +6,7 @@
 
 # Define some default flags.
 # NB. '-Wcast-qual' is nasty, so I omitted it.
-DEF_CFLAGS += -fno-builtin -Wall -Werror -Wredundant-decls -Wno-format -Wno-redundant-decls
+DEF_CFLAGS += -fno-builtin -Wall -Wredundant-decls -Wno-format -Wno-redundant-decls
 DEF_CFLAGS += $(call cc-option,$(CC),-fno-stack-protector,)
 DEF_CFLAGS += $(call cc-option,$(CC),-fgnu89-inline)
 DEF_CFLAGS += -Wstrict-prototypes -Wnested-externs -Wpointer-arith -Winline
diff -Naur xen/tools/Rules.mk xen-b/tools/Rules.mk
--- xen/tools/Rules.mk	2013-05-08 21:21:22.151481103 -0600
+++ xen-b/tools/Rules.mk	2013-05-12 06:30:26.754814436 -0600
@@ -9,6 +9,8 @@
 export _INSTALL := $(INSTALL)
 INSTALL = $(XEN_ROOT)/tools/cross-install
 
+LDFLAGS_RPATH = -Wl,-rpath,'$${ORIGIN}$(if $(1),/$(1))'
+
 XEN_INCLUDE        = $(XEN_ROOT)/tools/include
 XEN_LIBXC          = $(XEN_ROOT)/tools/libxc
 XEN_XENLIGHT       = $(XEN_ROOT)/tools/libxl
diff -Naur xen/tools/blktap/drivers/Makefile xen-b/tools/blktap/drivers/Makefile
--- xen/tools/blktap/drivers/Makefile	2013-05-08 21:21:22.151481103 -0600
+++ xen-b/tools/blktap/drivers/Makefile	2013-05-12 06:30:26.754814436 -0600
@@ -38,8 +38,9 @@
 CFLAGS += $(PTHREAD_CFLAGS)
 LDFLAGS += $(PTHREAD_LDFLAGS)
 
-LDLIBS_blktapctrl := $(MEMSHRLIBS) $(LDLIBS_libxenctrl) $(LDLIBS_libxenstore) -L../lib -lblktap -lrt -lm $(PTHREAD_LIBS)
-LDLIBS_img := $(AIOLIBS) $(CRYPT_LIB) $(PTHREAD_LIBS) -lz
+LDLIBS_xen := $(LDLIBS_libxenctrl) $(LDLIBS_libxenstore)
+LDLIBS_blktapctrl := $(MEMSHRLIBS) $(LDLIBS_xen) -L../lib -lblktap -lrt -lm $(PTHREAD_LIBS)
+LDLIBS_img := $(AIOLIBS) $(CRYPT_LIB) $(PTHREAD_LIBS) -lz $(LDLIBS_xen)
 
 BLK-OBJS-y  := block-aio.o
 BLK-OBJS-y  += block-sync.o
@@ -47,6 +48,7 @@
 BLK-OBJS-y  += block-ram.o
 BLK-OBJS-y  += block-qcow.o
 BLK-OBJS-y  += block-qcow2.o
+BLK-OBJS-y  += block-cdrom.o
 BLK-OBJS-y  += aes.o
 BLK-OBJS-y  += tapaio.o
 BLK-OBJS-$(CONFIG_Linux) += blk_linux.o
diff -Naur xen/tools/blktap/drivers/block-cdrom.c xen-b/tools/blktap/drivers/block-cdrom.c
--- xen/tools/blktap/drivers/block-cdrom.c	1969-12-31 17:00:00.000000000 -0700
+++ xen-b/tools/blktap/drivers/block-cdrom.c	2013-05-12 06:30:26.758147769 -0600
@@ -0,0 +1,565 @@
+/* block-cdrom.c
+ *
+ * simple slow synchronous cdrom disk implementation. Based off
+ * of block-sync.c
+ *
+ * (c) 2006 Andrew Warfield and Julian Chesterfield
+ * (c) 2008 Novell Inc. <plc@novell.com>
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License version 2
+ * as published by the Free Software Foundation; or, when distributed
+ * separately from the Linux kernel or incorporated into other
+ * software packages, subject to the following license:
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this source file (the "Software"), to deal in the Software without
+ * restriction, including without limitation the rights to use, copy, modify,
+ * merge, publish, distribute, sublicense, and/or sell copies of the Software,
+ * and to permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
+ * IN THE SOFTWARE.
+ */
+
+#include <errno.h>
+#include <fcntl.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <unistd.h>
+#include <string.h>
+#include <sys/statvfs.h>
+#include <sys/stat.h>
+#include <sys/ioctl.h>
+#include <sys/mount.h>
+
+#include "tapdisk.h"
+#include <xen/io/cdromif.h>
+
+struct tdcdrom_state {
+	int fd;
+	int xs_fd;        /* for xen event polling */
+	int media_present;
+	int media_changed;
+	struct xs_handle *xs_handle;
+	char *dev_name;
+	int dev_type;
+	td_flag_t flags;
+};
+
+#define BLOCK_DEVICE   0
+#define FILE_DEVICE    1
+#define CDROM_DEFAULT_SECTOR_SIZE 2048
+#define CDROM_DEFAULT_SIZE 2000000000
+
+/*Get Image size, secsize*/
+static void get_image_info(struct disk_driver *dd)
+{
+	int ret;
+	long size;
+	unsigned long total_size;
+	struct statvfs statBuf;
+	struct stat stat;
+	struct td_state     *s   = dd->td_state;
+	struct tdcdrom_state *prv = dd->private;
+
+	s->size = 0;
+	s->sector_size = CDROM_DEFAULT_SECTOR_SIZE;
+	s->info = (VDISK_CDROM | VDISK_REMOVABLE | VDISK_READONLY);
+	prv->media_present = 0;
+
+	ret = fstat(prv->fd, &stat);
+	if (ret != 0) {
+		DPRINTF("ERROR: fstat failed, Couldn't stat image");
+		return;
+	}
+
+	if (S_ISBLK(stat.st_mode)) {
+		/*Accessing block device directly*/
+		int status;
+
+		prv->dev_type = BLOCK_DEVICE;
+		status = ioctl(prv->fd, CDROM_DRIVE_STATUS, CDSL_CURRENT);
+		if (status == CDS_DISC_OK) {
+			prv->media_present = 1;
+			if ((ret =ioctl(prv->fd,BLKGETSIZE,&s->size))!=0) {
+				DPRINTF("ERR: BLKGETSIZE failed, couldn't stat image");
+				s->size = CDROM_DEFAULT_SIZE;
+			}
+		}
+		else {
+			s->size = CDROM_DEFAULT_SIZE;
+		}
+		/*Get the sector size*/
+#if defined(BLKSSZGET)
+		{
+			int arg;
+			s->sector_size = CDROM_DEFAULT_SECTOR_SIZE;
+			ioctl(prv->fd, BLKSSZGET, &s->sector_size);
+
+			if (s->sector_size != CDROM_DEFAULT_SECTOR_SIZE)
+				DPRINTF("Note: sector size is %llu (not %d)\n",
+					(long long unsigned)s->sector_size,
+					CDROM_DEFAULT_SECTOR_SIZE);
+		}
+#else
+		s->sector_size = CDROM_DEFAULT_SECTOR_SIZE;
+#endif
+		DPRINTF("Block Device: Image size: %llu"
+			" media_present: %d sector_size: %llu\n",
+			(long long unsigned)s->size, prv->media_present,
+			(long long unsigned)s->sector_size);
+	} else {
+		/*Local file? try fstat instead*/
+		prv->dev_type = FILE_DEVICE;
+		prv->media_present = 1;
+		s->size = (stat.st_size >> SECTOR_SHIFT);
+		s->sector_size = DEFAULT_SECTOR_SIZE;
+		DPRINTF("Local File: Image size: %llu\n",
+				(long long unsigned)s->size);
+	}
+	return;
+}
+
+static inline void init_fds(struct disk_driver *dd)
+{
+	int i;
+	struct tdcdrom_state *prv = dd->private;
+
+	for(i = 0; i < MAX_IOFD; i++)
+		dd->io_fd[i] = 0;
+
+	prv->xs_handle = xs_daemon_open();
+	prv->xs_fd = xs_fileno(prv->xs_handle);
+	dd->io_fd[0] = prv->xs_fd;
+}
+
+void open_device (struct disk_driver *dd)
+{
+	struct tdcdrom_state *prv = dd->private;
+	int o_flags;
+
+	o_flags = O_NONBLOCK | O_LARGEFILE |
+		((prv->flags == TD_RDONLY) ? O_RDONLY : O_RDWR);
+
+	if (prv->fd < 0) {
+		prv->fd = open(prv->dev_name, o_flags);
+		if (prv->fd == -1) {
+			DPRINTF("Unable tp open: (%s)\n", prv->dev_name);
+			return;
+		}
+	}
+
+	if (prv->fd != -1) {
+
+		get_image_info(dd);
+
+		if (prv->dev_type == BLOCK_DEVICE) {
+			int status;
+			status = ioctl(prv->fd, CDROM_DRIVE_STATUS, CDSL_CURRENT);
+			switch (status) {
+				case CDS_DISC_OK:
+					prv->media_present = 1;
+					break;
+				default:
+					prv->media_present = 0;
+			}
+		}
+		else
+			prv->media_present = 1;
+	}
+}
+
+/*
+ * Main entry point, called when first loaded
+ */
+int tdcdrom_open (struct disk_driver *dd, const char *name, td_flag_t flags)
+{
+	int ret;
+	struct tdcdrom_state *prv = dd->private;
+
+	ret = asprintf(&prv->dev_name, "%s", name);
+	if (ret < 0) {
+		prv->dev_name = NULL;
+		goto out;
+	}
+	prv->fd = -1;
+	prv->media_changed = 0;
+	prv->media_present = 0;
+	prv->flags = flags;
+	init_fds(dd);
+
+	open_device(dd);
+
+out:
+	return ret;
+}
+
+int tdcdrom_queue_read(struct disk_driver *dd, uint64_t sector,
+		int nb_sectors, char *buf, td_callback_t cb,
+		int id, void *private)
+{
+	struct td_state     *s   = dd->td_state;
+	struct tdcdrom_state *prv = dd->private;
+	int      size    = nb_sectors * s->sector_size;
+	uint64_t offset  = sector * (uint64_t)s->sector_size;
+	int ret;
+
+	if (prv->fd == -1 || prv->media_present == 0) {
+		ret = 0 - ENOMEDIUM;
+		return cb(dd, (ret < 0) ? ret: 0, sector, nb_sectors, id, private);
+	}
+	size    = nb_sectors * 512;
+	offset  = sector * (uint64_t)512;
+	ret = lseek(prv->fd, offset, SEEK_SET);
+	if (ret != (off_t)-1) {
+		ret = read(prv->fd, buf, size);
+		if (ret != size) {
+			ret = 0 - errno;
+		} else {
+			ret = 1;
+		}
+	} else ret = 0 - errno;
+
+	return cb(dd, (ret < 0) ? ret: 0, sector, nb_sectors, id, private);
+}
+
+int tdcdrom_queue_write(struct disk_driver *dd, uint64_t sector,
+		int nb_sectors, char *buf, td_callback_t cb,
+		int id, void *private)
+{
+	struct td_state     *s   = dd->td_state;
+	struct tdcdrom_state *prv = dd->private;
+	int      size    = nb_sectors * s->sector_size;
+	uint64_t offset  = sector * (uint64_t)s->sector_size;
+	int ret = 0;
+
+	if (prv->fd == -1 || prv->media_present == 0) {
+		ret = 0 - ENOMEDIUM;
+		return cb(dd, (ret < 0) ? ret: 0, sector, nb_sectors, id, private);
+	}
+	ret = lseek(prv->fd, offset, SEEK_SET);
+	if (ret != (off_t)-1) {
+		ret = write(prv->fd, buf, size);
+		if (ret != size) {
+			ret = 0 - errno;
+		} else {
+			ret = 1;
+		}
+	} else ret = 0 - errno;
+
+	return cb(dd, (ret < 0) ? ret : 0, sector, nb_sectors, id, private);
+}
+
+int tdcdrom_queue_packet(struct disk_driver *dd, uint64_t sector,
+		int nb_sectors, char *buf, td_callback_t cb,
+		int id, void *private)
+{
+	struct td_state     *s   = dd->td_state;
+	struct tdcdrom_state *prv = dd->private;
+	int      size    = nb_sectors * s->sector_size;
+	uint64_t offset  = sector * (uint64_t)s->sector_size;
+	int ret = 0;
+
+	union xen_block_packet *sp;
+	struct xen_cdrom_packet *xcp;
+	struct xen_cdrom_support *xcs;
+	struct xen_cdrom_open *xco;
+	struct xen_cdrom_media_info *xcmi;
+	struct xen_cdrom_media_changed *xcmc;
+	struct cdrom_generic_command cgc;
+	struct vcd_generic_command * vgc;
+	struct request_sense sense;
+
+	sp = (union xen_block_packet *)buf;
+	switch(sp->type) {
+		case XEN_TYPE_CDROM_SUPPORT:
+			xcs = &(sp->xcs);
+			xcs->err = 0;
+			xcs->ret = 0;
+			xcs->supported = 1;
+			break;
+		case XEN_TYPE_CDROM_PACKET:
+			xcp = &(sp->xcp);
+			xcp->err = 0;
+			xcp->ret = 0;
+			vgc = (struct vcd_generic_command *)(buf + PACKET_PAYLOAD_OFFSET);
+
+			memset( &cgc, 0, sizeof(struct cdrom_generic_command));
+			memcpy(cgc.cmd, vgc->cmd, CDROM_PACKET_SIZE);
+			cgc.stat = vgc->stat;
+			cgc.data_direction = vgc->data_direction;
+			cgc.quiet = vgc->quiet;
+			cgc.timeout = vgc->timeout;
+
+			if (prv->fd == -1) {
+				xcp = &(sp->xcp);
+				xcp->ret = -1;
+				xcp->err =  0 - ENODEV;
+				return cb(dd, (ret < 0) ? ret: 0, sector, nb_sectors, id, private);
+			}
+			if (prv->dev_type == FILE_DEVICE) {
+				DPRINTF("%s() FILE_DEVICE inappropriate packetcmd \n",__func__);
+				return cb(dd, (ret < 0) ? ret: 0, sector, nb_sectors, id, private);
+			}
+			switch ( cgc.cmd[0]) {
+				case GPCMD_PREVENT_ALLOW_MEDIUM_REMOVAL:
+					{
+						int lock;
+						lock = cgc.cmd[4] & 1;
+						if (ioctl (prv->fd, CDROM_LOCKDOOR, lock) < 0) {
+							xcp->err = -(errno);
+							xcp->ret = -1;
+						}
+					}
+					break;
+				case GPCMD_START_STOP_UNIT:
+					{
+						int start, eject;
+						start = cgc.cmd[4] & 1;
+						eject = (cgc.cmd[4] >> 1) & 1;
+						if (eject && !start) {
+							if (ioctl (prv->fd, CDROMEJECT, NULL) < 0) {
+								xcp->err = -(errno);
+								xcp->ret = -1;
+							}
+						} else if (eject && start) {
+							if (ioctl (prv->fd, CDROMCLOSETRAY, NULL) < 0) {
+								xcp->err = -(errno);
+								xcp->ret = -1;
+							}
+						}
+					}
+					break;
+				default:
+					{
+						if (vgc->sense_offset) {
+							cgc.sense = &sense;
+						}
+						if (vgc->buffer_offset) {
+							cgc.buffer = malloc(vgc->buflen);
+							memcpy(cgc.buffer, (char *)sp + PACKET_BUFFER_OFFSET, vgc->buflen);
+							cgc.buflen = vgc->buflen;
+						}
+						if (ioctl (prv->fd, CDROM_SEND_PACKET, &cgc) < 0 ) {
+							xcp->err = -(errno);
+							xcp->ret = -1;
+						}
+						if (cgc.sense) {
+							memcpy((char *)sp + PACKET_SENSE_OFFSET, cgc.sense, sizeof(struct request_sense));
+						}
+						if (cgc.buffer) {
+							vgc->buflen = cgc.buflen;
+							memcpy((char *)sp + PACKET_BUFFER_OFFSET, cgc.buffer, cgc.buflen);
+							free(cgc.buffer);
+						}
+						break;
+					}
+			}
+			break;
+		case XEN_TYPE_CDROM_OPEN:
+			{
+				unsigned int len;
+				struct stat statbuf;
+				int major = 0;
+				int minor = 0;
+
+				if (stat (prv->dev_name, &statbuf) == 0) {
+					major = major (statbuf.st_rdev);
+					minor = minor (statbuf.st_rdev);
+				}
+				xco = &(sp->xco);
+				xco->err = 0;
+				xco->ret = 0;
+				if (xco->payload_offset) {
+					char *present;
+					char *buf;
+					char *num;
+					char *nodename;
+					char media_present[2];
+					nodename = (char *)sp + xco->payload_offset;
+					if (asprintf(&buf, "%s/media-present", nodename) < 0)
+						goto out_payload_offset;
+					present = xs_read(prv->xs_handle, XBT_NULL, buf, &len);
+					if (present) {
+						free(buf);
+						goto out_payload_offset_free;
+					}
+
+					sprintf(media_present, "%d", prv->media_present);
+					xs_write(prv->xs_handle, XBT_NULL, buf, media_present, strlen(media_present));
+					xs_watch(prv->xs_handle, buf, "media-present");
+					free(buf);
+
+					if (asprintf(&buf, "%s/params", nodename) < 0)
+						goto out_payload_offset_free;
+					xs_watch(prv->xs_handle, buf, "params");
+					free(buf);
+
+					if (asprintf(&num, "%x:%x", major, minor) < 0)
+						goto out_payload_offset_free;
+					if (asprintf(&buf, "%s/physical-device", nodename) < 0) {
+						free(num);
+						goto out_payload_offset_free;
+					}
+					xs_write(prv->xs_handle, XBT_NULL, buf, num, strlen(num));
+					free(buf);
+					free(num);
+out_payload_offset_free:
+					free(present);
+out_payload_offset:
+					;
+				}
+
+				xco->media_present = prv->media_present;
+				xco->sectors = 0;
+				xco->sector_size = 2048;
+				if (prv->media_present && prv->fd != -1 ) {
+					get_image_info(dd);
+					xco->sectors = s->size;
+					xco->sector_size = s->sector_size;
+				}
+			}
+			break;
+		case XEN_TYPE_CDROM_MEDIA_CHANGED:
+			xcmc = &(sp->xcmc);
+			xcmc->err = 0;
+			xcmc->ret = 0;
+			xcmc->media_changed = prv->media_changed;
+			prv->media_changed = 0;
+			break;
+		default:
+			xcp = &(sp->xcp);
+			xcp->err = -EINVAL;
+			xcp->ret = -1;
+			break;
+	}
+
+	return cb(dd, (ret < 0) ? ret: 0, sector, nb_sectors, id, private);
+}
+
+int tdcdrom_submit(struct disk_driver *dd)
+{
+	return 0;
+}
+
+int tdcdrom_close(struct disk_driver *dd)
+{
+	struct tdcdrom_state *prv = dd->private;
+
+	if (prv->fd != -1) {
+		close(prv->fd);
+		prv->fd = -1;
+	}
+	prv->xs_fd = -1;
+	xs_daemon_close(prv->xs_handle);
+	free(prv->dev_name);
+
+	return 0;
+}
+
+void tdcdrom_process_media_change_event(struct disk_driver *dd, char **vec)
+{
+    struct tdcdrom_state *prv = dd->private;
+    char *media_present;
+    unsigned int len;
+
+	media_present = xs_read(prv->xs_handle, XBT_NULL, vec[XS_WATCH_PATH], &len);
+	if (strcmp(media_present, "0") == 0) {
+		close(prv->fd);
+		prv->fd = -1;
+		prv->media_present = 0;
+	}
+	else {
+		open_device(dd);
+		prv->media_changed = 1;
+	}
+	free(media_present);
+}
+
+void tdcrom_process_params_event(struct disk_driver *dd, char **vec)
+{
+    struct tdcdrom_state *prv = dd->private;
+    char *params;
+    unsigned int len;
+
+	params = xs_read(prv->xs_handle, XBT_NULL, vec[XS_WATCH_PATH], &len);
+	if (params) {
+		char *cp = strchr(params, ':');
+		if (cp) {
+			cp++;
+			if (prv->dev_name)
+				free(prv->dev_name);
+			if (asprintf(&prv->dev_name, "%s", cp) < 0) {
+				prv->dev_name = NULL;
+				return;
+			}
+			if (prv->fd != -1) {
+				close(prv->fd);
+				prv->fd = -1;
+			}
+			open_device(dd);
+			prv->media_changed = 1;
+		}
+		free(params);
+	}
+}
+
+int tdcdrom_do_callbacks(struct disk_driver *dd, int sid)
+{
+	struct tdcdrom_state *prv = dd->private;
+	char **vec;
+	unsigned int num;
+
+	vec = xs_read_watch(prv->xs_handle, &num);
+	if (!vec)
+		return 1;
+
+    if (!strcmp(vec[XS_WATCH_TOKEN], "media-present")) {
+        tdcdrom_process_media_change_event(dd, vec);
+        goto out;
+    }
+
+    if (!strcmp(vec[XS_WATCH_TOKEN], "params")) {
+        tdcrom_process_params_event(dd, vec);
+        goto out;
+    }
+
+ out:
+    free(vec);
+	return 1;
+}
+
+int tdcdrom_get_parent_id(struct disk_driver *dd, struct disk_id *id)
+{
+	return TD_NO_PARENT;
+}
+
+int tdcdrom_validate_parent(struct disk_driver *dd,
+		struct disk_driver *parent, td_flag_t flags)
+{
+	return -EINVAL;
+}
+
+struct tap_disk tapdisk_cdrom = {
+	.disk_type           = "tapdisk_cdrom",
+	.private_data_size   = sizeof(struct tdcdrom_state),
+	.td_open             = tdcdrom_open,
+	.td_queue_read       = tdcdrom_queue_read,
+	.td_queue_packet     = tdcdrom_queue_packet,
+	.td_queue_write      = tdcdrom_queue_write,
+	.td_submit           = tdcdrom_submit,
+	.td_close            = tdcdrom_close,
+	.td_do_callbacks     = tdcdrom_do_callbacks,
+	.td_get_parent_id    = tdcdrom_get_parent_id,
+	.td_validate_parent  = tdcdrom_validate_parent
+};
diff -Naur xen/tools/blktap/drivers/tapdisk.c xen-b/tools/blktap/drivers/tapdisk.c
--- xen/tools/blktap/drivers/tapdisk.c	2013-05-08 21:21:22.154814437 -0600
+++ xen-b/tools/blktap/drivers/tapdisk.c	2013-05-12 06:30:26.758147769 -0600
@@ -735,6 +735,22 @@
 					goto out;
 				}
 				break;
+			case BLKIF_OP_PACKET:
+				ret = 0;
+				if (drv->td_queue_packet)
+					ret = drv->td_queue_packet(dd, sector_nr,
+							nsects, page,
+							send_responses,
+							idx, (void *)(long)i);
+				if (ret > 0) dd->early += ret;
+				else if (ret == -EBUSY) {
+					/* put req back on queue */
+					--info->fe_ring.req_cons;
+					info->busy.req     = req;
+					info->busy.seg_idx = i;
+					goto out;
+				}
+				break;
 			default:
 				DPRINTF("Unknown block operation\n");
 				break;
diff -Naur xen/tools/blktap/drivers/tapdisk.h xen-b/tools/blktap/drivers/tapdisk.h
--- xen/tools/blktap/drivers/tapdisk.h	2013-05-08 21:21:22.154814437 -0600
+++ xen-b/tools/blktap/drivers/tapdisk.h	2013-05-12 06:30:26.758147769 -0600
@@ -137,6 +137,9 @@
 	int (*td_get_parent_id)  (struct disk_driver *dd, struct disk_id *id);
 	int (*td_validate_parent)(struct disk_driver *dd, 
 				  struct disk_driver *p, td_flag_t flags);
+	int (*td_queue_packet)  (struct disk_driver *dd, uint64_t sector,
+				  int nb_sectors, char *buf, td_callback_t cb,
+				  int id, void *prv);
 };
 
 typedef struct disk_info {
@@ -160,6 +163,7 @@
 extern struct tap_disk tapdisk_ram;
 extern struct tap_disk tapdisk_qcow;
 extern struct tap_disk tapdisk_qcow2;
+extern struct tap_disk tapdisk_cdrom;
 
 
 /*Define Individual Disk Parameters here */
@@ -229,6 +233,17 @@
 #endif
 };
 
+static disk_info_t cdrom_disk = {
+	DISK_TYPE_CDROM,
+	"raw image (cdrom)",
+	"cdrom",
+	0,
+	0,
+#ifdef TAPDISK
+	&tapdisk_cdrom,
+#endif
+};
+
 /*Main disk info array */
 static disk_info_t *dtypes[] = {
 	&aio_disk,
@@ -237,6 +252,7 @@
 	&ram_disk,
 	&qcow_disk,
 	&qcow2_disk,
+	&cdrom_disk,
 };
 
 typedef struct driver_list_entry {
diff -Naur xen/tools/blktap/lib/blktaplib.h xen-b/tools/blktap/lib/blktaplib.h
--- xen/tools/blktap/lib/blktaplib.h	2013-05-11 20:44:07.274814436 -0600
+++ xen-b/tools/blktap/lib/blktaplib.h	2013-05-12 06:30:26.758147769 -0600
@@ -219,6 +219,7 @@
 #define DISK_TYPE_RAM      3
 #define DISK_TYPE_QCOW     4
 #define DISK_TYPE_QCOW2    5
+#define DISK_TYPE_CDROM    6
 
 /* xenstore/xenbus: */
 #define DOMNAME "Domain-0"
diff -Naur xen/tools/blktap2/drivers/Makefile xen-b/tools/blktap2/drivers/Makefile
--- xen/tools/blktap2/drivers/Makefile	2013-05-08 21:21:22.158147771 -0600
+++ xen-b/tools/blktap2/drivers/Makefile	2013-05-12 06:30:26.758147769 -0600
@@ -9,7 +9,7 @@
 LOCK_UTIL  = lock-util
 INST_DIR   = $(SBINDIR)
 
-CFLAGS    += -Werror -g
+CFLAGS    += -g
 CFLAGS    += -Wno-unused
 CFLAGS    += -fno-strict-aliasing
 CFLAGS    += -I$(BLKTAP_ROOT)/include -I$(BLKTAP_ROOT)/drivers
diff -Naur xen/tools/debugger/gdbsx/Rules.mk xen-b/tools/debugger/gdbsx/Rules.mk
--- xen/tools/debugger/gdbsx/Rules.mk	2013-05-08 21:21:22.171481102 -0600
+++ xen-b/tools/debugger/gdbsx/Rules.mk	2013-05-12 06:30:26.758147769 -0600
@@ -1,4 +1,4 @@
 include $(XEN_ROOT)/tools/Rules.mk
 
-CFLAGS   += -Werror -Wmissing-prototypes 
+CFLAGS   += -Wmissing-prototypes 
 # (gcc 4.3x and later)   -Wconversion -Wno-sign-conversion
diff -Naur xen/tools/debugger/gdbsx/xg/xg_main.c xen-b/tools/debugger/gdbsx/xg/xg_main.c
--- xen/tools/debugger/gdbsx/xg/xg_main.c	2013-05-08 21:21:22.171481102 -0600
+++ xen-b/tools/debugger/gdbsx/xg/xg_main.c	2013-05-12 06:30:26.758147769 -0600
@@ -179,7 +179,7 @@
     hypercall.op = __HYPERVISOR_domctl;
     hypercall.arg[0] = (unsigned long)&domctl;
 
-    rc = ioctl(_dom0_fd, IOCTL_PRIVCMD_HYPERCALL, (ulong)&hypercall);
+    rc = ioctl(_dom0_fd, IOCTL_PRIVCMD_HYPERCALL, (unsigned long)&hypercall);
     if (domctlarg && sz)
         munlock(domctlarg, sz);
     return rc;
@@ -219,7 +219,7 @@
     hypercall.arg[0] = (unsigned long)XENVER_capabilities;
     hypercall.arg[1] = (unsigned long)&xen_caps;
 
-    rc = ioctl(_dom0_fd, IOCTL_PRIVCMD_HYPERCALL, (ulong)&hypercall);
+    rc = ioctl(_dom0_fd, IOCTL_PRIVCMD_HYPERCALL, (unsigned long)&hypercall);
     munlock(&xen_caps, sizeof(xen_caps));
     XGTRC("XENCAPS:%s\n", xen_caps);
 
diff -Naur xen/tools/examples/Makefile xen-b/tools/examples/Makefile
--- xen/tools/examples/Makefile	2013-05-08 21:21:22.171481102 -0600
+++ xen-b/tools/examples/Makefile	2013-05-12 06:30:26.758147769 -0600
@@ -25,7 +25,7 @@
 XEN_CONFIGS += xend-pci-permissive.sxp
 XEN_CONFIGS += xl.conf
 XEN_CONFIGS += cpupool
-
+XEN_CONFIGS += xmexample.disks
 .PHONY: all
 all:
 
diff -Naur xen/tools/examples/xend-config.sxp xen-b/tools/examples/xend-config.sxp
--- xen/tools/examples/xend-config.sxp	2013-05-08 21:21:22.171481102 -0600
+++ xen-b/tools/examples/xend-config.sxp	2013-05-12 06:30:26.758147769 -0600
@@ -194,6 +194,26 @@
 #(network-script network-route)
 #(vif-script     vif-route)
 
+# SuSE users note:
+# If using a routed network configuration it is advised to NOT use
+# network-route and vif-route scripts but instead use sysconfig scripts
+# in dom0 and vif-route-ifup script to "connect" the domU vif to dom0.
+# Since this configuration requires a vif sysconfig script in dom0, a static
+# vif name must be used.  E.g. in dom0 the vif sysconfig script
+# (/etc/sysconfig/network/ifcfg-xen1.0) may contain
+#
+#    NAME='XEN vm 1 virtual interface 0'
+#    BOOTPROTO='static'
+#    STARTMODE='hotplug'
+#    ...
+#
+# The corresponding domain vif configuration would contain e.g.
+# vif=[ 'mac=00:16:3e:aa:bb:cc,script=vif-route-ifup,vifname=xen1.0', ]
+#
+# If the vif-route-ifup script will be used for all domains, it can be
+# set here as the default vif script, alleviating the need for
+# 'script=' in domain vif configuration.
+#(vif-script     vif-route-ifup)
 
 ## Use the following if network traffic is routed with NAT, as an alternative
 # to the settings for bridged networking given above.
diff -Naur xen/tools/examples/xmexample.disks xen-b/tools/examples/xmexample.disks
--- xen/tools/examples/xmexample.disks	1969-12-31 17:00:00.000000000 -0700
+++ xen-b/tools/examples/xmexample.disks	2013-05-12 06:30:26.758147769 -0600
@@ -0,0 +1,32 @@
+# A VM's disks can be stored in a variety of ways.
+# Here are some examples:
+disk = [
+    # Block device
+    'phy:/dev/hdb,xvda,w',
+    # Raw format, accessed via loopback
+    'file:/var/lib/xen/images/disk-example/disk0,xvdb,w',
+    # Raw format, accessed via blocktap
+    'tap:aio:/var/lib/xen/images/disk-example/disk0,xvdc,w',
+    # QCOW format, accessed via blocktap
+    'tap:qcow:/var/lib/xen/images/disk-example/disk0.qcow,xvdd,w',
+    # NBD (network block device):  IP and port are separated by space
+    'nbd:192.168.0.1 20004,xvde,w',
+    # iSCSI:  The usual colon is replaced with '@'
+    'iscsi:iqn.2006-09.de.suse@0ac47ee2-216e-452a-a341-a12624cd0225,xvdf,w',
+    # Fibre Channel N_Port ID Virtualization
+    'npiv:210400e08b80c40f,xvdg,w' ]
+
+
+# Remaining settings for the example VM:
+name="disk-example"
+memory=512
+vcpus=1
+on_crash="destroy"
+on_poweroff="destroy"
+on_reboot="restart"
+localtime=0
+builder="linux"
+bootloader="/usr/lib/xen/boot/domUloader.py"
+bootargs="--entry=xvda2:/boot/vmlinuz-xen,/boot/initrd-xen"
+vif=[ 'mac=00:16:3e:00:01:02,bridge=xenbr0' ]
+vfb=['type=vnc,vncunused=1']
diff -Naur xen/tools/examples/xmexample.hvm xen-b/tools/examples/xmexample.hvm
--- xen/tools/examples/xmexample.hvm	2013-05-08 21:21:22.171481102 -0600
+++ xen-b/tools/examples/xmexample.hvm	2013-05-12 06:30:26.761481103 -0600
@@ -127,6 +127,15 @@
 # Device Model to be used
 device_model = 'qemu-dm'
 
+# the amount of memory in MiB for the guest
+#actmem=42
+
+# Optional: guest page file
+#xenpaging_file="/var/lib/xen/xenpaging/<domain_name>.<domaind_id>.paging"
+
+# Optional: extra cmdline options for xenpaging
+#xenpaging_extra=[ 'string', 'string' ]
+
 #-----------------------------------------------------------------------------
 # boot on floppy (a), hard disk (c), Network (n) or CD-ROM (d) 
 # default: hard disk, cd-rom, floppy
diff -Naur xen/tools/firmware/Makefile xen-b/tools/firmware/Makefile
--- xen/tools/firmware/Makefile	2013-05-11 20:45:48.751481103 -0600
+++ xen-b/tools/firmware/Makefile	2013-05-12 06:30:26.761481103 -0600
@@ -18,8 +18,8 @@
 	cp ovmf-makefile ovmf/Makefile;
 
 seabios-dir:
-	GIT=$(GIT) $(XEN_ROOT)/scripts/git-checkout.sh $(SEABIOS_UPSTREAM_URL) $(SEABIOS_UPSTREAM_TAG) seabios-dir
-	cp seabios-config seabios-dir/.config;
+	GIT=$(GIT) $(XEN_ROOT)/scripts/git-checkout.sh $(SEABIOS_UPSTREAM_URL) $(SEABIOS_UPSTREAM_TAG) seabios-dir 	
+	cp seabios-config seabios-dir/.config; 
 	patch -d seabios-dir -p1 -i ../seabios-mac-20130223.patch
 
 .PHONY: all
diff -Naur xen/tools/firmware/etherboot/Config xen-b/tools/firmware/etherboot/Config
--- xen/tools/firmware/etherboot/Config	2013-05-08 21:21:22.174814436 -0600
+++ xen-b/tools/firmware/etherboot/Config	2013-05-12 06:30:26.761481103 -0600
@@ -1,3 +1,4 @@
+NICS = rtl8139 8086100e eepro100 e1000 pcnet32 10ec8029
 
 CFLAGS += -UPXE_DHCP_STRICT
 CFLAGS += -DPXE_DHCP_STRICT
diff -Naur xen/tools/firmware/hvmloader/config.h xen-b/tools/firmware/hvmloader/config.h
--- xen/tools/firmware/hvmloader/config.h	2013-05-08 21:21:22.178147770 -0600
+++ xen-b/tools/firmware/hvmloader/config.h	2013-05-12 06:30:26.761481103 -0600
@@ -5,6 +5,9 @@
 
 enum virtual_vga { VGA_none, VGA_std, VGA_cirrus, VGA_pt };
 extern enum virtual_vga virtual_vga;
+//PARCHE//
+extern uint8_t gfx_bdf;
+//PARCHE_END//
 
 extern unsigned long igd_opregion_pgbase;
 #define IGD_OPREGION_PAGES 3
diff -Naur xen/tools/hotplug/Linux/network-bridge xen-b/tools/hotplug/Linux/network-bridge
--- xen/tools/hotplug/Linux/network-bridge	2013-05-08 21:21:22.191481103 -0600
+++ xen-b/tools/hotplug/Linux/network-bridge	2013-05-12 06:30:26.761481103 -0600
@@ -280,19 +280,19 @@
     transfer_addrs ${bridge} ${pdev}
     if ! ifdown ${bridge}; then
 	get_ip_info ${bridge}
-    fi
-    ip link set ${pdev} down
-    ip addr flush ${bridge}
+	ip link set ${pdev} down
+	ip addr flush ${bridge}
 
-    brctl delif ${bridge} ${pdev}
-    ip link set ${bridge} down
+	brctl delif ${bridge} ${pdev}
+	ip link set ${bridge} down
 
-    ip link set ${bridge} name ${tdev}
+	ip link set ${bridge} name ${tdev}
+	brctl delbr ${tdev}
+    fi
+    ip link set ${pdev} down
     ip link set ${pdev} name ${netdev}
     do_ifup ${netdev}
 
-    brctl delbr ${tdev}
-
     release_lock "network-bridge"
 }
 
diff -Naur xen/tools/hotplug/Linux/network-openvswitch xen-b/tools/hotplug/Linux/network-openvswitch
--- xen/tools/hotplug/Linux/network-openvswitch	1969-12-31 17:00:00.000000000 -0700
+++ xen-b/tools/hotplug/Linux/network-openvswitch	2013-05-12 06:30:26.761481103 -0600
@@ -0,0 +1,121 @@
+#!/bin/bash
+#============================================================================
+# Default Xen network start/stop script.
+# Xend calls a network script when it starts.
+# The script name to use is defined in ${XEN_CONFIG_DIR}/xend-config.sxp
+# in the network-script field.
+#
+# This script creates a virtual switch (default ${netdev}) and adds a
+# device (defaults to eth0) to it.  The interface that this Open vSwitch
+# is created on should not have a working IP address and will be used as
+# a switch for Xen domU's.
+#
+# Usage:
+# network-openvswitch (start|stop|status) {VAR=VAL}*
+#
+# Vars:
+# bridge     The bridge to use (default xenvs0).
+# netdev     The interface to add to the bridge (default eth0).
+#
+# start:
+# Creates the bridge as bridge
+# Enslaves netdev to bridge
+#
+# stop:
+# Removes netdev from the bridge
+# Deletes bridge
+#
+# status:
+# Print addresses, interfaces
+#
+#============================================================================
+
+dir=$(dirname "$0")
+. "$dir/logging.sh"
+. "$dir/xen-script-common.sh"
+. "$dir/xen-network-common.sh"
+. "$dir/locking.sh"
+
+findCommand "$@"
+evalVariables "$@"
+
+netdev=${netdev:-eth1}
+bridge=${bridge:-ovs0}
+
+addr=`ip addr show dev ${netdev} | egrep '^ *inet' | sed -e 's/ *inet
+//' -e 's/ .*//'`
+if [ -n "$addr" ]; then
+    echo "Invalid device: ${netdev} is up and has a valid IP address!" >&2
+    exit 1
+fi
+
+show_status () {
+    local dev=$1
+    local bridge=$2
+
+    echo '============================================================'
+    echo 'vSwitch interfaces'
+    ovs-vsctl list-ifaces ${bridge}
+    echo ' '
+    echo 'vSwitch ports'
+    ovs-vsctl list-ports ${bridge}
+    echo '============================================================'
+}
+
+op_start () {
+    if [ "${bridge}" = "null" ] ; then
+        return
+    fi
+
+    ip link set "${netdev}" down
+    ip link set "${netdev}" 0.0.0.0 up
+    ovs-vsctl -- --may-exist add-br ${bridge}
+    ip link set "${bridge}" 0.0.0.0 up
+    ovs-vsctl -- --may-exist add-port ${bridge} ${netdev}
+
+    # Remove any stale ports from last time virtual switch was running
+    for port in $(ovs-vsctl list-ports ${bridge})
+    do
+        if [ "${port}" != "${netdev}" ]
+        then
+            ip link set "${port}" down
+            ovs-vsctl del-port ${port}
+
+        fi
+    done
+}
+
+op_stop () {
+    if [ "${bridge}" = "null" ]; then
+        return
+    fi
+
+    # Remove all ports from virtual switch
+    for port in $(ovs-vsctl list-ports ${bridge})
+    do
+        ip link set "${port}" down
+        ovs-vsctl del-port ${port}
+    done
+
+    ip link set "${bridge}" down
+    ovs-vsctl -- --if-exists del-br ${bridge}
+}
+
+case "$command" in
+    start)
+        op_start
+        ;;
+
+    stop)
+        op_stop
+        ;;
+
+    status)
+        show_status ${netdev} ${bridge}
+        ;;
+
+    *)
+        echo "Unknown command: $command" >&2
+        echo 'Valid commands are: start, stop, status' >&2
+        exit 1
+esac
diff -Naur xen/tools/hotplug/Linux/vif-bridge xen-b/tools/hotplug/Linux/vif-bridge
--- xen/tools/hotplug/Linux/vif-bridge	2013-05-08 21:21:22.191481103 -0600
+++ xen-b/tools/hotplug/Linux/vif-bridge	2013-05-12 06:30:26.761481103 -0600
@@ -32,6 +32,13 @@
 dir=$(dirname "$0")
 . "$dir/vif-common.sh"
 
+mac=$(xenstore_read_default "$XENBUS_PATH/mac" "")
+if [ -z "$mac" ]
+then
+    log debug "No device details in $XENBUS_PATH, exiting."
+    exit 0
+fi
+
 bridge=${bridge:-}
 bridge=$(xenstore_read_default "$XENBUS_PATH/bridge" "$bridge")
 
diff -Naur xen/tools/hotplug/Linux/vif-route-ifup xen-b/tools/hotplug/Linux/vif-route-ifup
--- xen/tools/hotplug/Linux/vif-route-ifup	1969-12-31 17:00:00.000000000 -0700
+++ xen-b/tools/hotplug/Linux/vif-route-ifup	2013-05-12 06:30:26.761481103 -0600
@@ -0,0 +1,34 @@
+#!/bin/bash
+#============================================================================
+# /etc/xen/vif-route-ifup
+#
+# Script for configuring a vif in routed mode.
+# The hotplugging system will call this script if it is specified either in
+# the device configuration given to Xend, or the default Xend configuration
+# in /etc/xen/xend-config.sxp.  If the script is specified in neither of those
+# places, then vif-bridge is the default.
+#
+# Usage:
+# vif-route-ifup (add|remove|online|offline)
+#
+# Environment vars:
+# dev         vif interface name (required).
+#============================================================================
+
+dir=$(dirname "$0")
+. "$dir/vif-common.sh"
+
+case "$command" in
+    online)
+        ifup ${dev}
+        ;;
+    offline)
+        do_without_error ifdown ${dev}
+        ;;
+esac
+
+log debug "Successful vif-route-ifup $command for ${dev}."
+if [ "$command" = "online" ]
+then
+  success
+fi
diff -Naur xen/tools/hotplug/Linux/xend.rules xen-b/tools/hotplug/Linux/xend.rules
--- xen/tools/hotplug/Linux/xend.rules	2013-05-08 21:21:22.191481103 -0600
+++ xen-b/tools/hotplug/Linux/xend.rules	2013-05-12 06:30:26.761481103 -0600
@@ -1,4 +1,4 @@
 SUBSYSTEM=="pci", RUN+="socket:/org/xen/xend/udev_event"
 SUBSYSTEM=="scsi", RUN+="socket:/org/xen/xend/udev_event"
 SUBSYSTEM=="usb", RUN+="socket:/org/xen/xend/udev_event"
-#SUBSYSTEM=="net", KERNEL!="vif[0-9]*.[0-9]*|tap[0-9]*.[0-9]*", RUN+="socket:/org/xen/xend/udev_event"
+SUBSYSTEM=="net", KERNEL!="vif[0-9]*.[0-9]*|tap[0-9]*.[0-9]*", RUN+="socket:/org/xen/xend/udev_event"
diff -Naur xen/tools/libaio/harness/Makefile xen-b/tools/libaio/harness/Makefile
--- xen/tools/libaio/harness/Makefile	2013-05-08 21:21:22.194814436 -0600
+++ xen-b/tools/libaio/harness/Makefile	2013-05-12 06:30:26.761481103 -0600
@@ -4,7 +4,7 @@
 HARNESS_SRCS:=main.c
 # io_queue.c
 
-CFLAGS=-Wall -Werror -g -O -laio
+CFLAGS=-Wall -g -O -laio
 #-lpthread -lrt
 
 all: $(PROGS)
diff -Naur xen/tools/libfsimage/Rules.mk xen-b/tools/libfsimage/Rules.mk
--- xen/tools/libfsimage/Rules.mk	2013-05-08 21:21:22.201481103 -0600
+++ xen-b/tools/libfsimage/Rules.mk	2013-05-12 06:30:26.761481103 -0600
@@ -1,7 +1,7 @@
 include $(XEN_ROOT)/tools/Rules.mk
 
 CFLAGS += -Wno-unknown-pragmas -I$(XEN_ROOT)/tools/libfsimage/common/ -DFSIMAGE_FSDIR=\"$(FSDIR)\"
-CFLAGS += -Werror -D_GNU_SOURCE
+CFLAGS += -D_GNU_SOURCE
 LDFLAGS += -L../common/
 
 PIC_OBJS := $(patsubst %.c,%.opic,$(LIB_SRCS-y))
diff -Naur xen/tools/libxc/Makefile xen-b/tools/libxc/Makefile
--- xen/tools/libxc/Makefile	2013-05-08 21:21:22.204814437 -0600
+++ xen-b/tools/libxc/Makefile	2013-05-12 06:30:26.761481103 -0600
@@ -80,7 +80,7 @@
 
 -include $(XEN_TARGET_ARCH)/Makefile
 
-CFLAGS   += -Werror -Wmissing-prototypes
+CFLAGS   += -Wmissing-prototypes
 CFLAGS   += -I. $(CFLAGS_xeninclude)
 
 # Needed for posix_fadvise64() in xc_linux.c
diff -Naur xen/tools/libxc/xc_suspend.c xen-b/tools/libxc/xc_suspend.c
--- xen/tools/libxc/xc_suspend.c	2013-05-08 21:21:22.214814435 -0600
+++ xen-b/tools/libxc/xc_suspend.c	2013-05-12 06:30:26.761481103 -0600
@@ -16,8 +16,43 @@
 
 #include "xc_private.h"
 #include "xenguest.h"
+#include <signal.h>
+#ifdef __MINIOS__
+extern int kill (__pid_t __pid, int __sig);
+#endif
 
 #define SUSPEND_LOCK_FILE "/var/lib/xen/suspend_evtchn"
+/* cleanup obsolete suspend lock file which is unlinked for any reason,
+so that current process can get lock */
+static void clean_obsolete_lock(int domid)
+{
+    int fd, pid, n;
+    char buf[128];
+    char suspend_file[256];
+
+    snprintf(suspend_file, sizeof(suspend_file), "%s_%d_lock.d",
+        SUSPEND_LOCK_FILE, domid);
+    fd = open(suspend_file, O_RDWR);
+
+    if (fd < 0)
+        return;
+
+    n = read(fd, buf, 127);
+
+    close(fd);
+
+    if (n > 0)
+    {
+        sscanf(buf, "%d", &pid);
+        /* pid does not exist, this lock file is obsolete, just delete it */
+        if ( kill(pid,0) )
+        {
+            unlink(suspend_file);
+            return;
+        }
+    }
+}
+
 static int lock_suspend_event(xc_interface *xch, int domid)
 {
     int fd, rc;
@@ -27,6 +62,7 @@
 
     snprintf(suspend_file, sizeof(suspend_file), "%s_%d_lock.d",
 	    SUSPEND_LOCK_FILE, domid);
+    clean_obsolete_lock(domid);
     mask = umask(022);
     fd = open(suspend_file, O_CREAT | O_EXCL | O_RDWR, 0666);
     if (fd < 0)
@@ -41,6 +77,9 @@
     rc = write_exact(fd, buf, strlen(buf));
     close(fd);
 
+    if(rc)
+    unlink(suspend_file);
+
     return rc;
 }
 
@@ -127,8 +166,7 @@
     return suspend_evtchn;
 
 cleanup:
-    if (suspend_evtchn != -1)
-        xc_suspend_evtchn_release(xch, xce, domid, suspend_evtchn);
+    xc_suspend_evtchn_release(xch, xce, domid, suspend_evtchn);
 
     return -1;
 }
diff -Naur xen/tools/libxen/src/xen_common.c xen-b/tools/libxen/src/xen_common.c
--- xen/tools/libxen/src/xen_common.c	2013-05-08 21:21:22.221481103 -0600
+++ xen-b/tools/libxen/src/xen_common.c	2013-05-12 06:30:26.761481103 -0600
@@ -904,8 +904,15 @@
             0 != strcmp((char *)value_node->children->name, "struct") ||
             value_node->children->children == NULL)
         {
+#if PERMISSIVE
+            fprintf(stderr,
+                    "Expected Map from the server, but didn't get one\n");
+            ((arbitrary_map **)value)[slot] = NULL;
+#else
+
             server_error(s,
                          "Expected Map from the server, but didn't get it");
+#endif
         }
         else
         {
diff -Naur xen/tools/libxl/Makefile xen-b/tools/libxl/Makefile
--- xen/tools/libxl/Makefile	2013-05-08 21:21:22.224814437 -0600
+++ xen-b/tools/libxl/Makefile	2013-05-12 06:30:26.764814436 -0600
@@ -11,7 +11,7 @@
 XLUMAJOR = 4.3
 XLUMINOR = 0
 
-CFLAGS += -Werror -Wno-format-zero-length -Wmissing-declarations \
+CFLAGS += -Wno-format-zero-length -Wmissing-declarations \
 	-Wno-declaration-after-statement -Wformat-nonliteral
 CFLAGS += -I. -fPIC
 
diff -Naur xen/tools/libxl/Makefile.orig xen-b/tools/libxl/Makefile.orig
--- xen/tools/libxl/Makefile.orig	1969-12-31 17:00:00.000000000 -0700
+++ xen-b/tools/libxl/Makefile.orig	2013-05-08 21:21:22.224814437 -0600
@@ -0,0 +1,232 @@
+#
+# tools/libxl/Makefile
+#
+
+XEN_ROOT = $(CURDIR)/../..
+include $(XEN_ROOT)/tools/Rules.mk
+
+MAJOR = 4.3
+MINOR = 0
+
+XLUMAJOR = 4.3
+XLUMINOR = 0
+
+CFLAGS += -Werror -Wno-format-zero-length -Wmissing-declarations \
+	-Wno-declaration-after-statement -Wformat-nonliteral
+CFLAGS += -I. -fPIC
+
+ifeq ($(CONFIG_Linux),y)
+LIBUUID_LIBS += -luuid
+endif
+
+LIBXL_LIBS =
+LIBXL_LIBS = $(LDLIBS_libxenctrl) $(LDLIBS_libxenguest) $(LDLIBS_libxenstore) $(LDLIBS_libblktapctl) $(PTYFUNCS_LIBS) $(LIBUUID_LIBS)
+
+CFLAGS_LIBXL += $(CFLAGS_libxenctrl)
+CFLAGS_LIBXL += $(CFLAGS_libxenguest)
+CFLAGS_LIBXL += $(CFLAGS_libxenstore)
+CFLAGS_LIBXL += $(CFLAGS_libblktapctl) 
+CFLAGS_LIBXL += -Wshadow
+
+CFLAGS += $(PTHREAD_CFLAGS)
+LDFLAGS += $(PTHREAD_LDFLAGS)
+LIBXL_LIBS += $(PTHREAD_LIBS)
+
+LIBXLU_LIBS =
+
+LIBXL_OBJS-y = osdeps.o libxl_paths.o libxl_bootloader.o flexarray.o
+ifeq ($(LIBXL_BLKTAP),y)
+LIBXL_OBJS-y += libxl_blktap2.o
+else
+LIBXL_OBJS-y += libxl_noblktap2.o
+endif
+LIBXL_OBJS-$(CONFIG_X86) += libxl_cpuid.o libxl_x86.o
+LIBXL_OBJS-$(CONFIG_IA64) += libxl_nocpuid.o libxl_noarch.o
+LIBXL_OBJS-$(CONFIG_ARM) += libxl_nocpuid.o libxl_noarch.o
+
+ifeq ($(CONFIG_NetBSD),y)
+LIBXL_OBJS-y += libxl_netbsd.o
+else
+ifeq ($(CONFIG_Linux),y)
+LIBXL_OBJS-y += libxl_linux.o
+else
+$(error Your Operating System is not supported by libxenlight, \
+please check libxl_linux.c and libxl_netbsd.c to see how to get it ported)
+endif
+endif
+
+ifeq ($(FLEX),)
+%.c %.h:: %.l
+	$(warning Flex is needed to rebuild some libxl parsers and \
+		  scanners, please install it and rerun configure)
+endif
+
+ifeq ($(BISON),)
+%.c %.h:: %.y
+	$(warning Bison is needed to rebuild some libxl parsers and \
+		  scanners, please install it an rerun configure)
+endif
+
+LIBXL_LIBS += -lyajl
+
+LIBXL_OBJS = flexarray.o libxl.o libxl_create.o libxl_dm.o libxl_pci.o \
+			libxl_dom.o libxl_exec.o libxl_xshelp.o libxl_device.o \
+			libxl_internal.o libxl_utils.o libxl_uuid.o \
+			libxl_json.o libxl_aoutils.o libxl_numa.o \
+			libxl_save_callout.o _libxl_save_msgs_callout.o \
+			libxl_qmp.o libxl_event.o libxl_fork.o $(LIBXL_OBJS-y)
+LIBXL_OBJS += _libxl_types.o libxl_flask.o _libxl_types_internal.o
+
+$(LIBXL_OBJS): CFLAGS += $(CFLAGS_LIBXL) -include $(XEN_ROOT)/tools/config.h
+
+AUTOINCS= libxlu_cfg_y.h libxlu_cfg_l.h _libxl_list.h _paths.h \
+	_libxl_save_msgs_callout.h _libxl_save_msgs_helper.h
+AUTOSRCS= libxlu_cfg_y.c libxlu_cfg_l.c
+AUTOSRCS += _libxl_save_msgs_callout.c _libxl_save_msgs_helper.c
+LIBXLU_OBJS = libxlu_cfg_y.o libxlu_cfg_l.o libxlu_cfg.o \
+	libxlu_disk_l.o libxlu_disk.o libxlu_vif.o libxlu_pci.o
+$(LIBXLU_OBJS): CFLAGS += $(CFLAGS_libxenctrl) # For xentoollog.h
+
+CLIENTS = xl testidl libxl-save-helper
+
+CFLAGS_XL += $(CFLAGS_libxenlight)
+CFLAGS_XL += -Wshadow
+
+XL_OBJS = xl.o xl_cmdimpl.o xl_cmdtable.o xl_sxp.o
+$(XL_OBJS) _libxl.api-for-check: \
+            CFLAGS += $(CFLAGS_libxenctrl) # For xentoollog.h
+$(XL_OBJS): CFLAGS += $(CFLAGS_XL)
+$(XL_OBJS): CFLAGS += -include $(XEN_ROOT)/tools/config.h # libxl_json.h needs it.
+
+SAVE_HELPER_OBJS = libxl_save_helper.o _libxl_save_msgs_helper.o
+$(SAVE_HELPER_OBJS): CFLAGS += $(CFLAGS_libxenctrl)
+
+testidl.o: CFLAGS += $(CFLAGS_libxenctrl) $(CFLAGS_libxenlight)
+testidl.c: libxl_types.idl gentest.py libxl.h $(AUTOINCS)
+	$(PYTHON) gentest.py libxl_types.idl testidl.c.new
+	mv testidl.c.new testidl.c
+
+.PHONY: all
+all: $(CLIENTS) libxenlight.so libxenlight.a libxlutil.so libxlutil.a \
+	$(AUTOSRCS) $(AUTOINCS)
+
+$(LIBXL_OBJS) $(LIBXLU_OBJS) $(XL_OBJS) $(SAVE_HELPER_OBJS): \
+	$(AUTOINCS) libxl.api-ok
+
+%.c %.h:: %.y
+	@rm -f $*.[ch]
+	$(BISON) --output=$*.c $<
+
+%.c %.h:: %.l
+	@rm -f $*.[ch]
+	$(FLEX) --header-file=$*.h --outfile=$*.c $<
+
+genpath-target = $(call buildmakevars2file,_paths.h.tmp)
+$(eval $(genpath-target))
+
+libxl.api-ok: check-libxl-api-rules _libxl.api-for-check
+	$(PERL) $^
+	touch $@
+
+_%.api-for-check: %.h $(AUTOINCS)
+	$(CC) $(CPPFLAGS) $(CFLAGS) $(CFLAGS_$*.o) -c -E $< $(APPEND_CFLAGS) \
+		-DLIBXL_EXTERNAL_CALLERS_ONLY=LIBXL_EXTERNAL_CALLERS_ONLY \
+		>$@.new
+	mv -f $@.new $@
+
+_paths.h: genpath
+	sed -e "s/\([^=]*\)=\(.*\)/#define \1 \2/g" $@.tmp >$@.2.tmp
+	rm -f $@.tmp
+	$(call move-if-changed,$@.2.tmp,$@)
+
+_libxl_list.h: $(XEN_INCLUDE)/xen-external/bsd-sys-queue-h-seddery $(XEN_INCLUDE)/xen-external/bsd-sys-queue.h
+	$(PERL) $^ --prefix=libxl >$@.new
+	$(call move-if-changed,$@.new,$@)
+
+_libxl_save_msgs_helper.c _libxl_save_msgs_callout.c \
+_libxl_save_msgs_helper.h _libxl_save_msgs_callout.h: \
+		libxl_save_msgs_gen.pl
+	$(PERL) -w $< $@ >$@.new
+	$(call move-if-changed,$@.new,$@)
+
+libxl.h: _libxl_types.h
+libxl_json.h: _libxl_types_json.h
+libxl_internal.h: _libxl_types_internal.h _paths.h
+libxl_internal_json.h: _libxl_types_internal_json.h
+xl.h: _paths.h
+
+$(LIBXL_OBJS) $(LIBXLU_OBJS) $(XL_OBJS) $(SAVE_HELPER_OBJS): libxl.h
+$(LIBXL_OBJS): libxl_internal.h
+
+_libxl_type%.h _libxl_type%_json.h _libxl_type%.c: libxl_type%.idl gentypes.py idl.py
+	$(PYTHON) gentypes.py libxl_type$*.idl __libxl_type$*.h __libxl_type$*_json.h __libxl_type$*.c
+	$(call move-if-changed,__libxl_type$*.h,_libxl_type$*.h)
+	$(call move-if-changed,__libxl_type$*_json.h,_libxl_type$*_json.h)
+	$(call move-if-changed,__libxl_type$*.c,_libxl_type$*.c)
+
+libxenlight.so: libxenlight.so.$(MAJOR)
+	ln -sf $< $@
+
+libxenlight.so.$(MAJOR): libxenlight.so.$(MAJOR).$(MINOR)
+	ln -sf $< $@
+
+libxenlight.so.$(MAJOR).$(MINOR): $(LIBXL_OBJS)
+	$(CC) $(LDFLAGS) -Wl,$(SONAME_LDFLAG) -Wl,libxenlight.so.$(MAJOR) $(SHLIB_LDFLAGS) -o $@ $^ $(LIBXL_LIBS) $(APPEND_LDFLAGS)
+
+libxenlight.a: $(LIBXL_OBJS)
+	$(AR) rcs libxenlight.a $^
+
+libxlutil.so: libxlutil.so.$(XLUMAJOR)
+	ln -sf $< $@
+
+libxlutil.so.$(XLUMAJOR): libxlutil.so.$(XLUMAJOR).$(XLUMINOR)
+	ln -sf $< $@
+
+libxlutil.so.$(XLUMAJOR).$(XLUMINOR): $(LIBXLU_OBJS)
+	$(CC) $(LDFLAGS) -Wl,$(SONAME_LDFLAG) -Wl,libxlutil.so.$(XLUMAJOR) $(SHLIB_LDFLAGS) -o $@ $^ $(LIBXLU_LIBS) $(APPEND_LDFLAGS)
+
+libxlutil.a: $(LIBXLU_OBJS)
+	$(AR) rcs libxlutil.a $^
+
+xl: $(XL_OBJS) libxlutil.so libxenlight.so
+	$(CC) $(LDFLAGS) -o $@ $(XL_OBJS) libxlutil.so $(LDLIBS_libxenlight) $(LDLIBS_libxenctrl) -lyajl $(APPEND_LDFLAGS)
+
+libxl-save-helper: $(SAVE_HELPER_OBJS) libxenlight.so
+	$(CC) $(LDFLAGS) -o $@ $(SAVE_HELPER_OBJS) $(LDLIBS_libxenctrl) $(LDLIBS_libxenguest) $(APPEND_LDFLAGS)
+
+testidl: testidl.o libxlutil.so libxenlight.so
+	$(CC) $(LDFLAGS) -o $@ testidl.o libxlutil.so $(LDLIBS_libxenlight) $(LDLIBS_libxenctrl) $(APPEND_LDFLAGS)
+
+.PHONY: install
+install: all
+	$(INSTALL_DIR) $(DESTDIR)$(SBINDIR)
+	$(INSTALL_DIR) $(DESTDIR)$(LIBDIR)
+	$(INSTALL_DIR) $(DESTDIR)$(INCLUDEDIR)
+	$(INSTALL_DIR) $(DESTDIR)$(BASH_COMPLETION_DIR)
+	$(INSTALL_DIR) $(DESTDIR)$(XEN_RUN_DIR)
+	$(INSTALL_DIR) $(DESTDIR)$(PRIVATE_BINDIR)
+	$(INSTALL_PROG) xl $(DESTDIR)$(SBINDIR)
+	$(INSTALL_PROG) libxl-save-helper $(DESTDIR)$(PRIVATE_BINDIR)
+	$(INSTALL_PROG) libxenlight.so.$(MAJOR).$(MINOR) $(DESTDIR)$(LIBDIR)
+	ln -sf libxenlight.so.$(MAJOR).$(MINOR) $(DESTDIR)$(LIBDIR)/libxenlight.so.$(MAJOR)
+	ln -sf libxenlight.so.$(MAJOR) $(DESTDIR)$(LIBDIR)/libxenlight.so
+	$(INSTALL_DATA) libxenlight.a $(DESTDIR)$(LIBDIR)
+	$(INSTALL_PROG) libxlutil.so.$(XLUMAJOR).$(XLUMINOR) $(DESTDIR)$(LIBDIR)
+	ln -sf libxlutil.so.$(XLUMAJOR).$(XLUMINOR) $(DESTDIR)$(LIBDIR)/libxlutil.so.$(XLUMAJOR)
+	ln -sf libxlutil.so.$(XLUMAJOR) $(DESTDIR)$(LIBDIR)/libxlutil.so
+	$(INSTALL_DATA) libxlutil.a $(DESTDIR)$(LIBDIR)
+	$(INSTALL_DATA) libxl.h libxl_event.h libxl_json.h _libxl_types.h _libxl_types_json.h _libxl_list.h libxl_utils.h libxl_uuid.h $(DESTDIR)$(INCLUDEDIR)
+	$(INSTALL_DATA) bash-completion $(DESTDIR)$(BASH_COMPLETION_DIR)/xl.sh
+
+.PHONY: clean
+clean:
+	$(RM) -f _*.h *.o *.so* *.a $(CLIENTS) $(DEPS)
+	$(RM) -f _*.c *.pyc _paths.*.tmp _*.api-for-check
+	$(RM) -f testidl.c.new testidl.c *.api-ok
+
+distclean: clean
+
+realclean: distclean
+	$(RM) -f $(AUTOSRCS) $(AUTOINCS)
+
+-include $(DEPS)
diff -Naur xen/tools/libxl/libxl_dm.c xen-b/tools/libxl/libxl_dm.c
--- xen/tools/libxl/libxl_dm.c	2013-05-11 21:02:58.048147769 -0600
+++ xen-b/tools/libxl/libxl_dm.c	2013-05-12 06:30:26.764814436 -0600
@@ -222,6 +222,12 @@
                 }
             }
         }
+        if (b_info->u.hvm.watchdog || b_info->u.hvm.watchdog_action) {
+            flexarray_append(dm_args, "-watchdog");
+            if (b_info->u.hvm.watchdog_action) {
+                flexarray_vappend(dm_args, "-watchdog-action", b_info->u.hvm.watchdog_action, NULL);
+            }
+        }
         if (b_info->u.hvm.soundhw) {
             flexarray_vappend(dm_args, "-soundhw", b_info->u.hvm.soundhw, NULL);
         }
@@ -520,6 +526,12 @@
                 }
             }
         }
+        if (b_info->u.hvm.watchdog || b_info->u.hvm.watchdog_action) {
+            flexarray_append(dm_args, "-watchdog");
+            if (b_info->u.hvm.watchdog_action) {
+                flexarray_vappend(dm_args, "-watchdog-action", b_info->u.hvm.watchdog_action, NULL);
+            }
+        }
         if (b_info->u.hvm.soundhw) {
             flexarray_vappend(dm_args, "-soundhw", b_info->u.hvm.soundhw, NULL);
         }
diff -Naur xen/tools/libxl/libxl_types.idl xen-b/tools/libxl/libxl_types.idl
--- xen/tools/libxl/libxl_types.idl	2013-05-08 21:21:22.231481103 -0600
+++ xen-b/tools/libxl/libxl_types.idl	2013-05-12 06:30:26.764814436 -0600
@@ -332,6 +332,8 @@
                                        ("usbdevice",        string),
                                        ("soundhw",          string),
                                        ("xen_platform_pci", libxl_defbool),
+                                       ("watchdog",         string),
+                                       ("watchdog_action",  string),
                                        ("usbdevice_list",   libxl_string_list),
                                        ])),
                  ("pv", Struct(None, [("kernel", string),
diff -Naur xen/tools/libxl/xl_cmdimpl.c xen-b/tools/libxl/xl_cmdimpl.c
--- xen/tools/libxl/xl_cmdimpl.c	2013-05-11 21:04:14.408147769 -0600
+++ xen-b/tools/libxl/xl_cmdimpl.c	2013-05-12 06:30:26.764814436 -0600
@@ -1394,6 +1394,8 @@
                         " \"device_model_stubdomain_override\" directive"
                         " for pv guest\n");
         }
+        xlu_cfg_replace_string (config, "watchdog", &b_info->u.hvm.watchdog, 0);
+        xlu_cfg_replace_string (config, "watchdog_action", &b_info->u.hvm.watchdog_action, 0);
     }
 
 
diff -Naur xen/tools/misc/serial-split/Makefile xen-b/tools/misc/serial-split/Makefile
--- xen/tools/misc/serial-split/Makefile	1969-12-31 17:00:00.000000000 -0700
+++ xen-b/tools/misc/serial-split/Makefile	2013-05-12 06:30:26.764814436 -0600
@@ -0,0 +1,20 @@
+CC     ?= gcc
+CFLAGS ?= -Wall -Os
+CFILES = $(wildcard *.c)
+OBJS   = $(patsubst %.c,%.o,$(wildcard *.c))
+TARGET = serial-split
+
+all: $(TARGET)
+
+install: all
+	install -d $(DESTDIR)/usr/bin
+	install -s $(TARGET) $(DESTDIR)/usr/bin/
+
+clean:
+	rm *.o $(TARGET) *~
+
+$(TARGET): $(OBJS)
+	$(CC) $(CFLAGS) -o $@ $^
+
+%.o: %.c Makefile
+	$(CC) $(CFLAGS) -c -o $@ $<
diff -Naur xen/tools/misc/serial-split/serial-split.c xen-b/tools/misc/serial-split/serial-split.c
--- xen/tools/misc/serial-split/serial-split.c	1969-12-31 17:00:00.000000000 -0700
+++ xen-b/tools/misc/serial-split/serial-split.c	2013-05-12 06:30:26.764814436 -0600
@@ -0,0 +1,422 @@
+/*
+ *  serial-split.c
+ *  pdb / console splitter
+ *
+ *  Copyright 2005 Charles Coffing <ccoffing@novell.com>
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ */
+
+/*
+ *  Typical setup:
+ *
+ *               Development box          Xen box
+ *                      ...-----+        +-----...
+ *  +---------+                 |        |
+ *  | gdb     |                 |        |
+ *  |         |\ high           |        |
+ *  +---------+ \               |        |
+ *               \+-----------+ | serial | +------------------+
+ *                |  splitter |------------| Xen              |
+ *               /+-----------+ |        | |  - pdb    (com1H)|
+ *  +---------+ /               |        | |  - printk (com1) |
+ *  | console |/ low            |        | +------------------+
+ *  | viewer  |                 |        |
+ *  +---------+                 |        |
+ *                      ...-----+        +-----...
+ */
+
+
+#include <assert.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <unistd.h>
+#include <fcntl.h>
+#include <termios.h>
+#include <sys/signal.h>
+#include <sys/time.h>
+#include <sys/types.h>
+#include <sys/wait.h>
+#include <sys/socket.h>
+#include <sys/ioctl.h>
+#include <netinet/in.h>
+
+const unsigned int DefaultLowPort = 12010;
+const unsigned int DefaultBaud = 115200;
+const char DefaultSerialDevice[] = "/dev/ttyS0";
+
+#define DEBUG 0
+#define MAX(a,b) ((a)<(b)?(b):(a))
+
+
+static int cook_baud(int baud)
+{
+    int cooked_baud = 0;
+    switch (baud)
+    {
+    case     50: cooked_baud =     B50; break;
+    case     75: cooked_baud =     B75; break;
+    case    110: cooked_baud =    B110; break;
+    case    134: cooked_baud =    B134; break;
+    case    150: cooked_baud =    B150; break;
+    case    200: cooked_baud =    B200; break;
+    case    300: cooked_baud =    B300; break;
+    case    600: cooked_baud =    B600; break;
+    case   1200: cooked_baud =   B1200; break;
+    case   1800: cooked_baud =   B1800; break;
+    case   2400: cooked_baud =   B2400; break;
+    case   4800: cooked_baud =   B4800; break;
+    case   9600: cooked_baud =   B9600; break;
+    case  19200: cooked_baud =  B19200; break;
+    case  38400: cooked_baud =  B38400; break;
+    case  57600: cooked_baud =  B57600; break;
+    case 115200: cooked_baud = B115200; break;
+    }
+    return cooked_baud;
+}
+
+
+static int start_listener(unsigned short port)
+{
+    int fd;
+    struct sockaddr_in sin;
+    int on = 1;
+
+    if ((fd = socket (AF_INET, SOCK_STREAM, 0)) < 0)
+    {
+        perror("socket");
+        goto out1;
+    }
+
+    setsockopt(fd, SOL_SOCKET, SO_REUSEADDR, &on, sizeof (on));
+
+    memset(&sin, 0, sizeof(sin));
+    sin.sin_family = AF_INET;
+    sin.sin_port = htons (port);
+    sin.sin_addr.s_addr = INADDR_ANY;
+    if (bind(fd, (struct sockaddr *)&sin, sizeof(sin)) < 0)
+    {
+        perror("bind");
+        goto out2;
+    }
+
+    if (listen(fd, 1) < 0)
+    {
+        perror("listen");
+        goto out2;
+    }
+
+    fprintf(stderr, "Listening on port %d\n", port);
+
+    return fd;
+
+out2:
+    close(fd);
+out1:
+    return -1;
+}
+
+
+static int accept_conn(int fd)
+{
+    int on = 1;
+    int new_fd;
+    struct sockaddr_in from;
+    socklen_t fromlen = sizeof(from);
+
+    new_fd = accept(fd, (struct sockaddr *)&from, &fromlen);
+    if (new_fd < 0)
+        perror("accept");
+    ioctl(new_fd, FIONBIO, &on);
+
+    fprintf(stderr, "Accepted connection on %d\n", new_fd);
+
+    return new_fd;
+}
+
+
+static void close_conn(int * fd)
+{
+    shutdown(*fd, 2);
+    close(*fd);
+    *fd = -1;
+}
+
+
+static int receive_data(int * fd, char * buf, ssize_t max_bytes, int * poll)
+{
+    ssize_t bytes;
+    if ((bytes = read(*fd, buf, max_bytes)) < 0)
+    {
+        perror("read");
+        *poll = 1;
+        return 0;
+    }
+    else if (bytes == 0)
+    {
+        close_conn(fd);
+        *poll = 0;
+        return 0;
+    }
+    else
+    {
+        if (bytes == max_bytes)
+            *poll = 1;
+        else
+            *poll = 0;
+#if DEBUG
+        {
+            ssize_t i;
+            fprintf(stderr, "Received %d bytes on %d:\n", bytes, *fd);
+            for (i = 0; i < bytes; ++ i)
+            {
+                if ((i & 0xf) == 0)
+                    printf("    ");
+                printf("%02x", buf[i] & 0xff);
+                if (((i+1) & 0xf) == 0 || i + 1 == bytes)
+                    printf("\n");
+                else
+                    printf(" ");
+            }
+        }
+#endif
+        return bytes;
+    }
+}
+
+
+static void set_high_bit(char * buf, size_t bytes)
+{
+    size_t i;
+    for(i = 0; i < bytes; ++ i)
+        buf[i] |= 0x80;
+}
+
+
+static void clear_high_bit(char * buf, size_t bytes)
+{
+    size_t i;
+    for(i = 0; i < bytes; ++ i)
+        buf[i] &= 0x7f;
+}
+
+
+static int open_serial(char const * serial_dev, int baud)
+{
+    struct termios newsertio;
+    int serial_fd;
+    memset(&newsertio, 0, sizeof(newsertio));
+
+    if ((serial_fd = open(serial_dev, O_RDWR | O_NOCTTY | O_NONBLOCK)) < 0)
+    {
+        perror(serial_dev);
+        return -1;
+    }
+
+    newsertio.c_cflag = baud | CS8 | CLOCAL | CREAD;
+    newsertio.c_iflag = IGNBRK | IGNPAR;    /* raw input */
+    newsertio.c_oflag = 0;                  /* raw output */
+    newsertio.c_lflag = 0;                  /* no echo, no signals */
+    newsertio.c_cc[VMIN] = 1;
+    newsertio.c_cc[VTIME] = 0;
+    tcflush(serial_fd, TCIFLUSH);
+    tcsetattr(serial_fd, TCSANOW, &newsertio);
+
+    fprintf(stderr, "Listening on %s\n", serial_dev);
+
+    return serial_fd;
+}
+
+
+static void main_loop(int serial_fd, int low_listener, int high_listener)
+{
+    fd_set rdfds;
+    int low_poll = 0, high_poll = 0, serial_poll = 0;
+    int low_fd = -1, high_fd = -1;
+
+    while(1)
+    {
+        char buf[1024];
+        ssize_t bytes;
+        int max;
+
+        FD_ZERO(&rdfds);
+        FD_SET(low_fd < 0 ? low_listener : low_fd, &rdfds);
+        FD_SET(high_fd < 0 ? high_listener : high_fd, &rdfds);
+        FD_SET(serial_fd, &rdfds);
+
+        max = MAX(low_fd, low_listener);
+        max = MAX(max, high_fd);
+        max = MAX(max, high_listener);
+        max = MAX(max, serial_fd);
+
+        if (select(max + 1, &rdfds, NULL, NULL, NULL) < 0)
+        {
+            perror("select");
+            continue;
+        }
+
+        if (FD_ISSET(low_listener, &rdfds))
+        {
+            assert(low_fd < 0);
+            low_fd = accept_conn(low_listener);
+        }
+
+        if (FD_ISSET(high_listener, &rdfds))
+        {
+            assert(high_fd < 0);
+            high_fd = accept_conn(high_listener);
+        }
+
+        if (low_poll || (low_fd >= 0 && FD_ISSET(low_fd, &rdfds)))
+        {
+            if ((bytes = receive_data(&low_fd, &buf[0], sizeof(buf),
+                                      &low_poll)) > 0)
+            {
+                clear_high_bit(&buf[0], bytes);
+                if (write(serial_fd, &buf[0], bytes) < 0)
+                    perror("write");
+            }
+        }
+
+        if (high_poll || (high_fd >= 0 && FD_ISSET(high_fd, &rdfds)))
+        {
+            if ((bytes = receive_data(&high_fd, &buf[0], sizeof(buf),
+                                      &high_poll)) > 0)
+            {
+                set_high_bit(&buf[0], bytes);
+                if (write(serial_fd, &buf[0], bytes) < 0)
+                    perror("write");
+            }
+        }
+
+        if (serial_poll || FD_ISSET(serial_fd, &rdfds))
+        {
+            if ((bytes = receive_data(&serial_fd, &buf[0], sizeof(buf),
+                                      &serial_poll)) > 0)
+            {
+                ssize_t i;
+                for (i = 0; i < bytes; ++ i)
+                {
+                    if (buf[i] & 0x80)
+                    {
+                        if (high_fd >= 0)
+                        {
+                            buf[i] &= 0x7f;
+                            if ((write(high_fd, &buf[i], 1)) < 0)
+                            {
+                                perror("write");
+                                close_conn(&high_fd);
+                                high_poll = 0;
+                            }
+                        }
+                    }
+                    else
+                    {
+                        if (low_fd >= 0)
+                        {
+                            if ((write(low_fd, &buf[i], 1)) < 0)
+                            {
+                                perror("write");
+                                close_conn(&low_fd);
+                                low_poll = 0;
+                            }
+                        }
+                    }
+                }
+            }
+        }
+    }
+}
+
+
+static void usage()
+{
+    printf(
+"Description:\n"
+"        Splits the serial port between two TCP ports.  Bytes read from the\n"
+"        serial port will be delivered to one of the two TCP ports (high or\n"
+"        low) depending on whether the high bit is set.  Bytes written to the\n"
+"        TCP ports will be forwarded to the serial port; the high bit will be\n"
+"        set or cleared to denote the source.\n"
+"Usage:\n"
+"        serial-split [-d<serial-device>] [-b<baud>]\n"
+"                     [-l<low-port>] [-h<high-port>]\n"
+"Parameters:\n"
+"        -d<serial-device>  Defaults to %s.\n"
+"        -b<baud>           Baud rate of the serial port.  Defaults to %d.\n"
+"                           Also assumes 8N1.\n"
+"        -l<low-port>       Low TCP port.  Defaults to %d, or one less than\n"
+"                           the high port.\n"
+"        -h<high-port>      High TCP port.  Defaults to %d, or one more than\n"
+"                           the low port.\n",
+DefaultSerialDevice, DefaultBaud, DefaultLowPort, DefaultLowPort + 1);
+
+    exit(1);
+}
+
+
+int main(int argc, char **argv)
+{
+    int cooked_baud = cook_baud(DefaultBaud);
+    char const * serial_dev = DefaultSerialDevice;
+    int low_port = -1, high_port = -1;
+    int serial_fd, low_listener, high_listener;
+
+    while ( --argc != 0 )
+    {
+        char *p = argv[argc];
+        if ( *(p++) != '-' )
+            usage();
+        switch (*(p++))
+        {
+        case 'b':
+            if ( (cooked_baud = cook_baud(atoi(p))) == 0 )
+            {
+                fprintf(stderr, "Bad baud rate\n");
+                exit(1);
+            }
+            break;
+        case 'd':
+            serial_dev = p;
+            break;
+        case 'l':
+            if ((low_port = atoi(p)) <= 0)
+                usage();
+            break;
+        case 'h':
+            if ((high_port = atoi(p)) <= 0)
+                usage();
+            break;
+        default:
+            usage();
+        }
+    }
+
+    if (low_port == -1 && high_port == -1)
+        low_port = DefaultLowPort;
+    if (low_port == -1)
+        low_port = high_port - 1;
+    if (high_port == -1)
+        high_port = low_port + 1;
+
+    if ((serial_fd = open_serial(serial_dev, cooked_baud)) < 0 ||
+        (low_listener = start_listener(low_port)) < 0 ||
+        (high_listener = start_listener(high_port)) < 0)
+        exit(1);
+
+    main_loop(serial_fd, low_listener, high_listener);
+
+    return 0;
+}
+
diff -Naur xen/tools/misc/xend xen-b/tools/misc/xend
--- xen/tools/misc/xend	2013-05-08 21:21:22.238147768 -0600
+++ xen-b/tools/misc/xend	2013-05-12 06:30:26.764814436 -0600
@@ -1,4 +1,4 @@
-#!/usr/bin/env python
+#!/usr/bin/python -Es
 #  -*- mode: python; -*-
 #============================================================================
 # Copyright (C) 2004 Mike Wray <mike.wray@hp.com>
diff -Naur xen/tools/pygrub/src/pygrub xen-b/tools/pygrub/src/pygrub
--- xen/tools/pygrub/src/pygrub	2013-05-11 20:44:07.281481103 -0600
+++ xen-b/tools/pygrub/src/pygrub	2013-05-12 06:30:26.768147769 -0600
@@ -17,7 +17,6 @@
 import copy
 import logging
 import platform
-import xen.lowlevel.xc
 
 import curses, _curses, curses.wrapper, curses.textpad, curses.ascii
 import getopt
@@ -26,6 +25,7 @@
 import grub.GrubConf
 import grub.LiloConf
 import grub.ExtLinuxConf
+import xnloader
 
 PYGRUB_VER = 0.6
 FS_READ_MAX = 1024 * 1024
@@ -119,6 +119,7 @@
     fd = os.open(file, os.O_RDONLY)
     buf = os.read(fd, 512)
     os.close(fd)
+    offzerocount = 0
     for poff in (446, 462, 478, 494): # partition offsets
 
         # MBR contains a 16 byte descriptor per partition
@@ -128,6 +129,7 @@
         
         # offset == 0 implies this partition is not enabled
         if offset == 0:
+            offzerocount += 1
             continue
 
         if type == FDISK_PART_SOLARIS or type == FDISK_PART_SOLARIS_OLD:
@@ -148,6 +150,9 @@
         else:
             part_offs.append(offset)
 
+    if offzerocount == 4:
+        # Might be a grub boot sector pretending to be an MBR
+        part_offs.append(0)
     return part_offs
 
 class GrubLineEditor(curses.textpad.Textbox):
@@ -637,51 +642,6 @@
 
     return grubcfg
 
-def supports64bitPVguest():
-    xc = xen.lowlevel.xc.xc()
-    caps = xc.xeninfo()['xen_caps'].split(" ")
-    for cap in caps:
-        if cap == "xen-3.0-x86_64":
-            return True
-    return False
-
-# If nothing has been specified, look for a Solaris domU. If found, perform the
-# necessary tweaks.
-def sniff_solaris(fs, cfg):
-    if not fs.file_exists("/platform/i86xpv/kernel/unix") and \
-       not fs.file_exists("/platform/i86xpv/kernel/amd64/unix"):
-        return cfg
-
-    if not cfg["kernel"]:
-        if supports64bitPVguest() and \
-          fs.file_exists("/platform/i86xpv/kernel/amd64/unix"):
-            cfg["kernel"] = "/platform/i86xpv/kernel/amd64/unix"
-            cfg["ramdisk"] = "/platform/i86pc/amd64/boot_archive"
-        elif fs.file_exists("/platform/i86xpv/kernel/unix"):
-            cfg["kernel"] = "/platform/i86xpv/kernel/unix"
-            cfg["ramdisk"] = "/platform/i86pc/boot_archive"
-        else:
-            return cfg
-
-    # Unpleasant. Typically we'll have 'root=foo -k' or 'root=foo /kernel -k',
-    # and we need to maintain Xen properties (root= and ip=) and the kernel
-    # before any user args.
-    
-    xenargs = ""
-    userargs = ""
-    
-    if not cfg["args"]:
-        cfg["args"] = cfg["kernel"]
-    else:
-        for arg in cfg["args"].split():
-            if re.match("^root=", arg) or re.match("^ip=", arg):
-                xenargs += arg + " "
-            elif arg != cfg["kernel"]:
-                userargs += arg + " "
-        cfg["args"] = xenargs + " " + cfg["kernel"] + " " + userargs
-
-    return cfg
- 
 def sniff_netware(fs, cfg):
     if not fs.file_exists("/nwserver/xnloader.sys"):
         return cfg
@@ -734,6 +694,8 @@
             if len(data) == 0:
                 os.close(tfd)
                 del datafile
+                if file_to_read == "/nwserver/xnloader.sys":
+                    xnloader.patch_netware_loader(ret)
                 return ret
             try:
                 os.write(tfd, data)
@@ -846,10 +808,7 @@
         try:
             fs = fsimage.open(file, offset, bootfsoptions)
 
-            chosencfg = sniff_solaris(fs, incfg)
-
-            if not chosencfg["kernel"]:
-                chosencfg = sniff_netware(fs, incfg)
+            chosencfg = sniff_netware(fs, incfg)
 
             if not chosencfg["kernel"]:
                 chosencfg = run_grub(file, entry, fs, incfg["args"])
diff -Naur xen/tools/python/README.XendConfig xen-b/tools/python/README.XendConfig
--- xen/tools/python/README.XendConfig	2013-05-08 21:21:22.244814437 -0600
+++ xen-b/tools/python/README.XendConfig	2013-05-12 06:30:26.768147769 -0600
@@ -118,6 +118,9 @@
                                 image.vncdisplay
                                 image.vncunused
                                 image.hvm.device_model
+                                image.hvm.actmem
+                                image.hvm.xenpaging_file
+                                image.hvm.xenpaging_extra
                                 image.hvm.display
                                 image.hvm.xauthority
                                 image.hvm.vncconsole
diff -Naur xen/tools/python/README.sxpcfg xen-b/tools/python/README.sxpcfg
--- xen/tools/python/README.sxpcfg	2013-05-08 21:21:22.244814437 -0600
+++ xen-b/tools/python/README.sxpcfg	2013-05-12 06:30:26.768147769 -0600
@@ -51,6 +51,9 @@
   - vncunused
   (HVM)
   - device_model
+  - actmem
+  - xenpaging_file
+  - xenpaging_extra
   - display
   - xauthority
   - vncconsole
diff -Naur xen/tools/python/xen/util/pci.py xen-b/tools/python/xen/util/pci.py
--- xen/tools/python/xen/util/pci.py	2013-05-08 21:21:22.258147769 -0600
+++ xen-b/tools/python/xen/util/pci.py	2013-05-12 06:30:26.768147769 -0600
@@ -1268,7 +1268,11 @@
             pass
 
     def get_info_from_sysfs(self):
-        self.find_capability(0x11)
+        try:
+            self.find_capability(0x11)
+        except PciDeviceParseError, err:
+            log.error("Caught '%s'" % err)
+             return False
         sysfs_mnt = find_sysfs_mnt()
         if sysfs_mnt == None:
             return False
diff -Naur xen/tools/python/xen/xend/XendAPI.py xen-b/tools/python/xen/xend/XendAPI.py
--- xen/tools/python/xen/xend/XendAPI.py	2013-05-08 21:21:22.261481102 -0600
+++ xen-b/tools/python/xen/xend/XendAPI.py	2013-05-12 06:30:26.768147769 -0600
@@ -1941,10 +1941,10 @@
                               bool(live), port, node, ssl, bool(chs))
         return xen_api_success_void()
 
-    def VM_save(self, _, vm_ref, dest, checkpoint):
+    def VM_save(self, _, vm_ref, dest, checkpoint, force):
         xendom = XendDomain.instance()
         xeninfo = xendom.get_vm_by_uuid(vm_ref)
-        xendom.domain_save(xeninfo.getDomid(), dest, checkpoint)
+        xendom.domain_save(xeninfo.getDomid(), dest, checkpoint, force)
         return xen_api_success_void()
 
     def VM_restore(self, _, src, paused):
diff -Naur xen/tools/python/xen/xend/XendAPIConstants.py xen-b/tools/python/xen/xend/XendAPIConstants.py
--- xen/tools/python/xen/xend/XendAPIConstants.py	2013-05-08 21:21:22.261481102 -0600
+++ xen-b/tools/python/xen/xend/XendAPIConstants.py	2013-05-12 06:30:26.768147769 -0600
@@ -45,8 +45,10 @@
 XEN_API_ON_CRASH_BEHAVIOUR = [
     'destroy',
     'coredump_and_destroy',
+    'coredump_destroy',
     'restart',
     'coredump_and_restart',
+    'coredump_restart',
     'preserve',
     'rename_restart'
 ]
diff -Naur xen/tools/python/xen/xend/XendCheckpoint.py xen-b/tools/python/xen/xend/XendCheckpoint.py
--- xen/tools/python/xen/xend/XendCheckpoint.py	2013-05-11 21:04:14.414814436 -0600
+++ xen-b/tools/python/xen/xend/XendCheckpoint.py	2013-05-12 06:30:26.768147769 -0600
@@ -188,7 +188,7 @@
             dominfo.destroy()
             dominfo.testDeviceComplete()
         try:
-            dominfo.setName(domain_name, False)
+            dominfo.setName(domain_name)
         except VmError:
             # Ignore this.  The name conflict (hopefully) arises because we
             # are doing localhost migration; if we are doing a suspend of a
diff -Naur xen/tools/python/xen/xend/XendCheckpoint.py.orig xen-b/tools/python/xen/xend/XendCheckpoint.py.orig
--- xen/tools/python/xen/xend/XendCheckpoint.py.orig	1969-12-31 17:00:00.000000000 -0700
+++ xen-b/tools/python/xen/xend/XendCheckpoint.py.orig	2013-05-11 21:04:14.414814436 -0600
@@ -0,0 +1,441 @@
+# Copyright (C) 2005 Christian Limpach <Christian.Limpach@cl.cam.ac.uk>
+# Copyright (C) 2005 XenSource Ltd
+
+# This file is subject to the terms and conditions of the GNU General
+# Public License.  See the file "COPYING" in the main directory of
+# this archive for more details.
+
+import os
+import os.path
+import re
+import string
+import threading
+import fcntl
+from struct import pack, unpack, calcsize
+
+from xen.util.xpopen import xPopen3
+import xen.util.auxbin
+import xen.lowlevel.xc
+
+from xen.xend import balloon, sxp, image
+from xen.xend.XendError import XendError, VmError
+from xen.xend.XendLogging import log
+from xen.xend.XendConfig import XendConfig
+from xen.xend.XendConstants import *
+from xen.xend import XendNode
+
+SIGNATURE = "LinuxGuestRecord"
+QEMU_SIGNATURE = "QemuDeviceModelRecord"
+dm_batch = 512
+XC_SAVE = "xc_save"
+XC_RESTORE = "xc_restore"
+
+
+sizeof_int = calcsize("i")
+sizeof_unsigned_int = calcsize("I")
+sizeof_unsigned_long = calcsize("L")
+
+
+xc = xen.lowlevel.xc.xc()
+
+
+def write_exact(fd, buf, errmsg):
+    if os.write(fd, buf) != len(buf):
+        raise XendError(errmsg)
+
+
+def read_exact(fd, size, errmsg):
+    buf  = '' 
+    while size != 0: 
+        readstr = os.read(fd, size)
+        if not len(readstr):
+            log.error("read_exact: EOF trying to read %d (buf='%s')" % \
+                      (size, buf))
+            raise XendError(errmsg)
+        size = size - len(readstr)
+        buf  = buf + readstr
+    return buf
+
+
+def insert_after(list, pred, value):
+    for i,k in enumerate(list):
+        if type(k) == type([]):
+           if k[0] == pred:
+              list.insert (i+1, value)
+    return
+
+
+def save(fd, dominfo, network, live, dst, checkpoint=False, node=-1,sock=None):
+    from xen.xend import XendDomain
+
+    try:
+        if not os.path.isdir("/var/lib/xen"):
+            os.makedirs("/var/lib/xen")
+    except Exception, exn:
+        log.exception("Can't create directory '/var/lib/xen'")
+        raise XendError("Can't create directory '/var/lib/xen'")
+
+    write_exact(fd, SIGNATURE, "could not write guest state file: signature")
+
+    sxprep = dominfo.sxpr()
+
+    if node > -1:
+        insert_after(sxprep,'vcpus',['node', str(node)])
+
+    for device_sxp in sxp.children(sxprep, 'device'):
+        backend = sxp.child(device_sxp[1], 'backend')
+        if backend == None:
+            continue
+        bkdominfo = XendDomain.instance().domain_lookup_nr(backend[1])
+        if bkdominfo == None:
+            raise XendError("Could not find backend: %s" % backend[1])
+        if bkdominfo.getDomid() == XendDomain.DOM0_ID:
+            # Skip for compatibility of checkpoint data format
+            continue
+        backend[1] = bkdominfo.getName()
+        
+    config = sxp.to_string(sxprep)
+
+    domain_name = dominfo.getName()
+    # Rename the domain temporarily, so that we don't get a name clash if this
+    # domain is migrating (live or non-live) to the local host.  Doing such a
+    # thing is useful for debugging.
+    dominfo.setName('migrating-' + domain_name)
+
+    try:
+        dominfo.migrateDevices(network, dst, DEV_MIGRATE_STEP1, domain_name)
+
+        write_exact(fd, pack("!i", len(config)),
+                    "could not write guest state file: config len")
+        write_exact(fd, config, "could not write guest state file: config")
+
+        image_cfg = dominfo.info.get('image', {})
+        hvm = dominfo.info.is_hvm()
+
+        # xc_save takes three customization parameters: maxit, max_f, and
+        # flags the last controls whether or not save is 'live', while the
+        # first two further customize behaviour when 'live' save is
+        # enabled. Passing "0" simply uses the defaults compiled into
+        # libxenguest; see the comments and/or code in xc_linux_save() for
+        # more information.
+        max_iters = dominfo.info.get('max_iters', "0")
+        max_factor = dominfo.info.get('max_factor', "0")
+        min_remaining = dominfo.info.get('min_remaining', "0")
+        abort_if_busy = dominfo.info.get('abort_if_busy', "0")
+        log_save_progress = dominfo.info.get('log_save_progress', "0")
+        if max_iters == "None":
+            max_iters = "0"
+        if max_factor == "None":
+            max_factor = "0"
+        if min_remaining == "None":
+            min_remaining = "0"
+        if abort_if_busy == "None":
+            abort_if_busy = "0"
+        if log_save_progress == "None":
+            log_save_progress = "0"
+        cmd = [xen.util.auxbin.pathTo(XC_SAVE), str(fd),
+               str(dominfo.getDomid()),
+               max_iters, max_factor, min_remaining,
+               str( int(live) | (int(hvm) << 2) | (int(abort_if_busy) << 5) | (int(log_save_progress) << 6) ) ]
+        log.debug("[xc_save]: %s", string.join(cmd))
+
+        def saveInputHandler(line, tochild):
+            log.debug("In saveInputHandler %s", line)
+            if line == "suspend":
+                log.debug("Suspending %d ...", dominfo.getDomid())
+                dominfo.shutdown('suspend')
+                dominfo.waitForSuspend()
+            if line in ('suspend', 'suspended'):
+                dominfo.migrateDevices(network, dst, DEV_MIGRATE_STEP2,
+                                       domain_name)
+                log.info("Domain %d suspended.", dominfo.getDomid())
+                dominfo.migrateDevices(network, dst, DEV_MIGRATE_STEP3,
+                                       domain_name)
+                if hvm:
+                    dominfo.image.saveDeviceModel()
+
+            if line == "suspend":
+                tochild.write("done\n")
+                tochild.flush()
+                log.debug('Written done')
+
+        forkHelper(cmd, fd, saveInputHandler, False)
+
+        # put qemu device model state
+        if os.path.exists("/var/lib/xen/qemu-save.%d" % dominfo.getDomid()):
+            write_exact(fd, QEMU_SIGNATURE, "could not write qemu signature")
+            qemu_fd = os.open("/var/lib/xen/qemu-save.%d" % dominfo.getDomid(),
+                              os.O_RDONLY)
+            while True:
+                buf = os.read(qemu_fd, dm_batch)
+                if len(buf):
+                    write_exact(fd, buf, "could not write device model state")
+                else:
+                    break
+            os.close(qemu_fd)
+            os.remove("/var/lib/xen/qemu-save.%d" % dominfo.getDomid())
+
+        if checkpoint:
+            dominfo.resumeDomain()
+        else:
+            if live and sock != None:
+                try:
+                    sock.shutdown(2)
+                except:
+                    pass
+                sock.close()
+
+            dominfo.destroy()
+            dominfo.testDeviceComplete()
+        try:
+            dominfo.setName(domain_name, False)
+        except VmError:
+            # Ignore this.  The name conflict (hopefully) arises because we
+            # are doing localhost migration; if we are doing a suspend of a
+            # persistent VM, we need the rename, and don't expect the
+            # conflict.  This needs more thought.
+            pass
+
+    except Exception, exn:
+        log.exception("Save failed on domain %s (%s) - resuming.", domain_name,
+                      dominfo.getDomid())
+        dominfo.resumeDomain()
+ 
+        try:
+            dominfo.setName(domain_name)
+        except:
+            log.exception("Failed to reset the migrating domain's name")
+
+        raise exn
+
+
+def restore(xd, fd, dominfo = None, paused = False, relocating = False):
+    try:
+        if not os.path.isdir("/var/lib/xen"):
+            os.makedirs("/var/lib/xen")
+    except Exception, exn:
+        log.exception("Can't create directory '/var/lib/xen'")
+        raise XendError("Can't create directory '/var/lib/xen'")
+
+    signature = read_exact(fd, len(SIGNATURE),
+        "not a valid guest state file: signature read")
+    if signature != SIGNATURE:
+        raise XendError("not a valid guest state file: found '%s'" %
+                        signature)
+
+    l = read_exact(fd, sizeof_int,
+                   "not a valid guest state file: config size read")
+    vmconfig_size = unpack("!i", l)[0]
+    vmconfig_buf = read_exact(fd, vmconfig_size,
+        "not a valid guest state file: config read")
+
+    p = sxp.Parser()
+    p.input(vmconfig_buf)
+    if not p.ready:
+        raise XendError("not a valid guest state file: config parse")
+
+    vmconfig = p.get_val()
+
+    if not relocating:
+        domconfig = XendConfig(sxp_obj = vmconfig)
+        othervm = xd.domain_lookup_nr(domconfig["name_label"])
+        if othervm is None or othervm.domid is None:
+            othervm = xd.domain_lookup_nr(domconfig["uuid"])
+        if othervm is not None and othervm.domid is not None: 
+            raise VmError("Domain '%s' already exists with ID '%d'" % (domconfig["name_label"], othervm.domid))
+
+    if dominfo:
+        dominfo.resume()
+    else:
+        dominfo = xd.restore_(vmconfig)
+
+    image_cfg = dominfo.info.get('image', {})
+    is_hvm = dominfo.info.is_hvm()
+
+    if is_hvm:
+        nomigrate = dominfo.info['platform'].get('nomigrate', 0)
+    else:
+        nomigrate = dominfo.info['platform'].get('nomigrate')
+        if nomigrate is None:
+            nomigrate = 0
+    if int(nomigrate) != 0:
+        dominfo.destroy()
+        raise XendError("cannot restore non-migratable domain")
+
+    store_port   = dominfo.getStorePort()
+    console_port = dominfo.getConsolePort()
+
+    # if hvm, pass mem size to calculate the store_mfn
+    if is_hvm:
+        apic = int(dominfo.info['platform'].get('apic', 0))
+        pae  = int(dominfo.info['platform'].get('pae',  0))
+        log.info("restore hvm domain %d, apic=%d, pae=%d",
+                 dominfo.domid, apic, pae)
+    else:
+        apic = 0
+        pae  = 0
+
+    try:
+        assert store_port
+        assert console_port
+
+        restore_image = image.create(dominfo, dominfo.info)
+        memory = restore_image.getRequiredAvailableMemory(
+            dominfo.info['memory_dynamic_max'] / 1024)
+        maxmem = restore_image.getRequiredAvailableMemory(
+            dominfo.info['memory_static_max'] / 1024)
+        shadow = restore_image.getRequiredShadowMemory(
+            dominfo.info['shadow_memory'] * 1024,
+            dominfo.info['memory_static_max'] / 1024)
+
+        log.debug("restore:shadow=0x%x, _static_max=0x%x, _static_min=0x%x, ",
+                  dominfo.info['shadow_memory'],
+                  dominfo.info['memory_static_max'],
+                  dominfo.info['memory_static_min'])
+
+        # Round shadow up to a multiple of a MiB, as shadow_mem_control
+        # takes MiB and we must not round down and end up under-providing.
+        shadow = ((shadow + 1023) / 1024) * 1024
+
+        # set memory limit
+        xc.domain_setmaxmem(dominfo.getDomid(), maxmem)
+
+        vtd_mem = 0
+        info = xc.physinfo()
+        if 'hvm_directio' in info['virt_caps']:
+            # Reserve 1 page per MiB of RAM for separate VT-d page table.
+            vtd_mem = 4 * (dominfo.info['memory_static_max'] / 1024 / 1024)
+            # Round vtd_mem up to a multiple of a MiB.
+            vtd_mem = ((vtd_mem + 1023) / 1024) * 1024
+
+        balloon.free(memory + shadow + vtd_mem, dominfo)
+
+        shadow_cur = xc.shadow_mem_control(dominfo.getDomid(), shadow / 1024)
+        dominfo.info['shadow_memory'] = shadow_cur
+
+        superpages = restore_image.superpages
+
+        cmd = map(str, [xen.util.auxbin.pathTo(XC_RESTORE),
+                        fd, dominfo.getDomid(),
+                        store_port, console_port, int(is_hvm), pae, apic, superpages])
+        log.debug("[xc_restore]: %s", string.join(cmd))
+
+        handler = RestoreInputHandler()
+
+        forkHelper(cmd, fd, handler.handler, True)
+
+        # We don't want to pass this fd to any other children -- we 
+        # might need to recover the disk space that backs it.
+        try:
+            flags = fcntl.fcntl(fd, fcntl.F_GETFD)
+            flags |= fcntl.FD_CLOEXEC
+            fcntl.fcntl(fd, fcntl.F_SETFD, flags)
+        except:
+            pass
+
+        if handler.store_mfn is None:
+            raise XendError('Could not read store MFN')
+
+        if not is_hvm and handler.console_mfn is None:
+            raise XendError('Could not read console MFN')        
+
+        restore_image.setCpuid()
+
+        # xc_restore will wait for source to close connection
+        
+        dominfo.completeRestore(handler.store_mfn, handler.console_mfn)
+
+        #
+        # We shouldn't hold the domains_lock over a waitForDevices
+        # As this function sometime gets called holding this lock,
+        # we must release it and re-acquire it appropriately
+        #
+        from xen.xend import XendDomain
+
+        lock = True;
+        try:
+            XendDomain.instance().domains_lock.release()
+        except:
+            lock = False;
+
+        try:
+            dominfo.waitForDevices() # Wait for backends to set up
+        finally:
+            if lock:
+                XendDomain.instance().domains_lock.acquire()
+
+        if not paused:
+            dominfo.unpause()
+
+        return dominfo
+    except Exception, exn:
+        dominfo.destroy()
+        log.exception(exn)
+        raise exn
+
+
+class RestoreInputHandler:
+    def __init__(self):
+        self.store_mfn = None
+        self.console_mfn = None
+
+
+    def handler(self, line, _):
+        m = re.match(r"^(store-mfn) (\d+)$", line)
+        if m:
+            self.store_mfn = int(m.group(2))
+        else:
+            m = re.match(r"^(console-mfn) (\d+)$", line)
+            if m:
+                self.console_mfn = int(m.group(2))
+
+
+def forkHelper(cmd, fd, inputHandler, closeToChild):
+    child = xPopen3(cmd, True, -1, [fd])
+
+    if closeToChild:
+        child.tochild.close()
+
+    thread = threading.Thread(target = slurp, args = (child.childerr,))
+    thread.start()
+
+    try:
+        try:
+            while 1:
+                line = child.fromchild.readline()
+                if line == "":
+                    break
+                else:
+                    line = line.rstrip()
+                    log.debug('%s', line)
+                    inputHandler(line, child.tochild)
+
+        except IOError, exn:
+            raise XendError('Error reading from child process for %s: %s' %
+                            (cmd, exn))
+    finally:
+        child.fromchild.close()
+        if not closeToChild:
+            child.tochild.close()
+        thread.join()
+        child.childerr.close()
+        status = child.wait()
+
+    if status >> 8 == 127:
+        raise XendError("%s failed: popen failed" % string.join(cmd))
+    elif status != 0:
+        raise XendError("%s failed" % string.join(cmd))
+
+
+def slurp(infile):
+    while 1:
+        line = infile.readline()
+        if line == "":
+            break
+        else:
+            line = line.strip()
+            m = re.match(r"^ERROR: (.*)", line)
+            if m is None:
+                log.info('%s', line)
+            else:
+                log.error('%s', m.group(1))
diff -Naur xen/tools/python/xen/xend/XendConfig.py xen-b/tools/python/xen/xend/XendConfig.py
--- xen/tools/python/xen/xend/XendConfig.py	2013-05-08 21:21:22.264814435 -0600
+++ xen-b/tools/python/xen/xend/XendConfig.py	2013-05-12 06:30:26.768147769 -0600
@@ -147,6 +147,9 @@
     'apic': int,
     'boot': str,
     'device_model': str,
+    'actmem': str,
+    'xenpaging_file': str,
+    'xenpaging_extra': str,
     'loader': str,
     'display' : str,
     'fda': str,
@@ -159,6 +162,7 @@
     'nographic': int,
     'nomigrate': int,
     'pae' : int,
+    'extid': int,
     'rtc_timeoffset': int,
     'parallel': str,
     'serial': str,
@@ -192,6 +196,8 @@
     'xen_platform_pci': int,
     "gfx_passthru": int,
     'oos' : int,
+    'watchdog': str,
+    'watchdog_action': str,
 }
 
 # Xen API console 'other_config' keys.
@@ -512,8 +518,16 @@
             self['platform']['nomigrate'] = 0
 
         if self.is_hvm():
+            if 'actmem' not in self['platform']:
+                self['platform']['actmem'] = "0"
+            if 'xenpaging_file' not in self['platform']:
+                self['platform']['xenpaging_file'] = ""
+            if 'xenpaging_extra' not in self['platform']:
+                self['platform']['xenpaging_extra'] = []
             if 'timer_mode' not in self['platform']:
                 self['platform']['timer_mode'] = 1
+            if 'extid' in self['platform'] and int(self['platform']['extid']) == 1:
+                self['platform']['viridian'] = 1
             if 'viridian' not in self['platform']:
                 self['platform']['viridian'] = 0
             if 'rtc_timeoffset' not in self['platform']:
@@ -1865,7 +1879,14 @@
         ports = sxp.child(dev_sxp, 'port')
         for port in ports[1:]:
             try:
-                num, bus = port
+                # When ['port' ['1','']] is saved into sxp file, it will become (port (1 ))
+                # If using this sxp file, here variable "port" will be port=1,
+                # we should process it, otherwise, it will report error.
+                if len(port) == 1:
+                    num = port[0]
+                    bus = ""
+                else:
+                    num, bus = port
                 dev_config['port-%i' % int(num)] = str(bus)
             except TypeError:
                 pass
diff -Naur xen/tools/python/xen/xend/XendDomain.py xen-b/tools/python/xen/xend/XendDomain.py
--- xen/tools/python/xen/xend/XendDomain.py	2013-05-11 21:04:14.414814436 -0600
+++ xen-b/tools/python/xen/xend/XendDomain.py	2013-05-12 06:30:26.771481103 -0600
@@ -1505,7 +1505,7 @@
                     pass
                 sock.close()
 
-    def domain_save(self, domid, dst, checkpoint=False):
+    def domain_save(self, domid, dst, checkpoint=False, force=False):
         """Start saving a domain to file.
 
         @param domid: Domain ID or Name
@@ -1521,6 +1521,9 @@
             if not dominfo:
                 raise XendInvalidDomain(str(domid))
 
+            if os.access(dst, os.F_OK) and not force:
+                raise XendError("Save file:%s exist!\n" % dst)
+
             if dominfo.getDomid() == DOM0_ID:
                 raise XendError("Cannot save privileged domain %s" % str(domid))
             if dominfo._stateGet() != DOM_STATE_RUNNING:
@@ -1846,6 +1849,21 @@
             raise XendInvalidDomain(str(domid))
         dominfo.setMigrateConstraints(max_iters, max_factor, min_remaining, abort_if_busy, log_save_progress)
 
+    def domain_swaptarget_set(self, domid, mem):
+        """Set the memory limit for a domain.
+
+        @param domid: Domain ID or Name
+        @type domid: int or string.
+        @param mem: memory limit (in MiB)
+        @type mem: int
+        @raise XendError: fail to set memory
+        @rtype: 0
+        """
+        dominfo = self.domain_lookup_nr(domid)
+        if not dominfo:
+            raise XendInvalidDomain(str(domid))
+        dominfo.setSwapTarget(mem)
+
     def domain_maxmem_set(self, domid, mem):
         """Set the memory limit for a domain.
 
diff -Naur xen/tools/python/xen/xend/XendDomain.py.orig xen-b/tools/python/xen/xend/XendDomain.py.orig
--- xen/tools/python/xen/xend/XendDomain.py.orig	1969-12-31 17:00:00.000000000 -0700
+++ xen-b/tools/python/xen/xend/XendDomain.py.orig	2013-05-11 21:04:14.414814436 -0600
@@ -0,0 +1,1972 @@
+#============================================================================
+# This library is free software; you can redistribute it and/or
+# modify it under the terms of version 2.1 of the GNU Lesser General Public
+# License as published by the Free Software Foundation.
+#
+# This library is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+# Lesser General Public License for more details.
+#
+# You should have received a copy of the GNU Lesser General Public
+# License along with this library; if not, write to the Free Software
+# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+#============================================================================
+# Copyright (C) 2004, 2005 Mike Wray <mike.wray@hp.com>
+# Copyright (C) 2005 Christian Limpach <Christian.Limpach@cl.cam.ac.uk>
+# Copyright (C) 2005 XenSource Ltd
+#============================================================================
+
+"""Handler for domain operations.
+ Nothing here is persistent (across reboots).
+ Needs to be persistent for one uptime.
+"""
+
+import os
+import stat
+import shutil
+import socket
+import tempfile
+import threading
+import re
+
+import xen.lowlevel.xc
+
+
+from xen.xend import XendOptions, XendCheckpoint, XendDomainInfo
+from xen.xend.PrettyPrint import prettyprint
+from xen.xend import XendConfig, image
+from xen.xend.XendError import XendError, XendInvalidDomain, VmError
+from xen.xend.XendError import VMBadState
+from xen.xend.XendLogging import log
+from xen.xend.XendAPIConstants import XEN_API_VM_POWER_STATE
+from xen.xend.XendConstants import XS_VMROOT
+from xen.xend.XendConstants import DOM_STATE_HALTED, DOM_STATE_PAUSED
+from xen.xend.XendConstants import DOM_STATE_RUNNING, DOM_STATE_SUSPENDED
+from xen.xend.XendConstants import DOM_STATE_SHUTDOWN, DOM_STATE_UNKNOWN
+from xen.xend.XendConstants import DOM_STATE_CRASHED, HVM_PARAM_ACPI_S_STATE
+from xen.xend.XendConstants import TRIGGER_TYPE, TRIGGER_S3RESUME
+from xen.xend.XendDevices import XendDevices
+from xen.xend.XendAPIConstants import *
+
+from xen.xend.xenstore.xstransact import xstransact
+from xen.xend.xenstore.xswatch import xswatch
+from xen.util import mkdir, rwlock
+from xen.xend import uuid
+
+xc = xen.lowlevel.xc.xc()
+xoptions = XendOptions.instance() 
+
+__all__ = [ "XendDomain" ]
+
+CACHED_CONFIG_FILE = 'config.sxp'
+CHECK_POINT_FILE = 'checkpoint.chk'
+DOM0_UUID = "00000000-0000-0000-0000-000000000000"
+DOM0_NAME = "Domain-0"
+DOM0_ID   = 0
+
+POWER_STATE_NAMES = dict([(x, XEN_API_VM_POWER_STATE[x])
+                          for x in [DOM_STATE_HALTED,
+                                    DOM_STATE_PAUSED,
+                                    DOM_STATE_RUNNING,
+                                    DOM_STATE_SUSPENDED,
+                                    DOM_STATE_SHUTDOWN,
+                                    DOM_STATE_CRASHED,
+                                    DOM_STATE_UNKNOWN]])
+POWER_STATE_ALL = 'all'
+
+
+class XendDomain:
+    """Index of all domains. Singleton.
+
+    @ivar domains: map of domains indexed by domid
+    @type domains: dict of XendDomainInfo
+    @ivar managed_domains: domains that are not running and managed by Xend
+    @type managed_domains: dict of XendDomainInfo indexed by uuid
+    @ivar domains_lock: lock that must be held when manipulating self.domains
+    @type domains_lock: threaading.RLock
+    @ivar _allow_new_domains: Flag to set that allows creating of new domains.
+    @type _allow_new_domains: boolean
+    """
+
+    def __init__(self):
+        self.domains = {}
+        self.managed_domains = {}
+        self.domains_lock = threading.RLock()
+
+        self.policy_lock = rwlock.RWLock()
+
+        # xen api instance vars
+        # TODO: nothing uses this at the moment
+        self._allow_new_domains = True
+
+    # This must be called only the once, by instance() below.  It is separate
+    # from the constructor because XendDomainInfo calls back into this class
+    # in order to check the uniqueness of domain names.  This means that
+    # instance() must be able to return a valid instance of this class even
+    # during this initialisation.
+    def init(self):
+        """Singleton initialisation function."""
+
+        dom_path = self._managed_path()
+        mkdir.parents(dom_path, stat.S_IRWXU)
+
+        xstransact.Mkdir(XS_VMROOT)
+        xstransact.SetPermissions(XS_VMROOT, {'dom': DOM0_ID})
+
+        self.domains_lock.acquire()
+        try:
+            try:
+                dom0info = [d for d in self._running_domains() \
+                            if d.get('domid') == DOM0_ID][0]
+                
+                dom0info['name'] = DOM0_NAME
+                dom0 = XendDomainInfo.recreate(dom0info, True)
+            except IndexError:
+                raise XendError('Unable to find Domain 0')
+            
+            self._setDom0CPUCount()
+
+            # This watch registration needs to be before the refresh call, so
+            # that we're sure that we haven't missed any releases, but inside
+            # the domains_lock, as we don't want the watch to fire until after
+            # the refresh call has completed.
+            xswatch("@introduceDomain", self._on_domains_changed)
+            xswatch("@releaseDomain",   self._on_domains_changed)
+
+            self._init_domains()
+        finally:
+            self.domains_lock.release()
+
+    
+    def _on_domains_changed(self, _):
+        """ Callback method when xenstore changes.
+
+        Calls refresh which will keep the local cache of domains
+        in sync.
+
+        @rtype: int
+        @return: 1
+        """
+        self.domains_lock.acquire()
+        try:
+            self._refresh()
+        finally:
+            self.domains_lock.release()
+        return 1
+
+    def _init_domains(self):
+        """Does the initial scan of managed and active domains to
+        populate self.domains.
+
+        Note: L{XendDomainInfo._checkName} will call back into XendDomain
+        to make sure domain name is not a duplicate.
+
+        """
+        self.domains_lock.acquire()
+        try:
+            running = self._running_domains()
+            managed = self._managed_domains()
+
+            # add all active domains
+            for dom in running:
+                if dom['dying'] == 1:
+                    log.warn('Ignoring dying domain %d from now on' %
+                             dom['domid'])
+                    continue
+
+                if dom['domid'] != DOM0_ID:
+                    try:
+                        new_dom = XendDomainInfo.recreate(dom, False)
+                    except Exception:
+                        log.exception("Failed to create reference to running "
+                                      "domain id: %d" % dom['domid'])
+
+            image.cleanup_stale_sentinel_fifos()
+
+            # add all managed domains as dormant domains.
+            for dom in managed:
+                dom_uuid = dom.get('uuid')
+                if not dom_uuid:
+                    continue
+                
+                dom_name = dom.get('name_label', 'Domain-%s' % dom_uuid)
+                try:
+                    running_dom = self.domain_lookup_nr(dom_name)
+                    if not running_dom:
+                        # instantiate domain if not started.
+                        new_dom = XendDomainInfo.createDormant(dom)
+                        self._managed_domain_register(new_dom)
+                    else:
+                        self._managed_domain_register(running_dom)
+                        for key in XendConfig.XENAPI_CFG_TYPES.keys():
+                            if key not in XendConfig.LEGACY_XENSTORE_VM_PARAMS and \
+                                   key in dom:
+                                running_dom.info[key] = dom[key]
+                        # Devices information is restored from xenstore,
+                        # but VDI value in devices information can be not
+                        # restored because there is not VDI value in
+                        # xenstore. So we restore VDI value by using the
+                        # domain config file.
+                        for vbd_ref in running_dom.info['vbd_refs']:
+                            if dom['devices'].has_key(vbd_ref):
+                                r_devtype, r_devinfo = running_dom.info['devices'][vbd_ref]
+                                _, m_devinfo = dom['devices'][vbd_ref]
+                                r_devinfo['VDI'] = m_devinfo.get('VDI', '')
+                                running_dom.info['devices'][vbd_ref] = (r_devtype, r_devinfo)
+                except Exception:
+                    log.exception("Failed to create reference to managed "
+                                  "domain: %s" % dom_name)
+
+        finally:
+            self.domains_lock.release()
+
+
+    # -----------------------------------------------------------------
+    # Getting managed domains storage path names
+
+    def _managed_path(self, domuuid = None):
+        """Returns the path of the directory where managed domain
+        information is stored.
+
+        @keyword domuuid: If not None, will return the path to the domain
+                          otherwise, will return the path containing
+                          the directories which represent each domain.
+        @type: None or String.
+        @rtype: String
+        @return: Path.
+        """
+        dom_path = xoptions.get_xend_domains_path()
+        if domuuid:
+            dom_path = os.path.join(dom_path, domuuid)
+        return dom_path
+
+    def _managed_config_path(self, domuuid):
+        """Returns the path to the configuration file of a managed domain.
+
+        @param domname: Domain uuid
+        @type domname: String
+        @rtype: String
+        @return: path to config file.
+        """
+        return os.path.join(self._managed_path(domuuid), CACHED_CONFIG_FILE)
+    def domain_setpauseflag(self, dom, flag=False):
+        try:
+            dominfo = self.domain_lookup_nr(dom)
+            dominfo.paused_by_admin = flag
+        except Exception, err:
+            log.debug("error in in setpauseflag")
+    def domain_getpauseflag(self, dom):
+        try:
+            dominfo = self.domain_lookup_nr(dom)
+            return dominfo.paused_by_admin
+        except Exception, err:
+            log.debug("error in in getpauseflag")
+
+    def _managed_check_point_path(self, domuuid):
+        """Returns absolute path to check point file for managed domain.
+        
+        @param domuuid: Name of managed domain
+        @type domname: String
+        @rtype: String
+        @return: Path
+        """
+        return os.path.join(self._managed_path(domuuid), CHECK_POINT_FILE)
+
+    def _managed_config_remove(self, domuuid):
+        """Removes a domain configuration from managed list
+
+        @param domuuid: Name of managed domain
+        @type domname: String
+        @raise XendError: fails to remove the domain.
+        """
+        config_path = self._managed_path(domuuid)
+        try:
+            if os.path.exists(config_path) and os.path.isdir(config_path):
+                shutil.rmtree(config_path)
+        except IOError:
+            log.exception('managed_config_remove failed removing conf')
+            raise XendError("Unable to remove managed configuration"
+                            " for domain: %s" % domuuid)            
+
+    def managed_config_save(self, dominfo):
+        """Save a domain's configuration to disk
+        
+        @param domninfo: Managed domain to save.
+        @type dominfo: XendDomainInfo
+        @raise XendError: fails to save configuration.
+        @rtype: None
+        """
+        if not self.is_domain_managed(dominfo):
+            return # refuse to save configuration this domain isn't managed
+        
+        if dominfo:
+            domains_dir = self._managed_path()
+            dom_uuid = dominfo.get_uuid()            
+            domain_config_dir = self._managed_path(dom_uuid)
+
+            def make_or_raise(path):
+                try:
+                    mkdir.parents(path, stat.S_IRWXU)
+                except:
+                    log.exception("%s could not be created." % path)
+                    raise XendError("%s could not be created." % path)
+
+            make_or_raise(domains_dir)
+            make_or_raise(domain_config_dir)
+
+            try:
+                fd, fn = tempfile.mkstemp()
+                f = os.fdopen(fd, 'w+b')
+                try:
+                    prettyprint(dominfo.sxpr(legacy_only = False), f,
+                                width = 78)
+                finally:
+                    f.close()
+                    
+                try:
+                    shutil.move(fn, self._managed_config_path(dom_uuid))
+                except:
+                    log.exception("Renaming %s to %s", fn,
+                                  self._managed_config_path(dom_uuid))
+                    os.remove(fn)
+            except:
+                log.exception("Error occurred saving configuration file " +
+                              "to %s" % domain_config_dir)
+                raise XendError("Failed to save configuration file to: %s" %
+                                domain_config_dir)
+        else:
+            log.warn("Trying to save configuration for invalid domain")
+
+
+    def _managed_domains(self):
+        """ Returns list of domains that are managed.
+        
+        Expects to be protected by domains_lock.
+
+        @rtype: list of XendConfig
+        @return: List of domain configurations that are managed.
+        """
+        dom_path = self._managed_path()
+        dom_uuids = os.listdir(dom_path)
+        doms = []
+        for dom_uuid in dom_uuids:
+            try:
+                cfg_file = self._managed_config_path(dom_uuid)
+                cfg = XendConfig.XendConfig(filename = cfg_file)
+                if cfg.get('uuid') != dom_uuid:
+                    # something is wrong with the SXP
+                    log.error("UUID mismatch in stored configuration: %s" %
+                              cfg_file)
+                    continue
+                doms.append(cfg)
+            except Exception:
+                log.exception('Unable to open or parse config.sxp: %s' % \
+                              cfg_file)
+        return doms
+
+    def _managed_domain_unregister(self, dom):
+        try:
+            if self.is_domain_managed(dom):
+                self._managed_config_remove(dom.get_uuid())
+                del self.managed_domains[dom.get_uuid()]
+                dom.destroy_xapi_instances()
+        except ValueError:
+            log.warn("Domain is not registered: %s" % dom.get_uuid())
+
+    def _managed_domain_register(self, dom):
+        self.managed_domains[dom.get_uuid()] = dom
+
+    def is_domain_managed(self, dom = None):
+        return (dom.get_uuid() in self.managed_domains)
+
+    # End of Managed Domain Access
+    # --------------------------------------------------------------------
+
+    def _running_domains(self):
+        """Get table of domains indexed by id from xc.
+
+        @requires: Expects to be protected by domains_lock.
+        @rtype: list of dicts
+        @return: A list of dicts representing the running domains.
+        """
+        try:
+            return xc.domain_getinfo()
+        except RuntimeError, e:
+            log.exception("Unable to get domain information.")
+            return {}
+
+    def _setDom0CPUCount(self):
+        """Sets the number of VCPUs dom0 has. Retreived from the
+        Xend configuration, L{XendOptions}.
+
+        @requires: Expects to be protected by domains_lock.
+        @rtype: None
+        """
+        dom0 = self.privilegedDomain()
+
+        # get max number of vcpus to use for dom0 from config
+        target = int(xoptions.get_dom0_vcpus())
+        log.debug("number of vcpus to use is %d", target)
+   
+        # target == 0 means use all processors
+        if target > 0:
+            dom0.setVCpuCount(target)
+
+
+    def _refresh(self, refresh_shutdown = True):
+        """Refresh the domain list. Needs to be called when
+        either xenstore has changed or when a method requires
+        up to date information (like uptime, cputime stats).
+
+        Expects to be protected by the domains_lock.
+
+        @rtype: None
+        """
+
+        txn = xstransact()
+        try:
+            self._refreshTxn(txn, refresh_shutdown)
+            txn.commit()
+        except:
+            txn.abort()
+            raise
+
+    def _refreshTxn(self, transaction, refresh_shutdown):
+        running = self._running_domains()
+        # Add domains that are not already tracked but running in Xen,
+        # and update domain state for those that are running and tracked.
+        for dom in running:
+            domid = dom['domid']
+            if domid in self.domains:
+                self.domains[domid].update(dom, refresh_shutdown, transaction)
+            elif domid not in self.domains and dom['dying'] != 1:
+                try:
+                    new_dom = XendDomainInfo.recreate(dom, False)
+                except VmError:
+                    log.exception("Unable to recreate domain")
+                    try:
+                        xc.domain_pause(domid)
+                        XendDomainInfo.do_FLR(domid, dom['hvm'])
+                        xc.domain_destroy(domid)
+                    except:
+                        log.exception("Hard destruction of domain failed: %d" %
+                                      domid)
+
+        # update information for all running domains
+        # - like cpu_time, status, dying, etc.
+        # remove domains that are not running from active domain list.
+        # The list might have changed by now, because the update call may
+        # cause new domains to be added, if the domain has rebooted.  We get
+        # the list again.
+        running = self._running_domains()
+        running_domids = [d['domid'] for d in running if d['dying'] != 1]
+        for domid, dom in self.domains.items():
+            if domid not in running_domids and domid != DOM0_ID:
+                self._remove_domain(dom, domid)
+
+
+    def add_domain(self, info):
+        """Add a domain to the list of running domains
+        
+        @requires: Expects to be protected by the domains_lock.
+        @param info: XendDomainInfo of a domain to be added.
+        @type info: XendDomainInfo
+        """
+        log.debug("Adding Domain: %s" % info.getDomid())
+        self.domains[info.getDomid()] = info
+        
+        # update the managed domains with a new XendDomainInfo object
+        # if we are keeping track of it.
+        if info.get_uuid() in self.managed_domains:
+            self._managed_domain_register(info)
+
+    def remove_domain(self, info, domid = None):
+        """Remove the domain from the list of running domains, taking the
+        domains_lock first.
+        """
+        self.domains_lock.acquire()
+        try:
+            self._remove_domain(info, domid)
+        finally:
+            self.domains_lock.release()
+
+    def _remove_domain(self, info, domid = None):
+        """Remove the domain from the list of running domains
+        
+        @requires: Expects to be protected by the domains_lock.
+        @param info: XendDomainInfo of a domain to be removed.
+        @type info: XendDomainInfo
+        """
+        if info:
+            if domid == None:
+                domid = info.getDomid()
+
+            if info._stateGet() != DOM_STATE_HALTED:
+                info.cleanupDomain()
+            
+            if domid in self.domains:
+                del self.domains[domid]
+
+            info.destroy_xapi_instances()
+        else:
+            log.warning("Attempted to remove non-existent domain.")
+
+    def restore_(self, config):
+        """Create a domain as part of the restore process.  This is called
+        only from L{XendCheckpoint}.
+
+        A restore request comes into XendDomain through L{domain_restore}
+        or L{domain_restore_fd}.  That request is
+        forwarded immediately to XendCheckpoint which, when it is ready, will
+        call this method.  It is necessary to come through here rather than go
+        directly to L{XendDomainInfo.restore} because we need to
+        serialise the domain creation process, but cannot lock
+        domain_restore_fd as a whole, otherwise we will deadlock waiting for
+        the old domain to die.
+
+        @param config: Configuration of domain to restore
+        @type config: SXP Object (eg. list of lists)
+        """
+        self.domains_lock.acquire()
+        try:
+            dominfo = XendDomainInfo.restore(config)
+            return dominfo
+        finally:
+            self.domains_lock.release()
+
+
+    def domain_lookup(self, domid):
+        """Look up given I{domid} in the list of managed and running
+        domains.
+        
+        @note: Will cause a refresh before lookup up domains, for
+               a version that does not need to re-read xenstore
+               use L{domain_lookup_nr}.
+
+        @param domid: Domain ID or Domain Name.
+        @type domid: int or string
+        @return: Found domain.
+        @rtype: XendDomainInfo
+        @raise XendInvalidDomain: If domain is not found.
+        """
+        self.domains_lock.acquire()
+        try:
+            self._refresh(refresh_shutdown = False)
+            dom = self.domain_lookup_nr(domid)
+            if not dom:
+                raise XendInvalidDomain(str(domid))
+            return dom
+        finally:
+            self.domains_lock.release()
+
+
+    def domain_lookup_nr(self, domid):
+        """Look up given I{domid} in the list of managed and running
+        domains.
+
+        @param domid: Domain ID or Domain Name.
+        @type domid: int or string
+        @return: Found domain.
+        @rtype: XendDomainInfo or None
+        """
+        self.domains_lock.acquire()
+        try:
+            # lookup by name
+            match = [dom for dom in self.domains.values() \
+                     if dom.getName() == domid]
+            if match:
+                return match[0]
+
+            match = [dom for dom in self.managed_domains.values() \
+                     if dom.getName() == domid]
+            if match:
+                return match[0]
+
+            # lookup by id
+            try:
+                if int(domid) in self.domains:
+                    return self.domains[int(domid)]
+            except ValueError:
+                pass
+
+            # lookup by uuid for running domains
+            match = [dom for dom in self.domains.values() \
+                     if dom.get_uuid() == domid]
+            if match:
+                return match[0]
+
+            # lookup by uuid for inactive managed domains 
+            if domid in self.managed_domains:
+                return self.managed_domains[domid]
+
+            return None
+        finally:
+            self.domains_lock.release()
+
+    def privilegedDomain(self):
+        """ Get the XendDomainInfo of a dom0
+
+        @rtype: XendDomainInfo
+        """
+        self.domains_lock.acquire()
+        try:
+            return self.domains[DOM0_ID]
+        finally:
+            self.domains_lock.release()
+
+    def autostart_domains(self):
+        """ Autostart managed domains that are marked as such. """
+
+        need_starting = []
+        
+        self.domains_lock.acquire()
+        try:
+            for dom_uuid, dom in self.managed_domains.items():
+                if dom and dom._stateGet() == DOM_STATE_HALTED:
+                    on_xend_start = dom.info.get('on_xend_start', 'ignore')
+                    auto_power_on = dom.info.get('auto_power_on', False)
+                    should_start = (on_xend_start == 'start') or auto_power_on
+                    if should_start:
+                        need_starting.append(dom_uuid)
+        finally:
+            self.domains_lock.release()
+
+        for dom_uuid in need_starting:
+            self.domain_start(dom_uuid, False)
+
+    def cleanup_domains(self):
+        """Clean up domains that are marked as autostop.
+        Should be called when Xend goes down. This is currently
+        called from L{xen.xend.servers.XMLRPCServer}.
+
+        """
+        log.debug('cleanup_domains')
+        self.domains_lock.acquire()
+        try:
+            for dom in self.domains.values():
+                if dom.getName() == DOM0_NAME:
+                    continue
+                
+                try:
+                    if dom._stateGet() == DOM_STATE_RUNNING:
+                        shutdownAction = dom.info.get('on_xend_stop', 'ignore')
+                        if shutdownAction == 'shutdown':
+                            log.debug('Shutting down domain: %s' % dom.getName())
+                            dom.shutdown("poweroff")
+                        elif shutdownAction == 'suspend':
+                            self.domain_suspend(dom.getName())
+                        else:
+                            log.debug('Domain %s continues to run.' % dom.getName())
+                except:
+                    log.exception('Domain %s failed to %s.' % \
+                                  (dom.getName(), shutdownAction))
+        finally:
+            self.domains_lock.release()
+
+
+
+    # ----------------------------------------------------------------
+    # Xen API 
+    
+
+    def set_allow_new_domains(self, allow_new_domains):
+        self._allow_new_domains = allow_new_domains
+
+    def allow_new_domains(self):
+        return self._allow_new_domains
+
+    def get_domain_refs(self):
+        result = []
+        try:
+            self.domains_lock.acquire()
+            result = [d.get_uuid() for d in self.domains.values()]
+            for d in self.managed_domains.keys():
+                if d not in result:
+                    result.append(d)
+            return result
+        finally:
+            self.domains_lock.release()
+
+    def get_all_vms(self):
+        self.domains_lock.acquire()
+        try:
+            result = self.domains.values()
+            result += [x for x in self.managed_domains.values() if
+                       x not in result]
+            return result
+        finally:
+            self.domains_lock.release()
+
+    def get_vm_by_uuid(self, vm_uuid):
+        self.domains_lock.acquire()
+        try:
+            for dom in self.domains.values():
+                if dom.get_uuid() == vm_uuid:
+                    return dom
+
+            if vm_uuid in self.managed_domains:
+                return self.managed_domains[vm_uuid]
+
+            return None
+        finally:
+            self.domains_lock.release()
+
+    def get_vm_with_dev_uuid(self, klass, dev_uuid):
+        self.domains_lock.acquire()
+        try:
+            for dom in self.domains.values() + self.managed_domains.values():
+                if dom.has_device(klass, dev_uuid):
+                    return dom
+            return None
+        finally:
+            self.domains_lock.release()
+
+    def get_dev_property_by_uuid(self, klass, dev_uuid, field):
+        value = None
+        self.domains_lock.acquire()
+
+        try:
+            try:
+                dom = self.get_vm_with_dev_uuid(klass, dev_uuid)
+                if dom:
+                    value = dom.get_dev_property(klass, dev_uuid, field)
+            except ValueError, e:
+                pass
+        finally:
+            self.domains_lock.release()
+        
+        return value
+
+    def set_dev_property_by_uuid(self, klass, dev_uuid, field, value,
+                                 old_val = None):
+        rc = True
+        self.domains_lock.acquire()
+
+        try:
+            try:
+                dom = self.get_vm_with_dev_uuid(klass, dev_uuid)
+                if dom:
+                    o_val = dom.get_dev_property(klass, dev_uuid, field)
+                    log.info("o_val=%s, old_val=%s" % (o_val, old_val))
+                    if old_val and old_val != o_val:
+                        return False
+
+                    dom.set_dev_property(klass, dev_uuid, field, value)
+                    self.managed_config_save(dom)
+            except ValueError, e:
+                pass
+        finally:
+            self.domains_lock.release()
+
+        return rc
+
+    def is_valid_vm(self, vm_ref):
+        return (self.get_vm_by_uuid(vm_ref) != None)
+
+    def is_valid_dev(self, klass, dev_uuid):
+        return (self.get_vm_with_dev_uuid(klass, dev_uuid) != None)
+
+    def do_legacy_api_with_uuid(self, fn, vm_uuid, *args, **kwargs):
+        dom = self.uuid_to_dom(vm_uuid)
+        fn(dom, *args, **kwargs)
+
+    def uuid_to_dom(self, vm_uuid):
+        self.domains_lock.acquire()
+        try:
+            for domid, dom in self.domains.items():
+                if dom.get_uuid() == vm_uuid:
+                    return domid
+                    
+            if vm_uuid in self.managed_domains:
+                domid = self.managed_domains[vm_uuid].getDomid()
+                if domid is None:
+                    return self.managed_domains[vm_uuid].getName()
+                else:
+                    return domid
+            
+            raise XendInvalidDomain(vm_uuid)
+        finally:
+            self.domains_lock.release()
+        
+
+    def create_domain(self, xenapi_vm):
+        self.domains_lock.acquire()
+        try:
+            try:
+                xeninfo = XendConfig.XendConfig(xapi = xenapi_vm)
+                dominfo = XendDomainInfo.createDormant(xeninfo)
+                log.debug("Creating new managed domain: %s: %s" %
+                          (dominfo.getName(), dominfo.get_uuid()))
+                self._managed_domain_register(dominfo)
+                self.managed_config_save(dominfo)
+                return dominfo.get_uuid()
+            except XendError, e:
+                raise
+            except Exception, e:
+                raise XendError(str(e))
+        finally:
+            self.domains_lock.release()        
+
+    def rename_domain(self, dom, new_name):
+        self.domains_lock.acquire()
+        try:
+            old_name = dom.getName()
+            dom.setName(new_name)
+
+        finally:
+            self.domains_lock.release()
+                
+    
+    #
+    # End of Xen API 
+    # ----------------------------------------------------------------
+
+    # ------------------------------------------------------------
+    # Xen Legacy API     
+
+    def list(self, state = DOM_STATE_RUNNING):
+        """Get list of domain objects.
+
+        @param: the state in which the VMs should be -- one of the
+        DOM_STATE_XYZ constants, or the corresponding name, or 'all'.
+        @return: domains
+        @rtype: list of XendDomainInfo
+        """
+        if type(state) == int:
+            state = POWER_STATE_NAMES[state]
+        state = state.lower()
+        resu = False
+        count = 0
+        while True:
+            resu = self.domains_lock.acquire(0)
+            if resu or count < 20:
+                break
+            count += 1
+        try:
+            if resu:
+                self._refresh(refresh_shutdown = False)
+            
+            # active domains
+            active_domains = self.domains.values()
+            active_uuids = [d.get_uuid() for d in active_domains]
+
+            # inactive domains
+            inactive_domains = []
+            for dom_uuid, dom in self.managed_domains.items():
+                if dom_uuid not in active_uuids:
+                    inactive_domains.append(dom)
+
+            if state == POWER_STATE_ALL:
+                return active_domains + inactive_domains
+            else:
+                return filter(lambda x:
+                                  POWER_STATE_NAMES[x._stateGet()].lower() == state,
+                              active_domains + inactive_domains)
+        finally:
+            if resu:
+                self.domains_lock.release()
+
+
+    def list_sorted(self, state = DOM_STATE_RUNNING):
+        """Get list of domain objects, sorted by name.
+
+        @param: the state in which the VMs should be -- one of the
+        DOM_STATE_XYZ constants, or the corresponding name, or 'all'.
+        @return: domain objects
+        @rtype: list of XendDomainInfo
+        """
+        doms = self.list(state)
+        doms.sort(lambda x, y: cmp(x.getName(), y.getName()))
+        return doms
+
+    def list_names(self, state = DOM_STATE_RUNNING):
+        """Get list of domain names.
+
+        @param: the state in which the VMs should be -- one of the
+        DOM_STATE_XYZ constants, or the corresponding name, or 'all'.
+        @return: domain names
+        @rtype: list of strings.
+        """
+        return [d.getName() for d in self.list_sorted(state)]
+
+    def domain_suspend(self, domname):
+        """Suspends a domain that is persistently managed by Xend
+
+        @param domname: Domain Name
+        @type domname: string
+        @rtype: None
+        @raise XendError: Failure during checkpointing.
+        """
+
+        try:
+            dominfo = self.domain_lookup_nr(domname)
+            if not dominfo:
+                raise XendInvalidDomain(domname)
+
+            if dominfo.getDomid() == DOM0_ID:
+                raise XendError("Cannot suspend privileged domain %s" % domname)
+
+            if dominfo._stateGet() != DOM_STATE_RUNNING:
+                raise VMBadState("Domain is not running",
+                                 POWER_STATE_NAMES[DOM_STATE_RUNNING],
+                                 POWER_STATE_NAMES[dominfo._stateGet()])
+
+            dom_uuid = dominfo.get_uuid()
+
+            if not os.path.exists(self._managed_config_path(dom_uuid)):
+                raise XendError("Domain is not managed by Xend lifecycle " +
+                                "support.")
+
+            path = self._managed_check_point_path(dom_uuid)
+            oflags = os.O_WRONLY | os.O_CREAT | os.O_TRUNC
+            if hasattr(os, "O_LARGEFILE"):
+                oflags |= os.O_LARGEFILE
+            fd = os.open(path, oflags)
+            try:
+                # For now we don't support 'live checkpoint' 
+                XendCheckpoint.save(fd, dominfo, False, False, path)
+            finally:
+                os.close(fd)
+        except OSError, ex:
+            raise XendError("can't write guest state file %s: %s" %
+                            (path, ex[1]))
+
+    def domain_resume(self, domname, start_paused = False):
+        """Resumes a domain that is persistently managed by Xend.
+
+        @param domname: Domain Name
+        @type domname: string
+        @rtype: None
+        @raise XendError: If failed to restore.
+        """
+        self.domains_lock.acquire()
+        try:
+            try:
+                fd = None
+                dominfo = self.domain_lookup_nr(domname)
+
+                if not dominfo:
+                    raise XendInvalidDomain(domname)
+
+                if dominfo.getDomid() == DOM0_ID:
+                    raise XendError("Cannot resume privileged domain %s" % domname)
+
+                if dominfo._stateGet() != XEN_API_VM_POWER_STATE_SUSPENDED:
+                    raise XendError("Cannot resume domain that is not suspended.")
+
+                dominfo.setResume(True)
+
+                dom_uuid = dominfo.get_uuid()
+                chkpath = self._managed_check_point_path(dom_uuid)
+                if not os.path.exists(chkpath):
+                    raise XendError("Domain was not suspended by Xend")
+
+                # Restore that replaces the existing XendDomainInfo
+                try:
+                    log.debug('Current DomainInfo state: %d' % dominfo._stateGet())
+                    oflags = os.O_RDONLY
+                    if hasattr(os, "O_LARGEFILE"):
+                        oflags |= os.O_LARGEFILE
+                    fd = os.open(chkpath, oflags)
+                    XendCheckpoint.restore(self,
+                                           fd,
+                                           dominfo,
+                                           paused = start_paused)
+                    os.unlink(chkpath)
+                except OSError, ex:
+                    raise XendError("Failed to read stored checkpoint file")
+                except IOError, ex:
+                    raise XendError("Failed to delete checkpoint file")
+            except Exception, ex:
+                log.exception("Exception occurred when resuming")
+                raise XendError("Error occurred when resuming: %s" % str(ex))
+        finally:
+            if fd is not None:
+                os.close(fd)
+            self.domains_lock.release()
+
+
+    def domain_create(self, config):
+        """Create a domain from a configuration.
+
+        @param config: configuration
+        @type config: SXP Object (list of lists)
+        @rtype: XendDomainInfo
+        """
+        self.domains_lock.acquire()
+        try:
+            self._refresh()
+
+            dominfo = XendDomainInfo.create(config)
+            return dominfo
+        finally:
+            self.domains_lock.release()
+
+
+    def domain_create_from_dict(self, config_dict):
+        """Create a domain from a configuration dictionary.
+
+        @param config_dict: configuration
+        @rtype: XendDomainInfo
+        """
+        self.domains_lock.acquire()
+        try:
+            self._refresh()
+
+            dominfo = XendDomainInfo.create_from_dict(config_dict)
+            return dominfo
+        finally:
+            self.domains_lock.release()
+
+
+    def domain_new(self, config):
+        """Create a domain from a configuration but do not start it.
+        
+        @param config: configuration
+        @type config: SXP Object (list of lists)
+        @rtype: XendDomainInfo
+        """
+        self.domains_lock.acquire()
+        try:
+            try:
+                domconfig = XendConfig.XendConfig(sxp_obj = config)
+                dominfo = XendDomainInfo.createDormant(domconfig)
+                log.debug("Creating new managed domain: %s" %
+                          dominfo.getName())
+                self._managed_domain_register(dominfo)
+                self.managed_config_save(dominfo)
+                # no return value because it isn't meaningful for client
+            except XendError, e:
+                raise
+            except Exception, e:
+                raise XendError(str(e))
+        finally:
+            self.domains_lock.release()
+
+    def domain_start(self, domid, start_paused = True):
+        """Start a managed domain
+
+        @require: Domain must not be running.
+        @param domid: Domain name or domain ID.
+        @type domid: string or int
+        @rtype: None
+        @raise XendError: If domain is still running
+        @rtype: None
+        """
+        self.domains_lock.acquire()
+        try:
+            self._refresh()
+
+            dominfo = self.domain_lookup_nr(domid)
+            if not dominfo:
+                raise XendInvalidDomain(str(domid))
+
+            if dominfo._stateGet() != DOM_STATE_HALTED:
+                raise VMBadState("Domain is already running",
+                                 POWER_STATE_NAMES[DOM_STATE_HALTED],
+                                 POWER_STATE_NAMES[dominfo._stateGet()])
+            
+            dominfo.start(is_managed = True)
+        finally:
+            self.domains_lock.release()
+
+        try:
+            dominfo.waitForDevices()
+        except Exception, ex:
+            log.warn("Failed to setup devices for " + str(dominfo) + ": " + str(ex))
+            dominfo.destroy()
+            raise
+
+        if not start_paused:
+            dominfo.unpause()
+
+    def domain_delete(self, domid):
+        """Remove a managed domain from database
+
+        @require: Domain must not be running.
+        @param domid: Domain name or domain ID.
+        @type domid: string or int
+        @rtype: None
+        @raise XendError: If domain is still running
+        """
+        self.domains_lock.acquire()
+        try:
+            try:
+                dominfo = self.domain_lookup_nr(domid)
+                if not dominfo:
+                    raise XendInvalidDomain(str(domid))
+
+                if dominfo._stateGet() != XEN_API_VM_POWER_STATE_HALTED:
+                    raise VMBadState("Domain is not halted.",
+                                     POWER_STATE_NAMES[DOM_STATE_HALTED],
+                                     POWER_STATE_NAMES[dominfo._stateGet()])
+                
+                self._domain_delete_by_info(dominfo)
+            except Exception, ex:
+                raise XendError(str(ex))
+        finally:
+            self.domains_lock.release()
+
+
+    def domain_delete_by_dominfo(self, dominfo):
+        """Only for use by XendDomainInfo.
+        """
+        self.domains_lock.acquire()
+        try:
+            self._domain_delete_by_info(dominfo)
+        finally:
+            self.domains_lock.release()
+
+
+    def _domain_delete_by_info(self, dominfo):
+        """Expects to be protected by domains_lock.
+        """
+        log.info("Domain %s (%s) deleted." %
+                 (dominfo.getName(), dominfo.info.get('uuid')))
+                
+        self._managed_domain_unregister(dominfo)
+        self._remove_domain(dominfo)
+        XendDevices.destroy_device_state(dominfo)
+
+
+    def domain_configure(self, config):
+        """Configure an existing domain.
+
+        @param vmconfig: vm configuration
+        @type vmconfig: SXP Object (list of lists)
+        @todo: Not implemented
+        """
+        # !!!
+        raise XendError("Unsupported")
+
+    def domain_restore(self, src, paused=False):
+        """Restore a domain from file.
+
+        @param src: filename of checkpoint file to restore from
+        @type src: string
+        @return: Restored domain
+        @rtype: XendDomainInfo
+        @raise XendError: Failure to restore domain
+        """
+        try:
+            oflags = os.O_RDONLY
+            if hasattr(os, "O_LARGEFILE"):
+                oflags |= os.O_LARGEFILE
+            fd = os.open(src, oflags)
+            try:
+                return self.domain_restore_fd(fd, paused=paused)
+            finally:
+                os.close(fd)
+        except OSError, ex:
+            raise XendError("can't read guest state file %s: %s" %
+                            (src, ex[1]))
+
+    def domain_restore_fd(self, fd, paused=False, relocating=False):
+        """Restore a domain from the given file descriptor.
+
+        @param fd: file descriptor of the checkpoint file
+        @type fd: File object
+        @rtype: XendDomainInfo
+        @raise XendError: if failed to restore
+        """
+
+        try:
+            self.policy_lock.acquire_reader()
+
+            try:
+                dominfo = XendCheckpoint.restore(self, fd, paused=paused, relocating=relocating)
+                if relocating and \
+                   dominfo.info.has_key("change_home_server"):
+                    chs = (dominfo.info["change_home_server"] == "True")
+                    dominfo.setChangeHomeServer(None)
+                    if chs:
+                        self.domains_lock.acquire()
+                        try:
+                            log.debug("Migrating new managed domain: %s: %s" %
+                                      (dominfo.getName(), dominfo.get_uuid()))
+                            self._managed_domain_register(dominfo)
+                            self.managed_config_save(dominfo)
+                        finally:
+                            self.domains_lock.release()
+                return dominfo
+            except XendError, e:
+                log.exception("Restore failed")
+                raise
+            except:
+                # I don't really want to log this exception here, but the error
+                # handling in the relocation-socket handling code (relocate.py) is
+                # poor, so we need to log this for debugging.
+                log.exception("Restore failed")
+                raise XendError("Restore failed")
+        finally:
+            self.policy_lock.release()
+ 
+    def domain_unpause(self, domid):
+        """Unpause domain execution.
+
+        @param domid: Domain ID or Name
+        @type domid: int or string.
+        @rtype: None
+        @raise XendError: Failed to unpause
+        @raise XendInvalidDomain: Domain is not valid        
+        """
+        try:
+            dominfo = self.domain_lookup_nr(domid)
+            if not dominfo:
+                raise XendInvalidDomain(str(domid))
+            if dominfo.getDomid() == DOM0_ID:
+                raise XendError("Cannot unpause privileged domain %s" % domid)
+            if dominfo._stateGet() not in (DOM_STATE_PAUSED, DOM_STATE_RUNNING):
+                raise VMBadState("Domain '%s' is not started" % domid,
+                                 POWER_STATE_NAMES[DOM_STATE_PAUSED],
+                                 POWER_STATE_NAMES[dominfo._stateGet()])
+            log.info("Domain %s (%d) unpaused.", dominfo.getName(),
+                     int(dominfo.getDomid()))
+            dominfo.unpause()
+        except XendInvalidDomain:
+            log.exception("domain_unpause")
+            raise
+        except Exception, ex:
+            log.exception("domain_unpause")
+            raise XendError(str(ex))
+
+    def domain_pause(self, domid, state=False):
+        """Pause domain execution.
+
+        @param domid: Domain ID or Name
+        @type domid: int or string.
+        @keyword state: If True, will return the domain state before pause
+        @type state: bool
+        @rtype: int if state is True
+        @return: Domain state (DOM_STATE_*)
+        @rtype: None if state is False
+        @raise XendError: Failed to pause
+        @raise XendInvalidDomain: Domain is not valid
+        """        
+        try:
+            dominfo = self.domain_lookup_nr(domid)
+            if not dominfo:
+                raise XendInvalidDomain(str(domid))
+            if dominfo.getDomid() == DOM0_ID:
+                raise XendError("Cannot pause privileged domain %s" % domid)
+            ds = dominfo._stateGet()
+            if ds not in (DOM_STATE_RUNNING, DOM_STATE_PAUSED, DOM_STATE_CRASHED):
+                raise VMBadState("Domain '%s' is not started" % domid,
+                                 POWER_STATE_NAMES[DOM_STATE_RUNNING],
+                                 POWER_STATE_NAMES[ds])
+            log.info("Domain %s (%d) paused.", dominfo.getName(),
+                     int(dominfo.getDomid()))
+            if ds == DOM_STATE_RUNNING:
+                dominfo.pause()
+            if state:
+                return ds
+        except XendInvalidDomain:
+            log.exception("domain_pause")
+            raise
+        except Exception, ex:
+            log.exception("domain_pause")
+            raise XendError(str(ex))
+
+    def domain_dump(self, domid, filename=None, live=False, crash=False, reset=False):
+        """Dump domain core."""
+
+        dominfo = self.domain_lookup_nr(domid)
+        if not dominfo:
+            raise XendInvalidDomain(str(domid))
+
+        if dominfo.getDomid() == DOM0_ID:
+            raise XendError("Cannot dump core for privileged domain %s" % domid)
+        if dominfo._stateGet() not in (DOM_STATE_PAUSED, DOM_STATE_RUNNING, DOM_STATE_CRASHED):
+            raise VMBadState("Domain '%s' is not started" % domid,
+                             POWER_STATE_NAMES[DOM_STATE_PAUSED],
+                             POWER_STATE_NAMES[dominfo._stateGet()])
+
+        dopause = (not live and dominfo._stateGet() == DOM_STATE_RUNNING)
+        if dopause:
+            dominfo.pause()
+
+        try:
+            try:
+                log.info("Domain core dump requested for domain %s (%d) "
+                         "live=%d crash=%d reset=%d.",
+                         dominfo.getName(), dominfo.getDomid(), live, crash, reset)
+                dominfo.dumpCore(filename)
+                if crash:
+                    self.domain_destroy(domid)
+                elif reset:
+                    self.domain_reset(domid)
+            except Exception, ex:
+                raise XendError(str(ex))
+        finally:
+            if dopause and not crash and not reset:
+                dominfo.unpause()
+
+    def domain_destroy(self, domid):
+        """Terminate domain immediately.
+
+        @param domid: Domain ID or Name
+        @type domid: int or string.
+        @rtype: None
+        @raise XendError: Failed to destroy
+        @raise XendInvalidDomain: Domain is not valid        
+        """
+
+        dominfo = self.domain_lookup_nr(domid)
+        if dominfo and dominfo.getDomid() == DOM0_ID:
+            raise XendError("Cannot destroy privileged domain %s" % domid)
+
+        if dominfo:
+            val = dominfo.destroy()
+        else:
+            try:
+                xc.domain_pause(int(domid))
+                dom = self.domains[int(domid)]
+                XendDomainInfo.do_FLR(int(domid), dom.info.is_hvm())
+                val = xc.domain_destroy(int(domid))
+            except ValueError:
+                raise XendInvalidDomain(domid)
+            except Exception, e:
+                raise XendError(str(e))
+
+        return val       
+
+    def domain_migrate(self, domid, dst, live=False, port=0, node=-1, ssl=None,\
+                       chs=False):
+        """Start domain migration.
+        
+        @param domid: Domain ID or Name
+        @type domid: int or string.
+        @param dst: Destination IP address
+        @type dst: string
+        @keyword live: Live migration
+        @type live: bool
+        @keyword port: relocation port on destination
+        @type port: int
+        @keyword node: use node number for target
+        @type node: int
+        @keyword ssl: use ssl connection
+        @type ssl: bool
+        @keyword chs: change home server for managed domain
+        @type chs: bool
+        @rtype: None
+        @raise XendError: Failed to migrate
+        @raise XendInvalidDomain: Domain is not valid
+        """
+
+        dominfo = self.domain_lookup_nr(domid)
+        if not dominfo:
+            raise XendInvalidDomain(str(domid))
+
+        if dominfo.getDomid() == DOM0_ID:
+            raise XendError("Cannot migrate privileged domain %s" % domid)
+        if dominfo._stateGet() != DOM_STATE_RUNNING:
+            raise VMBadState("Domain is not running",
+                             POWER_STATE_NAMES[DOM_STATE_RUNNING],
+                             POWER_STATE_NAMES[dominfo._stateGet()])
+        if chs and not self.is_domain_managed(dominfo):
+            raise XendError("Domain is not a managed domain")
+
+        """ The following call may raise a XendError exception """
+        dominfo.testMigrateDevices(True, dst)
+
+        if live:
+            """ Make sure there's memory free for enabling shadow mode """
+            dominfo.checkLiveMigrateMemory()
+
+        if ssl is None:
+            ssl = xoptions.get_xend_relocation_ssl()
+
+        try:
+            dominfo.setChangeHomeServer(chs)
+            if ssl:
+                self._domain_migrate_by_ssl(dominfo, dst, live, port, node)
+            else:
+                self._domain_migrate(dominfo, dst, live, port, node)
+        except:
+            dominfo.setChangeHomeServer(None)
+            raise
+
+    def _domain_migrate_by_ssl(self, dominfo, dst, live, port, node):
+        from OpenSSL import SSL
+        from xen.web import connection
+        if port == 0:
+            port = xoptions.get_xend_relocation_ssl_port()
+        try:
+            ctx = SSL.Context(SSL.SSLv23_METHOD)
+            sock = SSL.Connection(ctx,
+                       socket.socket(socket.AF_INET, socket.SOCK_STREAM))
+            sock.set_connect_state()
+            sock.connect((dst, port))
+            sock.send("sslreceive\n")
+            sock.recv(80)
+        except SSL.Error, err:
+            raise XendError("SSL error: %s" % err)
+        except socket.error, err:
+            raise XendError("can't connect: %s" % err)
+
+        p2cread, p2cwrite = os.pipe()
+        threading.Thread(target=connection.SSLSocketServerConnection.fd2send,
+                         args=(sock, p2cread)).start()
+
+        try:
+            try:
+                XendCheckpoint.save(p2cwrite, dominfo, True, live, dst,
+                                    node=node,sock=sock)
+            except Exception, ex:
+                m_dsterr = None
+                try:
+                    sock.settimeout(3.0)
+                    dsterr = sock.recv(1024)
+                    sock.settimeout(None)
+                    if dsterr:
+                        # See send_error@relocate.py. If an error occurred
+                        # in a destination side, an error message with the
+                        # following form is returned from the destination
+                        # side.
+                        m_dsterr = \
+                            re.match(r"^\(err\s\(type\s(.+)\)\s\(value\s'(.+)'\)\)", dsterr)
+                except:
+                    # Probably socket.timeout exception occurred.
+                    # Ignore the exception because it has nothing to do with
+                    # an exception of XendCheckpoint.save.
+                    pass
+
+                if m_dsterr:
+                    raise XendError("%s (from %s)" % (m_dsterr.group(2), dst))
+                raise
+        finally:
+            if not live:
+                try:
+                    sock.shutdown(2)
+                except:
+                    # Probably the socket is already disconnected by sock.close
+                    # in the destination side.
+                    # Ignore the exception because it has nothing to do with
+                    # an exception of XendCheckpoint.save.
+                    pass
+                sock.close()
+
+        os.close(p2cread)
+        os.close(p2cwrite)
+
+    def _domain_migrate(self, dominfo, dst, live, port, node):
+        if port == 0:
+            port = xoptions.get_xend_relocation_port()
+        try:
+            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
+            # When connecting to our ssl enabled relocation server using a
+            # plain socket, send will success but recv will block. Add a
+            # 30 seconds timeout to raise a socket.timeout exception to
+            # inform the client.
+            sock.settimeout(30.0)
+            sock.connect((dst, port))
+            sock.send("receive\n")
+            sock.recv(80)
+            sock.settimeout(None)
+        except socket.error, err:
+            raise XendError("can't connect: %s" % err)
+
+        try:
+            try:
+                XendCheckpoint.save(sock.fileno(), dominfo, True, live,
+                                    dst, node=node,sock=sock)
+            except Exception, ex:
+                m_dsterr = None
+                try:
+                    sock.settimeout(3.0)
+                    dsterr = sock.recv(1024)
+                    sock.settimeout(None)
+                    if dsterr:
+                        # See send_error@relocate.py. If an error occurred
+                        # in a destination side, an error message with the
+                        # following form is returned from the destination
+                        # side.
+                        m_dsterr = \
+                            re.match(r"^\(err\s\(type\s(.+)\)\s\(value\s'(.+)'\)\)", dsterr)
+                except:
+                    # Probably socket.timeout exception occurred.
+                    # Ignore the exception because it has nothing to do with
+                    # an exception of XendCheckpoint.save.
+                    pass
+
+                if m_dsterr:
+                    raise XendError("%s (from %s)" % (m_dsterr.group(2), dst))
+                raise
+        finally:
+            if not live:
+                try:
+                    sock.shutdown(2)
+                except:
+                    # Probably the socket is already disconnected by sock.close
+                    # in the destination side.
+                    # Ignore the exception because it has nothing to do with
+                    # an exception of XendCheckpoint.save.
+                    pass
+                sock.close()
+
+    def domain_save(self, domid, dst, checkpoint=False):
+        """Start saving a domain to file.
+
+        @param domid: Domain ID or Name
+        @type domid: int or string.
+        @param dst: Destination filename
+        @type dst: string
+        @rtype: None
+        @raise XendError: Failed to save domain
+        @raise XendInvalidDomain: Domain is not valid        
+        """
+        try:
+            dominfo = self.domain_lookup_nr(domid)
+            if not dominfo:
+                raise XendInvalidDomain(str(domid))
+
+            if dominfo.getDomid() == DOM0_ID:
+                raise XendError("Cannot save privileged domain %s" % str(domid))
+            if dominfo._stateGet() != DOM_STATE_RUNNING:
+                raise VMBadState("Domain is not running",
+                                 POWER_STATE_NAMES[DOM_STATE_RUNNING],
+                                 POWER_STATE_NAMES[dominfo._stateGet()])
+
+            oflags = os.O_WRONLY | os.O_CREAT | os.O_TRUNC
+            if hasattr(os, "O_LARGEFILE"):
+                oflags |= os.O_LARGEFILE
+            fd = os.open(dst, oflags)
+            try:
+                XendCheckpoint.save(fd, dominfo, False, False, dst,
+                                    checkpoint=checkpoint)
+            except Exception, e:
+                os.close(fd)
+                raise e
+            os.close(fd)
+        except OSError, ex:
+            raise XendError("can't write guest state file %s: %s" %
+                            (dst, ex[1]))
+
+    def domain_usb_add(self, domid, dev_id):
+        dominfo = self.domain_lookup_nr(domid)
+        if not dominfo:
+            raise XendInvalidDomain(str(domid))
+
+        usb = dominfo.info['platform'].get('usb')
+        if not usb:
+            raise XendError("Can't add usb device to a guest with usb disabled in configure file")
+
+        hvm = dominfo.info.is_hvm()
+        if not hvm:
+            raise XendError("Can't add usb device to a non-hvm guest")
+
+        if dominfo._stateGet() != DOM_STATE_HALTED:
+            dominfo.image.signalDeviceModel("usb-add",
+                "usb-added", dev_id)
+        else:
+            log.debug("error: Domain is not running!")
+
+
+    def domain_usb_del(self, domid, dev_id):
+        dominfo = self.domain_lookup_nr(domid)
+        if not dominfo:
+            raise XendInvalidDomain(str(domid))
+
+        usb = dominfo.info['platform'].get('usb')
+        if not usb:
+            raise XendError("Can't add usb device to a guest with usb disabled in configure file")
+
+        hvm = dominfo.info.is_hvm()
+        if not hvm:
+            raise XendError("Can't del usb to a non-hvm guest")
+
+        if dominfo._stateGet() != DOM_STATE_HALTED:
+            dominfo.image.signalDeviceModel("usb-del",
+                "usb-deleted", dev_id)
+        else:
+            log.debug("error: Domain is not running!")
+
+    def domain_pincpu(self, domid, vcpu, cpumap):
+        """Set which cpus vcpu can use
+
+        @param domid: Domain ID or Name
+        @type domid: int or string.
+        @param vcpu: vcpu to pin to
+        @type vcpu: int
+        @param cpumap:  string repr of usable cpus
+        @type cpumap: string
+        @rtype: 0
+        """
+        dominfo = self.domain_lookup_nr(domid)
+        if not dominfo:
+            raise XendInvalidDomain(str(domid))
+
+        # if vcpu is keyword 'all', apply the cpumap to all vcpus
+        if str(vcpu).lower() == "all":
+            vcpus = range(0, int(dominfo.getVCpuCount()))
+        else:
+            vcpus = [ int(vcpu) ]
+       
+        # set the same cpumask for all vcpus
+        rc = 0
+        cpus = dominfo.getCpus()
+        cpumap = map(int, cpumap.split(","))
+        for v in vcpus:
+            try:
+                if dominfo._stateGet() in (DOM_STATE_RUNNING, DOM_STATE_PAUSED):
+                    rc = xc.vcpu_setaffinity(dominfo.getDomid(), v, cpumap)
+                cpus[v] = cpumap
+            except Exception, ex:
+                log.exception(ex)
+                raise XendError("Cannot pin vcpu: %d to cpu: %s - %s" % \
+                                (v, cpumap, str(ex)))
+        dominfo.setCpus(cpus)
+        self.managed_config_save(dominfo)
+
+        return rc
+
+    def domain_cpu_sedf_set(self, domid, period, slice_, latency, extratime,
+                            weight):
+        """Set Simple EDF scheduler parameters for a domain.
+
+        @param domid: Domain ID or Name
+        @type domid: int or string.
+        @rtype: 0
+        """
+        dominfo = self.domain_lookup_nr(domid)
+        if not dominfo:
+            raise XendInvalidDomain(str(domid))
+        try:
+            return xc.sedf_domain_set(dominfo.getDomid(), period, slice_,
+                                      latency, extratime, weight)
+        except Exception, ex:
+            raise XendError(str(ex))
+
+    def domain_cpu_sedf_get(self, domid):
+        """Get Simple EDF scheduler parameters for a domain.
+
+        @param domid: Domain ID or Name
+        @type domid: int or string.
+        @rtype: SXP object
+        @return: The parameters for Simple EDF schedule for a domain.
+        """
+        dominfo = self.domain_lookup_nr(domid)
+        if not dominfo:
+            raise XendInvalidDomain(str(domid))
+        try:
+            sedf_info = xc.sedf_domain_get(dominfo.getDomid())
+            # return sxpr
+            return ['sedf',
+                    ['domid',    sedf_info['domid']],
+                    ['period',    sedf_info['period']],
+                    ['slice',     sedf_info['slice']],
+                    ['latency',   sedf_info['latency']],
+                    ['extratime', sedf_info['extratime']],
+                    ['weight',    sedf_info['weight']]]
+
+        except Exception, ex:
+            raise XendError(str(ex))
+
+    def domain_shadow_control(self, domid, op):
+        """Shadow page control.
+        
+        @param domid: Domain ID or Name
+        @type domid: int or string.
+        @param op: operation
+        @type op: int
+        @rtype: 0
+        """
+        dominfo = self.domain_lookup(domid)
+        try:
+            return xc.shadow_control(dominfo.getDomid(), op)
+        except Exception, ex:
+            raise XendError(str(ex))
+
+    def domain_shadow_mem_get(self, domid):
+        """Get shadow pagetable memory allocation.
+        
+        @param domid: Domain ID or Name
+        @type domid: int or string.
+        @rtype: int
+        @return: shadow memory in MB
+        """
+        dominfo = self.domain_lookup(domid)
+        try:
+            return xc.shadow_mem_control(dominfo.getDomid())
+        except Exception, ex:
+            raise XendError(str(ex))
+
+    def domain_shadow_mem_set(self, domid, mb):
+        """Set shadow pagetable memory allocation.
+        
+        @param domid: Domain ID or Name
+        @type domid: int or string.
+        @param mb: shadow memory to set in MB
+        @type: mb: int
+        @rtype: int
+        @return: shadow memory in MB
+        """
+        dominfo = self.domain_lookup(domid)
+        try:
+            return xc.shadow_mem_control(dominfo.getDomid(), mb=mb)
+        except Exception, ex:
+            raise XendError(str(ex))
+
+    def domain_sched_credit_get(self, domid):
+        """Get credit scheduler parameters for a domain.
+
+        @param domid: Domain ID or Name
+        @type domid: int or string.
+        @rtype: dict with keys 'weight' and 'cap'
+        @return: credit scheduler parameters
+        """
+        dominfo = self.domain_lookup_nr(domid)
+        if not dominfo:
+            raise XendInvalidDomain(str(domid))
+        
+        if dominfo._stateGet() in (DOM_STATE_RUNNING, DOM_STATE_PAUSED):
+            try:
+                return xc.sched_credit_domain_get(dominfo.getDomid())
+            except Exception, ex:
+                raise XendError(str(ex))
+        else:
+            return {'weight' : dominfo.getWeight(),
+                    'cap'    : dominfo.getCap()} 
+    
+    def domain_sched_credit_set(self, domid, weight = None, cap = None):
+        """Set credit scheduler parameters for a domain.
+
+        @param domid: Domain ID or Name
+        @type domid: int or string.
+        @type weight: int
+        @type cap: int
+        @rtype: 0
+        """
+        set_weight = False
+        set_cap = False
+        dominfo = self.domain_lookup_nr(domid)
+        if not dominfo:
+            raise XendInvalidDomain(str(domid))
+        try:
+            if weight is None:
+                weight = int(0)
+            elif weight < 1 or weight > 65535:
+                raise XendError("Cpu weight out of range, valid values are "
+                                "within range from 1 to 65535")
+            else:
+                set_weight = True
+
+            if cap is None:
+                cap = int(~0)
+            elif cap < 0 or cap > dominfo.getVCpuCount() * 100:
+                raise XendError("Cpu cap out of range, valid range is "
+                                "from 0 to %s for specified number of vcpus" %
+                                (dominfo.getVCpuCount() * 100))
+            else:
+                set_cap = True
+
+            assert type(weight) == int
+            assert type(cap) == int
+
+            rc = 0
+            if dominfo._stateGet() in (DOM_STATE_RUNNING, DOM_STATE_PAUSED):
+                rc = xc.sched_credit_domain_set(dominfo.getDomid(), weight, cap)
+            if rc == 0:
+                if set_weight:
+                    dominfo.setWeight(weight)
+                if set_cap:
+                    dominfo.setCap(cap)
+                self.managed_config_save(dominfo)
+            return rc
+        except Exception, ex:
+            log.exception(ex)
+            raise XendError(str(ex))
+
+    def domain_sched_credit2_get(self, domid):
+        """Get credit2 scheduler parameters for a domain.
+
+        @param domid: Domain ID or Name
+        @type domid: int or string.
+        @rtype: dict with keys 'weight'
+        @return: credit2 scheduler parameters
+        """
+        dominfo = self.domain_lookup_nr(domid)
+        if not dominfo:
+            raise XendInvalidDomain(str(domid))
+
+        if dominfo._stateGet() in (DOM_STATE_RUNNING, DOM_STATE_PAUSED):
+            try:
+                return xc.sched_credit2_domain_get(dominfo.getDomid())
+            except Exception, ex:
+                raise XendError(str(ex))
+        else:
+            return {'weight' : dominfo.getWeight()}
+
+    def domain_sched_credit2_set(self, domid, weight = None):
+        """Set credit2 scheduler parameters for a domain.
+
+        @param domid: Domain ID or Name
+        @type domid: int or string.
+        @type weight: int
+        @rtype: 0
+        """
+        set_weight = False
+        dominfo = self.domain_lookup_nr(domid)
+        if not dominfo:
+            raise XendInvalidDomain(str(domid))
+        try:
+            if weight is None:
+                weight = int(0)
+            elif weight < 1 or weight > 65535:
+                raise XendError("weight is out of range")
+            else:
+                set_weight = True
+
+            assert type(weight) == int
+
+            rc = 0
+            if dominfo._stateGet() in (DOM_STATE_RUNNING, DOM_STATE_PAUSED):
+                rc = xc.sched_credit2_domain_set(dominfo.getDomid(), weight)
+            if rc == 0:
+                if set_weight:
+                    dominfo.setWeight(weight)
+                self.managed_config_save(dominfo)
+            return rc
+        except Exception, ex:
+            log.exception(ex)
+            raise XendError(str(ex))
+
+    def domain_migrate_constraints_set(self, domid, max_iters, max_factor, min_remaining, abort_if_busy, log_save_progress):
+        """Set the Migrate Constraints of this domain.
+        @param domid: Domain ID or Name
+        @param max_iters: Number of iterations before final suspend
+        @param max_factor: Max amount of memory to transfer before final suspend
+        @param min_remaining: Number of dirty pages before final suspend
+        @param abort_if_busy: Abort migration instead of doing final suspend
+        @param log_save_progress: Log progress of migrate to xend.log
+        """
+        dominfo = self.domain_lookup_nr(domid)
+        if not dominfo:
+            raise XendInvalidDomain(str(domid))
+        dominfo.setMigrateConstraints(max_iters, max_factor, min_remaining, abort_if_busy, log_save_progress)
+
+    def domain_maxmem_set(self, domid, mem):
+        """Set the memory limit for a domain.
+
+        @param domid: Domain ID or Name
+        @type domid: int or string.
+        @param mem: memory limit (in MiB)
+        @type mem: int
+        @raise XendError: fail to set memory
+        @rtype: 0
+        """
+        dominfo = self.domain_lookup_nr(domid)
+        if not dominfo:
+            raise XendInvalidDomain(str(domid))
+        dominfo.setMemoryMaximum(mem)
+
+    def domain_ioport_range_enable(self, domid, first, last):
+        """Enable access to a range of IO ports for a domain
+
+        @param first: first IO port
+        @param last: last IO port
+        @raise XendError: failed to set range
+        @rtype: 0
+        """
+        dominfo = self.domain_lookup_nr(domid)
+        if not dominfo:
+            raise XendInvalidDomain(str(domid))
+        nr_ports = last - first + 1
+        try:
+            return xc.domain_ioport_permission(dominfo.getDomid(),
+                                               first_port = first,
+                                               nr_ports = nr_ports,
+                                               allow_access = 1)
+        except Exception, ex:
+            raise XendError(str(ex))
+
+    def domain_ioport_range_disable(self, domid, first, last):
+        """Disable access to a range of IO ports for a domain
+
+        @param first: first IO port
+        @param last: last IO port
+        @raise XendError: failed to set range
+        @rtype: 0
+        """
+        dominfo = self.domain_lookup_nr(domid)
+        if not dominfo:
+            raise XendInvalidDomain(str(domid))
+        nr_ports = last - first + 1
+        try:
+            return xc.domain_ioport_permission(dominfo.getDomid(),
+                                               first_port = first,
+                                               nr_ports = nr_ports,
+                                               allow_access = 0)
+        except Exception, ex:
+            raise XendError(str(ex))
+
+    def domain_send_trigger(self, domid, trigger_name, vcpu = 0):
+        """Send trigger to a domain.
+
+        @param domid: Domain ID or Name
+        @type domid: int or string.
+        @param trigger_name: trigger type name
+        @type trigger_name: string
+        @param vcpu: VCPU to send trigger (default is 0) 
+        @type vcpu: int
+        @raise XendError: failed to send trigger
+        @raise XendInvalidDomain: Domain is not valid        
+        @rtype: 0
+        """
+        dominfo = self.domain_lookup_nr(domid)
+        if not dominfo:
+            raise XendInvalidDomain(str(domid))
+        if dominfo._stateGet() not in (DOM_STATE_RUNNING, DOM_STATE_PAUSED):
+            raise VMBadState("Domain '%s' is not started" % domid,
+                             POWER_STATE_NAMES[DOM_STATE_RUNNING],
+                             POWER_STATE_NAMES[dominfo._stateGet()])
+        if trigger_name.lower() in TRIGGER_TYPE.keys(): 
+            trigger = TRIGGER_TYPE[trigger_name.lower()]
+        else:
+            raise XendError("Invalid trigger: %s" % trigger_name)
+        if trigger == TRIGGER_S3RESUME:
+            xc.hvm_set_param(dominfo.getDomid(), HVM_PARAM_ACPI_S_STATE, 0)
+            return None
+        try:
+            return xc.domain_send_trigger(dominfo.getDomid(),
+                                          trigger,
+                                          vcpu)
+        except Exception, ex:
+            raise XendError(str(ex))
+
+    def domain_reset(self, domid):
+        """Terminate domain immediately, and then create domain.
+
+        @param domid: Domain ID or Name
+        @type domid: int or string.
+        @rtype: None
+        @raise XendError: Failed to destroy or create
+        @raise XendInvalidDomain: Domain is not valid
+        """
+
+        dominfo = self.domain_lookup_nr(domid)
+        if not dominfo:
+            raise XendInvalidDomain(str(domid))
+        if dominfo and dominfo.getDomid() == DOM0_ID:
+            raise XendError("Cannot reset privileged domain %s" % domid)
+        if dominfo._stateGet() not in (DOM_STATE_RUNNING, DOM_STATE_PAUSED):
+            raise VMBadState("Domain '%s' is not started" % domid,
+                             POWER_STATE_NAMES[DOM_STATE_RUNNING],
+                             POWER_STATE_NAMES[dominfo._stateGet()])
+        try:
+            dominfo.resetDomain()
+        except Exception, ex:
+            raise XendError(str(ex))
+
+
+def instance():
+    """Singleton constructor. Use this instead of the class constructor.
+    """
+    global inst
+    try:
+        inst
+    except:
+        inst = XendDomain()
+        inst.init()
+    return inst
diff -Naur xen/tools/python/xen/xend/XendDomainInfo.py xen-b/tools/python/xen/xend/XendDomainInfo.py
--- xen/tools/python/xen/xend/XendDomainInfo.py	2013-05-11 21:04:14.414814436 -0600
+++ xen-b/tools/python/xen/xend/XendDomainInfo.py	2013-05-12 06:30:26.771481103 -0600
@@ -1295,8 +1295,15 @@
                 frontpath = self.getDeviceController(deviceClass).frontendPath(dev)
                 backpath = xstransact.Read(frontpath, "backend")
                 thread.start_new_thread(self.getDeviceController(deviceClass).finishDeviceCleanup, (backpath, path))
-
-            rc = self.getDeviceController(deviceClass).destroyDevice(devid, force)
+            if deviceClass =='vusb':
+                dev = self.getDeviceController(deviceClass).convertToDeviceNumber(devid)
+                state = self.getDeviceController(deviceClass).readBackend(dev, 'state')
+                if state == '1':
+                    rc = self.getDeviceController(deviceClass).destroyDevice(devid, True)
+                else:
+                    rc = self.getDeviceController(deviceClass).destroyDevice(devid, force)
+            else:
+                rc = self.getDeviceController(deviceClass).destroyDevice(devid, force)
             if not force and rm_cfg:
                 # The backend path, other than the device itself,
                 # has to be passed because its accompanied frontend
@@ -1475,6 +1482,17 @@
         self.info['abort_if_busy'] = str(abort_if_busy)
         self.info['log_save_progress'] = str(log_save_progress)
 
+    def setSwapTarget(self, target):
+        """Set the swap target of this domain.
+        @param target: In MiB.
+        """
+        log.debug("Setting swap target of domain %s (%s) to %d MiB.",
+                  self.info['name_label'], str(self.domid), target)
+
+        if self.domid > 0:
+            self.storeDom("memory/target-tot_pages", target * 1024)
+            self.info['platform']['actmem'] = str(target)
+
     def setMemoryTarget(self, target):
         """Set the memory target of this domain.
         @param target: In MiB.
@@ -2263,6 +2281,8 @@
                  self.info['name_label'], self.domid, self.info['uuid'],
                  new_name, new_uuid)
         self._unwatchVm()
+        if self.image:
+            self.image.destroyXenPaging()
         self._releaseDevices()
         # Remove existing vm node in xenstore
         self._removeVm()
@@ -2900,7 +2920,7 @@
 
             self.guest_bitsize = self.image.getBitSize()
             # Make sure there's enough RAM available for the domain
-            balloon.free(memory + shadow + vtd_mem, self)
+            balloon.free(memory + shadow + vtd_mem + 512, self)
 
             # Set up the shadow memory
             shadow_cur = xc.shadow_mem_control(self.domid, shadow / 1024)
@@ -2935,6 +2955,9 @@
 
             self._createDevices()
 
+            if self.image:
+                self.image.createXenPaging()
+
             self.image.cleanupTmpImages()
 
             self.info['start_time'] = time.time()
@@ -2959,6 +2982,8 @@
         self.refresh_shutdown_lock.acquire()
         try:
             self.unwatchShutdown()
+            if self.image:
+                self.image.destroyXenPaging()
             self._releaseDevices()
             bootloader_tidy(self)
 
@@ -3043,6 +3068,7 @@
         self.refreshShutdown()
 
         log.debug("XendDomainInfo.completeRestore done")
+            self.image.createXenPaging()
 
 
     def _endRestore(self):
@@ -3173,6 +3199,8 @@
             # could also fetch a parsed note from xenstore
             fast = self.info.get_notes().get('SUSPEND_CANCEL') and 1 or 0
             if not fast:
+                if self.image:
+                    self.image.destroyXenPaging()
                 self._releaseDevices()
                 self.testDeviceComplete()
                 self.testvifsComplete()
@@ -3188,6 +3216,8 @@
                 self._storeDomDetails()
 
                 self._createDevices()
+                if self.image:
+                    self.image.createXenPaging()
                 log.debug("XendDomainInfo.resumeDomain: devices created")
 
             xc.domain_resume(self.domid, fast)
@@ -3924,6 +3954,14 @@
             else:
                 config['mode'] = 'RW'
 
+        if dev_class == 'console':
+            if not config.has_key('protocol'):
+                con_type = config.get('type', '')
+                if con_type == 'vnc':
+                    config['protocol'] = 'rfb'
+                elif con_type == 'sdl':
+                    config['protocol'] = 'rdp'
+
         return config
 
     def get_dev_property(self, dev_class, dev_uuid, field):
diff -Naur xen/tools/python/xen/xend/XendDomainInfo.py.orig xen-b/tools/python/xen/xend/XendDomainInfo.py.orig
--- xen/tools/python/xen/xend/XendDomainInfo.py.orig	1969-12-31 17:00:00.000000000 -0700
+++ xen-b/tools/python/xen/xend/XendDomainInfo.py.orig	2013-05-11 21:04:14.414814436 -0600
@@ -0,0 +1,4440 @@
+#===========================================================================
+# This library is free software; you can redistribute it and/or
+# modify it under the terms of version 2.1 of the GNU Lesser General Public
+# License as published by the Free Software Foundation.
+#
+# This library is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+# Lesser General Public License for more details.
+#
+# You should have received a copy of the GNU Lesser General Public
+# License along with this library; if not, write to the Free Software
+# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+#============================================================================
+# Copyright (C) 2004, 2005 Mike Wray <mike.wray@hp.com>
+# Copyright (C) 2005-2007 XenSource Ltd
+#============================================================================
+
+"""Representation of a single domain.
+Includes support for domain construction, using
+open-ended configurations.
+
+Author: Mike Wray <mike.wray@hp.com>
+
+"""
+
+import logging
+import time
+import threading
+import thread
+import re
+import copy
+import os
+import stat
+import shutil
+import traceback
+from types import StringTypes
+
+import xen.lowlevel.xc
+from xen.util import asserts, auxbin, mkdir
+from xen.util.blkif import parse_uname
+import xen.util.xsm.xsm as security
+from xen.util import xsconstants
+from xen.util import mkdir
+from xen.util.pci import serialise_pci_opts, pci_opts_list_to_sxp, \
+                         append_default_pci_opts, \
+                         pci_dict_to_bdf_str, pci_dict_to_xc_str, \
+                         pci_convert_sxp_to_dict, pci_convert_dict_to_sxp, \
+                         pci_dict_cmp, PCI_DEVFN, PCI_SLOT, PCI_FUNC, parse_hex
+
+from xen.xend import balloon, sxp, uuid, image, arch
+from xen.xend import XendOptions, XendNode, XendConfig
+
+from xen.xend.XendConfig import scrub_password
+from xen.xend.XendBootloader import bootloader, bootloader_tidy
+from xen.xend.XendError import XendError, VmError
+from xen.xend.XendDevices import XendDevices
+from xen.xend.XendTask import XendTask
+from xen.xend.xenstore.xstransact import xstransact, complete
+from xen.xend.xenstore.xsutil import GetDomainPath, IntroduceDomain, SetTarget, ResumeDomain
+from xen.xend.xenstore.xswatch import xswatch
+from xen.xend.XendConstants import *
+from xen.xend.XendAPIConstants import *
+from xen.xend.XendCPUPool import XendCPUPool
+from xen.xend.server.DevConstants import xenbusState
+from xen.xend.server.BlktapController import TapdiskController
+
+from xen.xend.XendVMMetrics import XendVMMetrics
+
+from xen.xend import XendAPIStore
+from xen.xend.XendPPCI import XendPPCI
+from xen.xend.XendDPCI import XendDPCI
+from xen.xend.XendPSCSI import XendPSCSI
+from xen.xend.XendDSCSI import XendDSCSI, XendDSCSI_HBA
+
+MIGRATE_TIMEOUT = 30.0
+BOOTLOADER_LOOPBACK_DEVICE = '/dev/xvdp'
+
+xc = xen.lowlevel.xc.xc()
+xoptions = XendOptions.instance()
+
+log = logging.getLogger("xend.XendDomainInfo")
+#log.setLevel(logging.TRACE)
+
+
+def create(config):
+    """Creates and start a VM using the supplied configuration. 
+
+    @param config: A configuration object involving lists of tuples.
+    @type  config: list of lists, eg ['vm', ['image', 'xen.gz']]
+
+    @rtype:  XendDomainInfo
+    @return: An up and running XendDomainInfo instance
+    @raise VmError: Invalid configuration or failure to start.
+    """
+    from xen.xend import XendDomain
+    domconfig = XendConfig.XendConfig(sxp_obj = config)
+    othervm = XendDomain.instance().domain_lookup_nr(domconfig["name_label"])
+    if othervm is None or othervm.domid is None:
+        othervm = XendDomain.instance().domain_lookup_nr(domconfig["uuid"])
+    if othervm is not None and othervm.domid is not None:
+        raise VmError("Domain '%s' already exists with ID '%d'" % (domconfig["name_label"], othervm.domid))
+    log.debug("XendDomainInfo.create(%s)", scrub_password(config))
+    vm = XendDomainInfo(domconfig)
+    try:
+        vm.start()
+    except:
+        log.exception('Domain construction failed')
+        vm.destroy()
+        raise
+
+    return vm
+
+def create_from_dict(config_dict):
+    """Creates and start a VM using the supplied configuration. 
+
+    @param config_dict: An configuration dictionary.
+
+    @rtype:  XendDomainInfo
+    @return: An up and running XendDomainInfo instance
+    @raise VmError: Invalid configuration or failure to start.
+    """
+
+    log.debug("XendDomainInfo.create_from_dict(%s)",
+              scrub_password(config_dict))
+    vm = XendDomainInfo(XendConfig.XendConfig(xapi = config_dict))
+    try:
+        vm.start()
+    except:
+        log.exception('Domain construction failed')
+        vm.destroy()
+        raise
+    return vm
+
+def recreate(info, priv):
+    """Create the VM object for an existing domain.  The domain must not
+    be dying, as the paths in the store should already have been removed,
+    and asking us to recreate them causes problems.
+
+    @param xeninfo: Parsed configuration
+    @type  xeninfo: Dictionary
+    @param priv: Is a privileged domain (Dom 0)
+    @type  priv: bool
+
+    @rtype:  XendDomainInfo
+    @return: A up and running XendDomainInfo instance
+    @raise VmError: Invalid configuration.
+    @raise XendError: Errors with configuration.
+    """
+
+    log.debug("XendDomainInfo.recreate(%s)", scrub_password(info))
+
+    assert not info['dying']
+
+    xeninfo = XendConfig.XendConfig(dominfo = info)
+    xeninfo['is_control_domain'] = priv
+    xeninfo['is_a_template'] = False
+    xeninfo['auto_power_on'] = False
+    domid = xeninfo['domid']
+    uuid1 = uuid.fromString(xeninfo['uuid'])
+    needs_reinitialising = False
+    
+    dompath = GetDomainPath(domid)
+    if not dompath:
+        raise XendError('No domain path in store for existing '
+                        'domain %d' % domid)
+
+    log.info("Recreating domain %d, UUID %s. at %s" %
+             (domid, xeninfo['uuid'], dompath))
+
+    # need to verify the path and uuid if not Domain-0
+    # if the required uuid and vm aren't set, then that means
+    # we need to recreate the dom with our own values
+    #
+    # NOTE: this is probably not desirable, really we should just
+    #       abort or ignore, but there may be cases where xenstore's
+    #       entry disappears (eg. xenstore-rm /)
+    #
+    try:
+        vmpath = xstransact.Read(dompath, "vm")
+        if not vmpath:
+            if not priv:
+                log.warn('/local/domain/%d/vm is missing. recreate is '
+                         'confused, trying our best to recover' % domid)
+            needs_reinitialising = True
+            raise XendError('reinit')
+        
+        uuid2_str = xstransact.Read(vmpath, "uuid")
+        if not uuid2_str:
+            log.warn('%s/uuid/ is missing. recreate is confused, '
+                     'trying our best to recover' % vmpath)
+            needs_reinitialising = True
+            raise XendError('reinit')
+        
+        uuid2 = uuid.fromString(uuid2_str)
+        if uuid1 != uuid2:
+            log.warn('UUID in /vm does not match the UUID in /dom/%d.'
+                     'Trying out best to recover' % domid)
+            needs_reinitialising = True
+    except XendError:
+        pass # our best shot at 'goto' in python :)
+
+    vm = XendDomainInfo(xeninfo, domid, dompath, augment = True, priv = priv,
+                        vmpath = vmpath)
+    
+    if needs_reinitialising:
+        vm._recreateDom()
+        vm._removeVm()
+        vm._storeVmDetails()
+        vm._storeDomDetails()
+        
+    vm.image = image.create(vm, vm.info)
+    vm.image.recreate()
+
+    vm._registerWatches()
+    vm.refreshShutdown(xeninfo)
+
+    # register the domain in the list 
+    from xen.xend import XendDomain
+    XendDomain.instance().add_domain(vm)
+
+    return vm
+
+
+def restore(config):
+    """Create a domain and a VM object to do a restore.
+
+    @param config: Domain SXP configuration
+    @type  config: list of lists. (see C{create})
+
+    @rtype:  XendDomainInfo
+    @return: A up and running XendDomainInfo instance
+    @raise VmError: Invalid configuration or failure to start.
+    @raise XendError: Errors with configuration.
+    """
+
+    log.debug("XendDomainInfo.restore(%s)", scrub_password(config))
+    vm = XendDomainInfo(XendConfig.XendConfig(sxp_obj = config),
+                        resume = True)
+    try:
+        vm.resume()
+        return vm
+    except:
+        vm.destroy()
+        raise
+
+def createDormant(domconfig):
+    """Create a dormant/inactive XenDomainInfo without creating VM.
+    This is for creating instances of persistent domains that are not
+    yet start.
+
+    @param domconfig: Parsed configuration
+    @type  domconfig: XendConfig object
+    
+    @rtype:  XendDomainInfo
+    @return: A up and running XendDomainInfo instance
+    @raise XendError: Errors with configuration.    
+    """
+    
+    log.debug("XendDomainInfo.createDormant(%s)", scrub_password(domconfig))
+    
+    # domid does not make sense for non-running domains.
+    domconfig.pop('domid', None)
+    vm = XendDomainInfo(domconfig)
+    return vm    
+
+def domain_by_name(name):
+    """Get domain by name
+
+    @params name: Name of the domain
+    @type   name: string
+    @return: XendDomainInfo or None
+    """
+    from xen.xend import XendDomain
+    return XendDomain.instance().domain_lookup_by_name_nr(name)
+
+
+def shutdown_reason(code):
+    """Get a shutdown reason from a code.
+
+    @param code: shutdown code
+    @type  code: int
+    @return: shutdown reason
+    @rtype:  string
+    """
+    return DOMAIN_SHUTDOWN_REASONS.get(code, "?")
+
+def dom_get(dom):
+    """Get info from xen for an existing domain.
+
+    @param dom: domain id
+    @type  dom: int
+    @return: info or None
+    @rtype: dictionary
+    """
+    try:
+        domlist = xc.domain_getinfo(dom, 1)
+        if domlist and dom == domlist[0]['domid']:
+            return domlist[0]
+    except Exception, err:
+        # ignore missing domain
+        log.trace("domain_getinfo(%d) failed, ignoring: %s", dom, str(err))
+    return None
+
+from xen.xend.server.pciif import parse_pci_name, PciDevice,\
+    get_assigned_pci_devices, get_all_assigned_pci_devices
+
+
+def do_FLR(domid, is_hvm):
+    dev_str_list = get_assigned_pci_devices(domid)
+
+    for dev_str in dev_str_list:
+        try:
+            dev = PciDevice(parse_pci_name(dev_str))
+        except Exception, e:
+            raise VmError("pci: failed to locate device and "+
+                    "parse it's resources - "+str(e))
+        dev.do_FLR(is_hvm, xoptions.get_pci_dev_assign_strict_check())
+
+class XendDomainInfo:
+    """An object represents a domain.
+
+    @TODO: try to unify dom and domid, they mean the same thing, but
+           xc refers to it as dom, and everywhere else, including
+           xenstore it is domid. The best way is to change xc's
+           python interface.
+
+    @ivar info: Parsed configuration
+    @type info: dictionary
+    @ivar domid: Domain ID (if VM has started)
+    @type domid: int or None
+    @ivar paused_by_admin: Is this Domain paused by command or API 
+    @type paused_by_admin: bool 
+    @ivar guest_bitsize: the bitsize of guest 
+    @type guest_bitsize: int or None
+    @ivar alloc_mem: the memory domain allocated when booting 
+    @type alloc_mem: int or None 
+    @ivar vmpath: XenStore path to this VM.
+    @type vmpath: string
+    @ivar dompath: XenStore path to this Domain.
+    @type dompath: string
+    @ivar image:  Reference to the VM Image.
+    @type image: xen.xend.image.ImageHandler
+    @ivar store_port: event channel to xenstored
+    @type store_port: int
+    @ivar console_port: event channel to xenconsoled
+    @type console_port: int
+    @ivar store_mfn: xenstored mfn
+    @type store_mfn: int
+    @ivar console_mfn: xenconsoled mfn
+    @type console_mfn: int
+    @ivar notes: OS image notes
+    @type notes: dictionary
+    @ivar vmWatch: reference to a watch on the xenstored vmpath
+    @type vmWatch: xen.xend.xenstore.xswatch
+    @ivar shutdownWatch: reference to watch on the xenstored domain shutdown
+    @type shutdownWatch: xen.xend.xenstore.xswatch
+    @ivar shutdownStartTime: UNIX Time when domain started shutting down.
+    @type shutdownStartTime: float or None
+    @ivar restart_in_progress: Is a domain restart thread running?
+    @type restart_in_progress: bool
+#    @ivar state: Domain state
+#    @type state: enum(DOM_STATE_HALTED, DOM_STATE_RUNNING, ...)
+    @ivar state_updated: lock for self.state
+    @type state_updated: threading.Condition
+    @ivar refresh_shutdown_lock: lock for polling shutdown state
+    @type refresh_shutdown_lock: threading.Condition
+    @ivar _deviceControllers: device controller cache for this domain
+    @type _deviceControllers: dict 'string' to DevControllers
+    """
+    
+    def __init__(self, info, domid = None, dompath = None, augment = False,
+                 priv = False, resume = False, vmpath = None):
+        """Constructor for a domain
+
+        @param   info: parsed configuration
+        @type    info: dictionary
+        @keyword domid: Set initial domain id (if any)
+        @type    domid: int
+        @keyword dompath: Set initial dompath (if any)
+        @type    dompath: string
+        @keyword augment: Augment given info with xenstored VM info
+        @type    augment: bool
+        @keyword priv: Is a privileged domain (Dom 0)
+        @type    priv: bool
+        @keyword resume: Is this domain being resumed?
+        @type    resume: bool
+        """
+
+        self.info = info
+        if domid == None:
+            self.domid =  self.info.get('domid')
+        else:
+            self.domid = domid
+        self.guest_bitsize = None
+        self.alloc_mem = None
+        self.paused_by_admin = False
+
+        maxmem = self.info.get('memory_static_max', 0)
+        memory = self.info.get('memory_dynamic_max', 0)
+
+        if self.info.is_hvm() and maxmem > memory:
+            self.pod_enabled = True
+        else:
+            self.pod_enabled = False
+        
+        #REMOVE: uuid is now generated in XendConfig
+        #if not self._infoIsSet('uuid'):
+        #    self.info['uuid'] = uuid.toString(uuid.create())
+
+        # Find a unique /vm/<uuid>/<integer> path if not specified.
+        # This avoids conflict between pre-/post-migrate domains when doing
+        # localhost relocation.
+        self.vmpath = vmpath
+        i = 0
+        while self.vmpath == None:
+            self.vmpath = XS_VMROOT + self.info['uuid']
+            if i != 0:
+                self.vmpath = self.vmpath + '-' + str(i)
+            try:
+                if self._readVm("uuid"):
+                    self.vmpath = None
+                    i = i + 1
+            except:
+                pass
+
+        self.dompath = dompath
+
+        self.image = None
+        self.store_port = None
+        self.store_mfn = None
+        self.console_port = None
+        self.console_mfn = None
+
+        self.native_protocol = None
+
+        self.vmWatch = None
+        self.shutdownWatch = None
+        self.shutdownStartTime = None
+        self._resume = resume
+        self.restart_in_progress = False
+
+        self.state_updated = threading.Condition()
+        self.refresh_shutdown_lock = threading.Condition()
+        self._stateSet(DOM_STATE_HALTED)
+
+        self._deviceControllers = {}
+
+        for state in DOM_STATES_OLD:
+            self.info[state] = 0
+
+        if augment:
+            self._augmentInfo(priv)
+
+        self._checkName(self.info['name_label'])
+
+        self.metrics = XendVMMetrics(uuid.createString(), self)
+            
+
+    #
+    # Public functions available through XMLRPC
+    #
+
+
+    def start(self, is_managed = False):
+        """Attempts to start the VM by do the appropriate
+        initialisation if it not started.
+        """
+        from xen.xend import XendDomain
+
+        if self._stateGet() in (XEN_API_VM_POWER_STATE_HALTED, XEN_API_VM_POWER_STATE_SUSPENDED, XEN_API_VM_POWER_STATE_CRASHED):
+            try:
+                XendTask.log_progress(0, 30, self._constructDomain)
+                XendTask.log_progress(31, 60, self._initDomain)
+                
+                XendTask.log_progress(61, 70, self._storeVmDetails)
+                XendTask.log_progress(71, 80, self._storeDomDetails)
+                XendTask.log_progress(81, 90, self._registerWatches)
+                XendTask.log_progress(91, 100, self.refreshShutdown)
+
+                xendomains = XendDomain.instance()
+
+                # save running configuration if XendDomains believe domain is
+                # persistent
+                if is_managed:
+                    xendomains.managed_config_save(self)
+            except:
+                log.exception('VM start failed')
+                self.destroy()
+                raise
+        else:
+            raise XendError('VM already running')
+
+    def resume(self):
+        """Resumes a domain that has come back from suspension."""
+        state = self._stateGet()
+        if state in (DOM_STATE_SUSPENDED, DOM_STATE_HALTED):
+            try:
+                self._constructDomain()
+
+                try:
+                    self._setCPUAffinity()
+                except:
+                    # usually a CPU we want to set affinity to does not exist
+                    # we just ignore it so that the domain can still be restored
+                    log.warn("Cannot restore CPU affinity")
+
+                self._setSchedParams()
+                self._storeVmDetails()
+                self._createChannels()
+                self._createDevices()
+                self._storeDomDetails()
+                self._endRestore()
+            except:
+                log.exception('VM resume failed')
+                self.destroy()
+                raise
+        else:
+            raise XendError('VM is not suspended; it is %s'
+                            % XEN_API_VM_POWER_STATE[state])
+
+    def shutdown(self, reason):
+        """Shutdown a domain by signalling this via xenstored."""
+        log.debug('XendDomainInfo.shutdown(%s)', reason)
+        if self._stateGet() in (DOM_STATE_SHUTDOWN, DOM_STATE_HALTED,):
+            raise XendError('Domain cannot be shutdown')
+
+        if self.domid == 0:
+            raise XendError('Domain 0 cannot be shutdown')
+        
+        if reason not in DOMAIN_SHUTDOWN_REASONS.values():
+            raise XendError('Invalid reason: %s' % reason)
+        self.storeDom("control/shutdown", reason)
+
+        # HVM domain shuts itself down only if it has PV drivers
+        if self.info.is_hvm():
+            hvm_pvdrv = xc.hvm_get_param(self.domid, HVM_PARAM_CALLBACK_IRQ)
+            hvm_s_state = xc.hvm_get_param(self.domid, HVM_PARAM_ACPI_S_STATE)
+            if not hvm_pvdrv or hvm_s_state != 0:
+                code = REVERSE_DOMAIN_SHUTDOWN_REASONS[reason]
+                log.info("HVM save:remote shutdown dom %d!", self.domid)
+                xc.domain_shutdown(self.domid, code)
+
+    def pause(self):
+        """Pause domain
+        
+        @raise XendError: Failed pausing a domain
+        """
+        try:
+            if(self.domid):
+                # get all blktap2 devices
+                dev =  xstransact.List(self.vmpath + '/device/tap2')
+                for x in dev:
+                    path = self.getDeviceController('tap2').readBackend(x, 'params')
+                    if path and path.startswith(TapdiskController.TAP_DEV):
+                        TapdiskController.pause(path)
+        except Exception, ex:
+            log.warn('Could not pause blktap disk.');
+
+        try:
+            xc.domain_pause(self.domid)
+            self._stateSet(DOM_STATE_PAUSED)
+        except Exception, ex:
+            log.exception(ex)
+            raise XendError("Domain unable to be paused: %s" % str(ex))
+
+    def unpause(self):
+        """Unpause domain
+        
+        @raise XendError: Failed unpausing a domain
+        """
+        try:
+            if(self.domid):
+                dev =  xstransact.List(self.vmpath + '/device/tap2')
+                for x in dev:
+                    path = self.getDeviceController('tap2').readBackend(x, 'params')
+                    if path and path.startswith(TapdiskController.TAP_DEV):
+                        TapdiskController.unpause(path)
+
+        except Exception, ex:
+            log.warn('Could not unpause blktap disk: %s' % str(ex));
+
+        try:
+            xc.domain_unpause(self.domid)
+            self._stateSet(DOM_STATE_RUNNING)
+        except Exception, ex:
+            log.exception(ex)
+            raise XendError("Domain unable to be unpaused: %s" % str(ex))
+
+    def send_sysrq(self, key):
+        """ Send a Sysrq equivalent key via xenstored."""
+        if self._stateGet() not in (DOM_STATE_RUNNING, DOM_STATE_PAUSED):
+            raise XendError("Domain '%s' is not started" % self.info['name_label'])
+
+        asserts.isCharConvertible(key)
+        self.storeDom("control/sysrq", '%c' % key)
+
+    def pci_device_configure_boot(self):
+
+        if not self.info.is_hvm():
+            return
+
+        devid = '0'
+        first = True
+        dev_info = self._getDeviceInfo_pci(devid)
+        if dev_info is None:
+            return
+
+        # get the virtual slot info from xenstore
+        dev_uuid = sxp.child_value(dev_info, 'uuid')
+        pci_conf = self.info['devices'][dev_uuid][1]
+        pci_devs = pci_conf['devs']
+
+        # Keep a set of keys that are done rather than
+        # just itterating through set(map(..., pci_devs))
+        # to preserve any order information present.
+        done = set()
+        for key in map(lambda x: x['key'], pci_devs):
+            if key in done:
+                continue
+            done |= set([key])
+            dev = filter(lambda x: x['key'] == key, pci_devs)
+
+            head_dev = dev.pop()
+            dev_sxp = pci_convert_dict_to_sxp(head_dev, 'Initialising',
+                                              'Booting')
+            self.pci_device_configure(dev_sxp, first_dev = first)
+            first = False
+
+            # That is all for single-function virtual devices
+            if len(dev) == 0:
+                continue
+
+            if int(head_dev['vdevfn'], 16) & AUTO_PHP_SLOT:
+                new_dev_info = self._getDeviceInfo_pci(devid)
+                if new_dev_info is None:
+                    continue
+                new_dev_uuid = sxp.child_value(new_dev_info, 'uuid')
+                new_pci_conf = self.info['devices'][new_dev_uuid][1]
+                new_pci_devs = new_pci_conf['devs']
+
+                new_head_dev = filter(lambda x: pci_dict_cmp(x, head_dev),
+                                      new_pci_devs)[0]
+
+                if int(new_head_dev['vdevfn'], 16) & AUTO_PHP_SLOT:
+                    continue
+
+                vdevfn = PCI_SLOT(int(new_head_dev['vdevfn'], 16))
+                new_dev = []
+                for i in dev:
+                    i['vdevfn'] = '0x%02x' % \
+                                 PCI_DEVFN(vdevfn,
+                                           PCI_FUNC(int(i['vdevfn'], 16)))
+                    new_dev.append(i)
+
+                dev = new_dev
+
+            for i in dev:
+                dev_sxp = pci_convert_dict_to_sxp(i, 'Initialising', 'Booting')
+                self.pci_device_configure(dev_sxp)
+
+    def hvm_pci_device_create(self, dev_config):
+        log.debug("XendDomainInfo.hvm_pci_device_create: %s"
+                  % scrub_password(dev_config))
+
+        if not self.info.is_hvm():
+            raise VmError("hvm_pci_device_create called on non-HVM guest")
+
+        #all the PCI devs share one conf node
+        devid = '0'
+
+        new_dev = dev_config['devs'][0]
+        dev_info = self._getDeviceInfo_pci(devid)#from self.info['devices']
+
+        #check conflict before trigger hotplug event
+        if dev_info is not None:
+            dev_uuid = sxp.child_value(dev_info, 'uuid')
+            pci_conf = self.info['devices'][dev_uuid][1]
+            pci_devs = pci_conf['devs']
+            for x in pci_devs:
+                if (int(x['vdevfn'], 16) == int(new_dev['vdevfn'], 16) and
+                    not int(x['vdevfn'], 16) & AUTO_PHP_SLOT):
+                    raise VmError("vdevfn %s already have a device." %
+                                  (new_dev['vdevfn']))
+
+                if (pci_dict_cmp(x, new_dev)):
+                    raise VmError("device is already inserted")
+
+        # Test whether the devices can be assigned.
+        self.pci_dev_check_attachability_and_do_FLR(new_dev)
+
+        return self.hvm_pci_device_insert_dev(new_dev)
+
+    def iommu_check_pod_mode(self):
+        """ Disallow PCI device assignment if pod is enabled. """
+        if self.pod_enabled:
+            raise VmError("failed to assign device since pod is enabled")
+
+    def pci_dev_check_assignability_and_do_FLR(self, config):
+        """ In the case of static device assignment(i.e., the 'pci' string in
+        guest config file), we check if the device(s) specified in the 'pci'
+        can be  assigned to guest or not; if yes, we do_FLR the device(s).
+        """
+
+        self.iommu_check_pod_mode()
+        pci_dev_ctrl = self.getDeviceController('pci')
+        return pci_dev_ctrl.dev_check_assignability_and_do_FLR(config)
+
+    def pci_dev_check_attachability_and_do_FLR(self, new_dev):
+        """ In the case of dynamic device assignment(i.e., xm pci-attach), we
+        check if the device can be attached to guest or not; if yes, we do_FLR
+        the device.
+        """
+
+        self.iommu_check_pod_mode()
+
+        # Test whether the devices can be assigned
+
+        pci_name = pci_dict_to_bdf_str(new_dev)
+        _all_assigned_pci_devices =  get_all_assigned_pci_devices(self.domid)
+        if pci_name in _all_assigned_pci_devices:
+            raise VmError("failed to assign device %s that has"
+                          " already been assigned to other domain." % pci_name)
+
+        # Test whether the device is owned by pciback or pci-stub.
+        try:
+            pci_device = PciDevice(new_dev)
+        except Exception, e:
+            raise VmError("pci: failed to locate device and "+
+                    "parse its resources - "+str(e))
+        if pci_device.driver!='pciback' and pci_device.driver!='pci-stub':
+            raise VmError(("pci: PCI Backend and pci-stub don't own device %s")\
+                            %pci_device.name)
+
+        strict_check = xoptions.get_pci_dev_assign_strict_check()
+        # Check non-page-aligned MMIO BAR.
+        if pci_device.has_non_page_aligned_bar and strict_check:
+            raise VmError("pci: %s: non-page-aligned MMIO BAR found." % \
+                pci_device.name)
+
+        # PV guest has less checkings.
+        if not self.info.is_hvm():
+            # try to do FLR for PV guest
+            pci_device.do_FLR(self.info.is_hvm(), strict_check)
+            return
+
+        if not strict_check:
+            return
+
+        # Check if there is intermediate PCIe switch bewteen the device and
+        # Root Complex.
+        if pci_device.is_behind_switch_lacking_acs():
+            err_msg = 'pci: to avoid potential security issue, %s is not'+\
+                    ' allowed to be assigned to guest since it is behind'+\
+                    ' PCIe switch that does not support or enable ACS.'
+            raise VmError(err_msg % pci_device.name)
+
+        # Check the co-assignment.
+        # To pci-attach a device D to domN, we should ensure each of D's
+        # co-assignment devices hasn't been assigned, or has been assigned to
+        # domN.
+        coassignment_list = pci_device.find_coassigned_devices()
+        pci_device.devs_check_driver(coassignment_list)
+        assigned_pci_device_str_list = self._get_assigned_pci_devices()
+        for pci_str in coassignment_list:
+            if not (pci_str in _all_assigned_pci_devices):
+                continue
+            if not pci_str in assigned_pci_device_str_list:
+                raise VmError(("pci: failed to pci-attach %s to domain %s" + \
+                    " because one of its co-assignment device %s has been" + \
+                    " assigned to other domain." \
+                    )% (pci_device.name, self.info['name_label'], pci_str))
+
+        # try to do FLR for HVM guest
+        pci_device.do_FLR(self.info.is_hvm(), strict_check)
+
+    def hvm_pci_device_insert(self, dev_config):
+        log.debug("XendDomainInfo.hvm_pci_device_insert: %s"
+                  % scrub_password(dev_config))
+
+        if not self.info.is_hvm():
+            raise VmError("hvm_pci_device_create called on non-HVM guest")
+
+        new_dev = dev_config['devs'][0]
+
+        return self.hvm_pci_device_insert_dev(new_dev)
+
+    def hvm_pci_device_insert_dev(self, new_dev):
+        log.debug("XendDomainInfo.hvm_pci_device_insert_dev: %s"
+                  % scrub_password(new_dev))
+
+        if self.domid is not None:
+            opts = ''
+            optslist = []
+            pci_defopts = []
+            if 'pci_msitranslate' in self.info['platform']:
+                pci_defopts.append(['msitranslate',
+                        str(self.info['platform']['pci_msitranslate'])])
+            if 'pci_power_mgmt' in self.info['platform']:
+                pci_defopts.append(['power_mgmt',
+                        str(self.info['platform']['pci_power_mgmt'])])
+            if new_dev.has_key('opts'):
+                optslist += new_dev['opts']
+
+            if optslist or pci_defopts:
+                opts = ',' + serialise_pci_opts(
+                       append_default_pci_opts(optslist, pci_defopts))
+
+            bdf_str = "%s@%02x%s" % (pci_dict_to_bdf_str(new_dev),
+                                     int(new_dev['vdevfn'], 16), opts)
+            log.debug("XendDomainInfo.hvm_pci_device_insert_dev: %s" % bdf_str)
+            bdf = xc.assign_device(self.domid, pci_dict_to_xc_str(new_dev))
+            if bdf > 0:
+                raise VmError("Failed to assign device to IOMMU (%s)" % bdf_str)
+            log.debug("pci: assign device %s" % bdf_str)
+            self.image.signalDeviceModel('pci-ins', 'pci-inserted', bdf_str)
+
+            vdevfn = xstransact.Read("/local/domain/0/device-model/%i/parameter"
+                                    % self.getDomid())
+            try:
+                vdevfn_int = int(vdevfn, 16)
+            except ValueError:
+                raise VmError(("Cannot pass-through PCI function '%s'. " +
+                               "Device model reported an error: %s") %
+                              (bdf_str, vdevfn))
+        else:
+            vdevfn = new_dev['vdevfn']
+
+        return vdevfn
+
+
+    def device_create(self, dev_config):
+        """Create a new device.
+
+        @param dev_config: device configuration
+        @type  dev_config: SXP object (parsed config)
+        """
+        log.debug("XendDomainInfo.device_create: %s" % scrub_password(dev_config))
+        dev_type = sxp.name(dev_config)
+
+        if dev_type == 'vif':
+            for x in dev_config:
+                if x != 'vif' and x[0] == 'mac':
+                    if not re.match('^([0-9a-f]{2}:){5}[0-9a-f]{2}$', x[1], re.I):
+                        log.error("Virtual network interface creation error - invalid MAC Address entered: %s", x[1])
+                        raise VmError("Cannot create a new virtual network interface - MAC address is not valid!");
+
+        dev_uuid = self.info.device_add(dev_type, cfg_sxp = dev_config)
+        dev_config_dict = self.info['devices'][dev_uuid][1]
+        log.debug("XendDomainInfo.device_create: %s" % scrub_password(dev_config_dict))
+
+        if self.domid is not None:
+            try:
+                dev_config_dict['devid'] = devid = \
+                    self._createDevice(dev_type, dev_config_dict)
+                if dev_type == 'tap2':
+                    # createDevice may create a blktap1 device if blktap2 is not
+                    # installed or if the blktap driver is not supported in
+                    # blktap1
+                    dev_type = self.getBlockDeviceClass(devid)
+                self._waitForDevice(dev_type, devid)
+            except VmError, ex:
+                del self.info['devices'][dev_uuid]
+                if dev_type == 'pci':
+                    for dev in dev_config_dict['devs']:
+                        XendAPIStore.deregister(dev['uuid'], 'DPCI')
+                elif dev_type == 'vscsi':
+                    for dev in dev_config_dict['devs']:
+                        XendAPIStore.deregister(dev['uuid'], 'DSCSI')
+                elif dev_type == 'tap' or dev_type == 'tap2':
+                    self.info['vbd_refs'].remove(dev_uuid)
+                else:
+                    self.info['%s_refs' % dev_type].remove(dev_uuid)
+                raise ex
+        else:
+            devid = None
+
+        xen.xend.XendDomain.instance().managed_config_save(self)
+        return self.getDeviceController(dev_type).sxpr(devid)
+
+
+    def pci_device_configure(self, dev_sxp, devid = 0, first_dev = False):
+        """Configure an existing pci device.
+        
+        @param dev_sxp: device configuration
+        @type  dev_sxp: SXP object (parsed config)
+        @param devid:      device id
+        @type  devid:      int
+        @return: Returns True if successfully updated device
+        @rtype: boolean
+        """
+        log.debug("XendDomainInfo.pci_device_configure: %s"
+                  % scrub_password(dev_sxp))
+
+        dev_class = sxp.name(dev_sxp)
+
+        if dev_class != 'pci':
+            return False
+
+        pci_state = sxp.child_value(dev_sxp, 'state')
+        pci_sub_state = sxp.child_value(dev_sxp, 'sub_state')
+        existing_dev_info = self._getDeviceInfo_pci(devid)
+
+        if existing_dev_info is None and pci_state != 'Initialising':
+            raise XendError("Cannot detach when pci platform does not exist")
+
+        pci_dev = sxp.children(dev_sxp, 'dev')[0]
+        dev_config = pci_convert_sxp_to_dict(dev_sxp)
+        dev = dev_config['devs'][0]
+
+        stubdomid = self.getStubdomDomid()
+        # Do HVM specific processing
+        if self.info.is_hvm():
+            from xen.xend import XendDomain
+            if pci_state == 'Initialising':
+                if stubdomid is not None :
+                    XendDomain.instance().domain_lookup(stubdomid).pci_device_configure(dev_sxp[:])
+
+                # HVM PCI device attachment
+                if pci_sub_state == 'Booting':
+                    vdevfn = self.hvm_pci_device_insert(dev_config)
+                else:
+                    vdevfn = self.hvm_pci_device_create(dev_config)
+                # Update vdevfn
+                dev['vdevfn'] = vdevfn
+                for n in sxp.children(pci_dev):
+                    if(n[0] == 'vdevfn'):
+                        n[1] = vdevfn
+            else:
+                # HVM PCI device detachment
+                existing_dev_uuid = sxp.child_value(existing_dev_info, 'uuid')
+                existing_pci_conf = self.info['devices'][existing_dev_uuid][1]
+                existing_pci_devs = existing_pci_conf['devs']
+                new_devs = filter(lambda x: pci_dict_cmp(x, dev),
+                                  existing_pci_devs)
+                if len(new_devs) < 0:
+                    raise VmError("Device %s is not connected" %
+                                  pci_dict_to_bdf_str(dev))
+                new_dev = new_devs[0]
+                # Only tell qemu-dm to unplug function 0.
+                # When unplugging a function, all functions in the
+                # same vslot must be unplugged, and function 0 must
+                # be one of the functions present when a vslot is
+                # hot-plugged. Telling qemu-dm to unplug function 0
+                # also tells it to unplug all other functions in the
+                # same vslot.
+                if (PCI_FUNC(int(new_dev['vdevfn'], 16)) == 0):
+                    self.hvm_destroyPCIDevice(new_dev)
+                if stubdomid is not None :
+                    XendDomain.instance().domain_lookup(stubdomid).pci_device_configure(dev_sxp[:])
+                # Update vdevfn
+                dev['vdevfn'] = new_dev['vdevfn']
+                for n in sxp.children(pci_dev):
+                    if(n[0] == 'vdevfn'):
+                        n[1] = new_dev['vdevfn']
+        else:
+        # Do PV specific checking
+            if pci_state == 'Initialising':
+                # PV PCI device attachment
+                self.pci_dev_check_attachability_and_do_FLR(dev)
+
+        # If pci platform does not exist, create and exit.
+        if existing_dev_info is None :
+            self.device_create(dev_sxp)
+            return True
+
+        if first_dev is True :
+            existing_dev_uuid = sxp.child_value(existing_dev_info, 'uuid')
+            existing_pci_conf = self.info['devices'][existing_dev_uuid][1]
+            devid = self._createDevice('pci', existing_pci_conf)
+            self.info['devices'][existing_dev_uuid][1]['devid'] = devid
+
+        if self.domid is not None:
+            # use DevController.reconfigureDevice to change device config
+            dev_control = self.getDeviceController(dev_class)
+            dev_uuid = dev_control.reconfigureDevice(devid, dev_config)
+            if not self.info.is_hvm() and not self.info.is_stubdom():
+                # in PV case, wait until backend state becomes connected.
+                dev_control.waitForDevice_reconfigure(devid)
+            num_devs = dev_control.cleanupDevice(devid)
+
+            # update XendConfig with new device info
+            if dev_uuid:
+                new_dev_sxp = dev_control.configuration(devid)
+                self.info.device_update(dev_uuid, new_dev_sxp)
+
+            # If there is no device left, destroy pci and remove config.
+            if num_devs == 0:
+                if self.info.is_hvm():
+                    self.destroyDevice('pci', devid, True)
+                else:
+                    self.destroyDevice('pci', devid)
+                del self.info['devices'][dev_uuid]
+        else:
+            new_dev_sxp = ['pci']
+            for cur_dev in sxp.children(existing_dev_info, 'dev'):
+                if pci_state == 'Closing':
+                    if int(dev['domain'], 16) == int(sxp.child_value(cur_dev, 'domain'), 16) and \
+                       int(dev['bus'], 16) == int(sxp.child_value(cur_dev, 'bus'), 16) and \
+                       int(dev['slot'], 16) == int(sxp.child_value(cur_dev, 'slot'), 16) and \
+                       int(dev['func'], 16) == int(sxp.child_value(cur_dev, 'func'), 16):
+                        continue
+                new_dev_sxp.append(cur_dev)
+
+            if pci_state == 'Initialising' and pci_sub_state != 'Booting':
+                for new_dev in sxp.children(dev_sxp, 'dev'):
+                    new_dev_sxp.append(new_dev)
+
+            dev_uuid = sxp.child_value(existing_dev_info, 'uuid')
+            self.info.device_update(dev_uuid, new_dev_sxp)
+
+            # If there is no device left, remove config.
+            if len(sxp.children(new_dev_sxp, 'dev')) == 0:
+                del self.info['devices'][dev_uuid]
+
+        xen.xend.XendDomain.instance().managed_config_save(self)
+
+        return True
+
+    def vscsi_device_configure(self, dev_sxp):
+        """Configure an existing vscsi device.
+            quoted pci funciton
+        """
+        def _is_vscsi_defined(dev_info, p_devs = None, v_devs = None):
+            if not dev_info:
+                return False
+            for dev in sxp.children(dev_info, 'dev'):
+                if p_devs is not None:
+                    if sxp.child_value(dev, 'p-dev') in p_devs:
+                        return True
+                if v_devs is not None:
+                    if sxp.child_value(dev, 'v-dev') in v_devs:
+                        return True
+            return False
+
+        def _vscsi_be(be):
+            be_xdi = xen.xend.XendDomain.instance().domain_lookup_nr(be)
+            if be_xdi is not None:
+                be_domid = be_xdi.getDomid()
+                if be_domid is not None:
+                    return str(be_domid)
+            return str(be)
+
+        dev_class = sxp.name(dev_sxp)
+        if dev_class != 'vscsi':
+            return False
+
+        dev_config = self.info.vscsi_convert_sxp_to_dict(dev_sxp)
+        devs = dev_config['devs']
+        v_devs = [d['v-dev'] for d in devs]
+        state = devs[0]['state']
+        req_devid = int(devs[0]['devid'])
+        cur_dev_sxp = self._getDeviceInfo_vscsi(req_devid)
+
+        if state == xenbusState['Initialising']:
+            # new create
+            # If request devid does not exist, create and exit.
+            p_devs = [d['p-dev'] for d in devs]
+            for dev_type, dev_info in self.info.all_devices_sxpr():
+                if dev_type != 'vscsi':
+                    continue
+                if _is_vscsi_defined(dev_info, p_devs = p_devs):
+                    raise XendError('The physical device "%s" is already defined' % \
+                                    p_devs[0])
+            if cur_dev_sxp is None:
+                self.device_create(dev_sxp)
+                return True
+
+            if _is_vscsi_defined(cur_dev_sxp, v_devs = v_devs):
+                raise XendError('The virtual device "%s" is already defined' % \
+                                v_devs[0])
+
+            if int(dev_config['feature-host']) != \
+               int(sxp.child_value(cur_dev_sxp, 'feature-host')):
+                raise XendError('The physical device "%s" cannot define '
+                                'because mode is different' % devs[0]['p-dev'])
+
+            new_be = dev_config.get('backend', None)
+            if new_be is not None:
+                cur_be = sxp.child_value(cur_dev_sxp, 'backend', None)
+                if cur_be is None:
+                    cur_be = xen.xend.XendDomain.DOM0_ID
+                new_be_dom = _vscsi_be(new_be)
+                cur_be_dom = _vscsi_be(cur_be)
+                if new_be_dom != cur_be_dom:
+                    raise XendError('The physical device "%s" cannot define '
+                                    'because backend is different' % devs[0]['p-dev'])
+
+        elif state == xenbusState['Closing']:
+            if not _is_vscsi_defined(cur_dev_sxp, v_devs = v_devs):
+                raise XendError("Cannot detach vscsi device does not exist")
+
+        if self.domid is not None:
+            # use DevController.reconfigureDevice to change device config
+            dev_control = self.getDeviceController(dev_class)
+            dev_uuid = dev_control.reconfigureDevice(req_devid, dev_config)
+            dev_control.waitForDevice_reconfigure(req_devid)
+            num_devs = dev_control.cleanupDevice(req_devid)
+
+            # update XendConfig with new device info
+            if dev_uuid:
+                new_dev_sxp = dev_control.configuration(req_devid)
+                self.info.device_update(dev_uuid, new_dev_sxp)
+
+            # If there is no device left, destroy vscsi and remove config.
+            if num_devs == 0:
+                self.destroyDevice('vscsi', req_devid)
+                del self.info['devices'][dev_uuid]
+
+        else:
+            new_dev_sxp = ['vscsi']
+            cur_mode = sxp.children(cur_dev_sxp, 'feature-host')[0]
+            new_dev_sxp.append(cur_mode)
+            try:
+                cur_be = sxp.children(cur_dev_sxp, 'backend')[0]
+                new_dev_sxp.append(cur_be)
+            except IndexError:
+                pass
+
+            for cur_dev in sxp.children(cur_dev_sxp, 'dev'):
+                if state == xenbusState['Closing']:
+                    if int(cur_mode[1]) == 1:
+                        continue
+                    if sxp.child_value(cur_dev, 'v-dev') in v_devs:
+                        continue
+                new_dev_sxp.append(cur_dev)
+
+            if state == xenbusState['Initialising']:
+                for new_dev in sxp.children(dev_sxp, 'dev'):
+                    new_dev_sxp.append(new_dev)
+
+            dev_uuid = sxp.child_value(cur_dev_sxp, 'uuid')
+            self.info.device_update(dev_uuid, new_dev_sxp)
+
+            # If there is only 'vscsi' in new_dev_sxp, remove the config.
+            if len(sxp.children(new_dev_sxp, 'dev')) == 0:
+                del self.info['devices'][dev_uuid]
+
+        xen.xend.XendDomain.instance().managed_config_save(self)
+
+        return True
+
+    def vusb_device_configure(self, dev_sxp, devid):
+        """Configure a virtual root port.
+        """
+        dev_class = sxp.name(dev_sxp)
+        if dev_class != 'vusb':
+            return False
+
+        dev_config = {}
+        ports = sxp.child(dev_sxp, 'port')
+        for port in ports[1:]:
+            try:
+                num, bus = port
+                dev_config['port-%i' % int(num)] = str(bus)
+            except TypeError:
+                pass
+
+        dev_control = self.getDeviceController(dev_class)
+        dev_control.reconfigureDevice(devid, dev_config)
+
+        return True
+
+    def device_configure(self, dev_sxp, devid = None):
+        """Configure an existing device.
+        
+        @param dev_config: device configuration
+        @type  dev_config: SXP object (parsed config)
+        @param devid:      device id
+        @type  devid:      int
+        @return: Returns True if successfully updated device
+        @rtype: boolean
+        """
+
+        # convert device sxp to a dict
+        dev_class = sxp.name(dev_sxp)
+        dev_config = {}
+
+        if dev_class == 'pci':
+            return self.pci_device_configure(dev_sxp)
+
+        if dev_class == 'vscsi':
+            return self.vscsi_device_configure(dev_sxp)
+
+        if dev_class == 'vusb':
+            return self.vusb_device_configure(dev_sxp, devid)
+
+        for opt_val in dev_sxp[1:]:
+            try:
+                dev_config[opt_val[0]] = opt_val[1]
+            except IndexError:
+                pass
+
+        dev_control = self.getDeviceController(dev_class)
+        if devid is None:
+            dev = dev_config.get('dev', '')
+            if not dev:
+                raise VmError('Block device must have virtual details specified')
+            if 'ioemu:' in dev:
+                (_, dev) = dev.split(':', 1)
+            try:
+                (dev, _) = dev.split(':', 1)  # Remove ":disk" or ":cdrom"
+            except ValueError:
+                pass
+            devid = dev_control.convertToDeviceNumber(dev)
+        dev_info = self._getDeviceInfo_vbd(devid)
+        if dev_info is None:
+            raise VmError("Device %s not connected" % devid)
+        dev_uuid = sxp.child_value(dev_info, 'uuid')
+
+        if self.domid is not None:
+            # use DevController.reconfigureDevice to change device config
+            dev_control.reconfigureDevice(devid, dev_config)
+        else:
+            (_, new_b, new_f) = dev_control.getDeviceDetails(dev_config)
+            if (new_f['device-type'] == 'cdrom' and
+                sxp.child_value(dev_info, 'dev').endswith(':cdrom') and
+                new_b['mode'] == 'r' and
+                sxp.child_value(dev_info, 'mode') == 'r'):
+                pass
+            else:
+                raise VmError('Refusing to reconfigure device %s:%d to %s' %
+                              (dev_class, devid, dev_config))
+
+        # update XendConfig with new device info
+        self.info.device_update(dev_uuid, dev_sxp)
+        xen.xend.XendDomain.instance().managed_config_save(self)
+
+        return True
+
+    def waitForDevices(self):
+        """Wait for this domain's configured devices to connect.
+
+        @raise VmError: if any device fails to initialise.
+        """
+        for devclass in XendDevices.valid_devices():
+            self.getDeviceController(devclass).waitForDevices()
+
+    def hvm_destroyPCIDevice(self, pci_dev):
+        log.debug("hvm_destroyPCIDevice: %s", pci_dev)
+
+        if not self.info.is_hvm():
+            raise VmError("hvm_destroyPCIDevice called on non-HVM guest")
+
+        # Check the co-assignment.
+        # To pci-detach a device D from domN, we should ensure: for each DD in the
+        # list of D's co-assignment devices, DD is not assigned (to domN).
+        # 
+        from xen.xend.server.pciif import PciDevice
+        try:
+            pci_device = PciDevice(pci_dev)
+        except Exception, e:
+            raise VmError("pci: failed to locate device and "+
+                    "parse its resources - "+str(e))
+        coassignment_list = pci_device.find_coassigned_devices()
+        coassignment_list.remove(pci_device.name)
+        assigned_pci_device_str_list = self._get_assigned_pci_devices()
+        for pci_str in coassignment_list:
+            if xoptions.get_pci_dev_assign_strict_check() and \
+                pci_str in assigned_pci_device_str_list:
+                raise VmError(("pci: failed to pci-detach %s from domain %s" + \
+                    " because one of its co-assignment device %s is still " + \
+                    " assigned to the domain." \
+                    )% (pci_device.name, self.info['name_label'], pci_str))
+
+
+        bdf_str = pci_dict_to_bdf_str(pci_dev)
+        log.info("hvm_destroyPCIDevice:%s:%s!", pci_dev, bdf_str)
+        if self.domid is not None:
+            self.image.signalDeviceModel('pci-rem', 'pci-removed', bdf_str)
+
+        return 0
+
+    def destroyDevice(self, deviceClass, devid, force = False, rm_cfg = False):
+        log.debug("XendDomainInfo.destroyDevice: deviceClass = %s, device = %s",
+                  deviceClass, devid)
+
+        if rm_cfg:
+            # Convert devid to device number.  A device number is
+            # needed to remove its configuration.
+            dev = self.getDeviceController(deviceClass).convertToDeviceNumber(devid)
+            
+            # Save current sxprs.  A device number and a backend
+            # path are needed to remove its configuration but sxprs
+            # do not have those after calling destroyDevice.
+            sxprs = self.getDeviceSxprs(deviceClass)
+
+        rc = None
+        if self.domid is not None:
+            
+            #new blktap implementation may need a sysfs write after everything is torn down.
+            if deviceClass == 'tap2':
+                dev = self.getDeviceController(deviceClass).convertToDeviceNumber(devid)
+                path = self.getDeviceController(deviceClass).readBackend(dev, 'params')
+                frontpath = self.getDeviceController(deviceClass).frontendPath(dev)
+                backpath = xstransact.Read(frontpath, "backend")
+                thread.start_new_thread(self.getDeviceController(deviceClass).finishDeviceCleanup, (backpath, path))
+
+            rc = self.getDeviceController(deviceClass).destroyDevice(devid, force)
+            if not force and rm_cfg:
+                # The backend path, other than the device itself,
+                # has to be passed because its accompanied frontend
+                # path may be void until its removal is actually
+                # issued.  It is probable because destroyDevice is
+                # issued first.
+                for dev_num, dev_info in sxprs:
+                    dev_num = int(dev_num)
+                    if dev_num == dev:
+                        for x in dev_info:
+                            if x[0] == 'backend':
+                                backend = x[1]
+                                break
+                        break
+                self._waitForDevice_destroy(deviceClass, devid, backend)
+
+        if rm_cfg and deviceClass != "vif2":
+            if deviceClass == 'vif':
+                if self.domid is not None:
+                    mac = ''
+                    for dev_num, dev_info in sxprs:
+                        dev_num = int(dev_num)
+                        if dev_num == dev:
+                            for x in dev_info:
+                                if x[0] == 'mac':
+                                    mac = x[1]
+                                    break
+                            break
+                    dev_info = self._getDeviceInfo_vif(mac)
+                else:
+                    _, dev_info = sxprs[dev]
+            else:  # 'vbd' or 'tap' or 'tap2'
+                dev_info = self._getDeviceInfo_vbd(dev)
+                # To remove the UUID of the device from refs,
+                # deviceClass must be always 'vbd'.
+                deviceClass = 'vbd'
+            if dev_info is None:
+                raise XendError("Device %s is not defined" % devid)
+
+            dev_uuid = sxp.child_value(dev_info, 'uuid')
+            del self.info['devices'][dev_uuid]
+            self.info['%s_refs' % deviceClass].remove(dev_uuid)
+            xen.xend.XendDomain.instance().managed_config_save(self)
+
+        return rc
+
+    def getDeviceSxprs(self, deviceClass):
+        if deviceClass == 'pci':
+            dev_info = self._getDeviceInfo_pci('0')#from self.info['devices']
+            if dev_info is None:
+                return []
+            dev_uuid = sxp.child_value(dev_info, 'uuid')
+            pci_devs = self.info['devices'][dev_uuid][1]['devs']
+            return pci_devs
+        if self._stateGet() in (DOM_STATE_RUNNING, DOM_STATE_PAUSED, DOM_STATE_CRASHED):
+            return self.getDeviceController(deviceClass).sxprs()
+        else:
+            sxprs = []
+            dev_num = 0
+            for dev_type, dev_info in self.info.all_devices_sxpr():
+                if (deviceClass == 'vbd' and dev_type not in ['vbd', 'tap', 'tap2']) or \
+                   (deviceClass != 'vbd' and dev_type != deviceClass):
+                    continue
+
+                if deviceClass == 'vscsi':
+                    vscsi_devs = ['devs', []]
+                    for vscsi_dev in sxp.children(dev_info, 'dev'):
+                        vscsi_dev.append(['frontstate', None])
+                        vscsi_devs[1].append(vscsi_dev)
+                        dev_num = int(sxp.child_value(vscsi_dev, 'devid'))
+                    vscsi_mode = sxp.children(dev_info, 'feature-host')[0]
+                    sxprs.append([dev_num, [vscsi_devs, vscsi_mode]])
+                elif deviceClass == 'vbd':
+                    dev = sxp.child_value(dev_info, 'dev')
+                    if 'ioemu:' in dev:
+                        (_, dev) = dev.split(':', 1)
+                    try:
+                        (dev_name, _) = dev.split(':', 1)  # Remove ":disk" or ":cdrom"
+                    except ValueError:
+                        dev_name = dev
+                    dev_num = self.getDeviceController('vbd').convertToDeviceNumber(dev_name)
+                    sxprs.append([dev_num, dev_info])
+                else:
+                    sxprs.append([dev_num, dev_info])
+                    dev_num += 1
+            return sxprs
+
+    def getBlockDeviceClass(self, devid):
+        # if the domain is running we can get the device class from xenstore.
+        # This is more accurate, as blktap1 devices show up as blktap2 devices
+        # in the config.
+        if self._stateGet() in (DOM_STATE_RUNNING, DOM_STATE_PAUSED, DOM_STATE_CRASHED):
+            # All block devices have a vbd frontend, so we know the frontend path
+            dev = self.getDeviceController('vbd').convertToDeviceNumber(devid)
+            frontendPath = "%s/device/vbd/%s" % (self.dompath, dev)
+            for devclass in XendDevices.valid_devices():
+                for dev in xstransact.List("%s/device/%s" % (self.vmpath, devclass)):
+                    devFrontendPath = xstransact.Read("%s/device/%s/%s/frontend" % (self.vmpath, devclass, dev))
+                    if frontendPath == devFrontendPath:
+                        return devclass
+
+        else: # the domain is not active so we must get the device class
+              # from the config
+            # To get a device number from the devid,
+            # we temporarily use the device controller of VBD.
+            dev = self.getDeviceController('vbd').convertToDeviceNumber(devid)
+            dev_info = self._getDeviceInfo_vbd(dev)
+            if dev_info:
+                return dev_info[0]
+
+    def _getDeviceInfo_vif(self, mac):
+        for dev_type, dev_info in self.info.all_devices_sxpr():
+            if dev_type != 'vif':
+                continue
+            if mac == sxp.child_value(dev_info, 'mac'):
+                return dev_info
+
+    def _getDeviceInfo_vbd(self, devid):
+        for dev_type, dev_info in self.info.all_devices_sxpr():
+            if dev_type != 'vbd' and dev_type != 'tap' and dev_type != 'tap2':
+                continue
+            dev = sxp.child_value(dev_info, 'dev')
+            dev = dev.split(':')[0]
+            dev = self.getDeviceController(dev_type).convertToDeviceNumber(dev)
+            if devid == dev:
+                return dev_info
+
+    def _getDeviceInfo_pci(self, devid):
+        for dev_type, dev_info in self.info.all_devices_sxpr():
+            if dev_type != 'pci':
+                continue
+            return dev_info
+        return None
+
+    def _getDeviceInfo_vscsi(self, devid):
+        devid = int(devid)
+        for dev_type, dev_info in self.info.all_devices_sxpr():
+            if dev_type != 'vscsi':
+                continue
+            devs = sxp.children(dev_info, 'dev')
+            if devid == int(sxp.child_value(devs[0], 'devid')):
+                return dev_info
+        return None
+
+    def _getDeviceInfo_vusb(self, devid):
+        for dev_type, dev_info in self.info.all_devices_sxpr():
+            if dev_type != 'vusb':
+                continue
+            return dev_info
+        return None
+
+    def _get_assigned_pci_devices(self, devid = 0):
+        if self.domid is not None:
+            return get_assigned_pci_devices(self.domid)
+
+        dev_info = self._getDeviceInfo_pci(devid)
+        if dev_info is None:
+            return []
+        dev_uuid = sxp.child_value(dev_info, 'uuid')
+        pci_conf = self.info['devices'][dev_uuid][1]
+        return map(pci_dict_to_bdf_str, pci_conf['devs'])
+
+    def setMigrateConstraints(self, max_iters, max_factor, min_remaining, abort_if_busy, log_save_progress):
+        """Set the Migrate Constraints of this domain.
+        @param max_iters: Number of iterations before final suspend
+        @param max_factor: Max amount of memory to transfer before final suspend
+        @param min_remaining: Number of dirty pages before final suspend
+        @param abort_if_busy: Abort migration instead of doing final suspend
+        @param log_save_progress: Log progress of migrate to xend.log
+        """
+        log.debug("Setting migration constraints of domain %s (%s) to '%s' '%s' '%s' '%s'.",
+                  self.info['name_label'], str(self.domid), max_iters, max_factor, min_remaining, abort_if_busy)
+        self.info['max_iters'] = str(max_iters)
+        self.info['max_factor'] = str(max_factor)
+        self.info['min_remaining'] = str(min_remaining)
+        self.info['abort_if_busy'] = str(abort_if_busy)
+        self.info['log_save_progress'] = str(log_save_progress)
+
+    def setMemoryTarget(self, target):
+        """Set the memory target of this domain.
+        @param target: In MiB.
+        """
+        log.debug("Setting memory target of domain %s (%s) to %d MiB.",
+                  self.info['name_label'], str(self.domid), target)
+        
+        MiB = 1024 * 1024
+        memory_cur = self.get_memory_dynamic_max() / MiB
+
+        if self.domid == 0:
+            dom0_min_mem = xoptions.get_dom0_min_mem()
+            if target < memory_cur and dom0_min_mem > target:
+                raise XendError("memory_dynamic_max too small")
+
+        self._safe_set_memory('memory_dynamic_min', target * MiB)
+        self._safe_set_memory('memory_dynamic_max', target * MiB)
+
+        if self.domid >= 0:
+            if target > memory_cur:
+                balloon.free((target - memory_cur) * 1024, self)
+            self.storeVm("memory", target)
+            self.storeDom("memory/target", target << 10)
+            xc.domain_set_target_mem(self.domid,
+                                     (target * 1024))
+        xen.xend.XendDomain.instance().managed_config_save(self)
+
+    def setMemoryMaximum(self, limit):
+        """Set the maximum memory limit of this domain
+        @param limit: In MiB.
+        """
+        log.debug("Setting memory maximum of domain %s (%s) to %d MiB.",
+                  self.info['name_label'], str(self.domid), limit)
+
+        maxmem_cur = self.get_memory_static_max()
+        MiB = 1024 * 1024
+        self._safe_set_memory('memory_static_max', limit * MiB)
+
+        if self.domid >= 0:
+            maxmem = int(limit) * 1024
+            try:
+                return xc.domain_setmaxmem(self.domid, maxmem)
+            except Exception, ex:
+                self._safe_set_memory('memory_static_max', maxmem_cur)
+                raise XendError(str(ex))
+        xen.xend.XendDomain.instance().managed_config_save(self)
+
+
+    def getVCPUInfo(self):
+        try:
+            # We include the domain name and ID, to help xm.
+            sxpr = ['domain',
+                    ['domid',      self.domid],
+                    ['name',       self.info['name_label']],
+                    ['vcpu_count', self.info['VCPUs_max']]]
+
+            for i in range(0, self.info['VCPUs_max']):
+                if self.domid is not None:
+                    info = xc.vcpu_getinfo(self.domid, i)
+
+                    sxpr.append(['vcpu',
+                                 ['number',   i],
+                                 ['online',   info['online']],
+                                 ['blocked',  info['blocked']],
+                                 ['running',  info['running']],
+                                 ['cpu_time', info['cpu_time'] / 1e9],
+                                 ['cpu',      info['cpu']],
+                                 ['cpumap',   info['cpumap']]])
+                else:
+                    sxpr.append(['vcpu',
+                                 ['number',   i],
+                                 ['online',   0],
+                                 ['blocked',  0],
+                                 ['running',  0],
+                                 ['cpu_time', 0.0],
+                                 ['cpu',      -1],
+                                 ['cpumap',   self.info['cpus'][i] and \
+                                              self.info['cpus'][i] or range(64)]])
+
+            return sxpr
+
+        except RuntimeError, exn:
+            raise XendError(str(exn))
+
+
+    def getDomInfo(self):
+        return dom_get(self.domid)
+
+    #
+    # internal functions ... TODO: re-categorised
+    # 
+
+    def _augmentInfo(self, priv):
+        """Augment self.info, as given to us through L{recreate}, with
+        values taken from the store.  This recovers those values known
+        to xend but not to the hypervisor.
+        """
+        augment_entries = XendConfig.LEGACY_XENSTORE_VM_PARAMS[:]
+        if priv:
+            augment_entries.remove('memory')
+            augment_entries.remove('maxmem')
+            augment_entries.remove('vcpus')
+            augment_entries.remove('vcpu_avail')
+
+        vm_config = self._readVMDetails([(k, XendConfig.LEGACY_CFG_TYPES[k])
+                                         for k in augment_entries])
+        
+        # make returned lists into a dictionary
+        vm_config = dict(zip(augment_entries, vm_config))
+        
+        for arg in augment_entries:
+            val = vm_config[arg]
+            if val != None:
+                if arg in XendConfig.LEGACY_CFG_TO_XENAPI_CFG:
+                    xapiarg = XendConfig.LEGACY_CFG_TO_XENAPI_CFG[arg]
+                    self.info[xapiarg] = val
+                elif arg == "memory":
+                    self.info["static_memory_min"] = val
+                elif arg == "maxmem":
+                    self.info["static_memory_max"] = val
+                else:
+                    self.info[arg] = val
+
+        # read CPU Affinity
+        self.info['cpus'] = []
+        vcpus_info = self.getVCPUInfo()
+        for vcpu_info in sxp.children(vcpus_info, 'vcpu'):
+            self.info['cpus'].append(sxp.child_value(vcpu_info, 'cpumap'))
+
+        # For dom0, we ignore any stored value for the vcpus fields, and
+        # read the current value from Xen instead.  This allows boot-time
+        # settings to take precedence over any entries in the store.
+        if priv:
+            xeninfo = dom_get(self.domid)
+            self.info['VCPUs_max'] = xeninfo['online_vcpus']
+            self.info['vcpu_avail'] = (1 << xeninfo['online_vcpus']) - 1
+
+        # read image value
+        image_sxp = self._readVm('image')
+        if image_sxp:
+            self.info.update_with_image_sxp(sxp.from_string(image_sxp))
+
+        # read devices
+        devices = []
+        for devclass in XendDevices.valid_devices():
+            devconfig = self.getDeviceController(devclass).configurations()
+            if devconfig:
+                devices.extend(devconfig)
+
+        if not self.info['devices'] and devices is not None:
+            for device in devices:
+                self.info.device_add(device[0], cfg_sxp = device)
+
+        self._update_consoles()
+
+    def _update_consoles(self, transaction = None):
+        if self.domid == None or self.domid == 0:
+            return
+
+        # Update VT100 port if it exists
+        if transaction is None:
+            self.console_port = self.readDom('console/port')
+        else:
+            self.console_port = self.readDomTxn(transaction, 'console/port')
+        if self.console_port is not None:
+            serial_consoles = self.info.console_get_all('vt100')
+            if not serial_consoles:
+                cfg = self.info.console_add('vt100', self.console_port)
+                self._createDevice('console', cfg)
+            else:
+                console_uuid = serial_consoles[0].get('uuid')
+                self.info.console_update(console_uuid, 'location',
+                                         self.console_port)
+                # Notify xenpv device model that console info is ready
+                if not self.info.is_hvm() and self.info.has_rfb():
+                    console_ctrl = self.getDeviceController('console')
+                    # The value is unchanged. Just for xenstore watcher
+                    console_ctrl.writeBackend(0, 'uuid', console_uuid)
+                
+
+        # Update VNC port if it exists and write to xenstore
+        if transaction is None:
+            vnc_port = self.readDom('console/vnc-port')
+        else:
+            vnc_port = self.readDomTxn(transaction, 'console/vnc-port')
+        if vnc_port is not None:
+            for dev_uuid, (dev_type, dev_info) in self.info['devices'].items():
+                if dev_type == 'vfb':
+                    old_location = dev_info.get('location')
+                    listen_host = dev_info.get('vnclisten', \
+                                XendOptions.instance().get_vnclisten_address())
+                    new_location = '%s:%s' % (listen_host, str(vnc_port))
+                    if old_location == new_location:
+                        break
+
+                    dev_info['location'] = new_location
+                    self.info.device_update(dev_uuid, cfg_xenapi = dev_info)
+                    vfb_ctrl = self.getDeviceController('vfb')
+                    vfb_ctrl.reconfigureDevice(0, dev_info)
+                    break
+                
+    #
+    # Function to update xenstore /vm/*
+    #
+
+    def _readVm(self, *args):
+        return xstransact.Read(self.vmpath, *args)
+
+    def _writeVm(self, *args):
+        return xstransact.Write(self.vmpath, *args)
+
+    def _removeVm(self, *args):
+        return xstransact.Remove(self.vmpath, *args)
+
+    def _gatherVm(self, *args):
+        return xstransact.Gather(self.vmpath, *args)
+
+    def _listRecursiveVm(self, *args):
+        return xstransact.ListRecursive(self.vmpath, *args)
+
+    def storeVm(self, *args):
+        return xstransact.Store(self.vmpath, *args)
+
+    def permissionsVm(self, *args):
+        return xstransact.SetPermissions(self.vmpath, *args)
+
+    #
+    # Function to update xenstore /dom/*
+    #
+
+    def readDom(self, *args):
+        return xstransact.Read(self.dompath, *args)
+
+    def gatherDom(self, *args):
+        return xstransact.Gather(self.dompath, *args)
+
+    def _writeDom(self, *args):
+        return xstransact.Write(self.dompath, *args)
+
+    def _removeDom(self, *args):
+        return xstransact.Remove(self.dompath, *args)
+
+    def storeDom(self, *args):
+        return xstransact.Store(self.dompath, *args)
+
+
+    def readDomTxn(self, transaction, *args):
+        paths = map(lambda x: self.dompath + "/" + x, args)
+        return transaction.read(*paths)
+
+    def gatherDomTxn(self, transaction, *args):
+        paths = map(lambda x: self.dompath + "/" + x, args)
+        return transaction.gather(*paths)
+
+    def _writeDomTxn(self, transaction, *args):
+        paths = map(lambda x: self.dompath + "/" + x, args)
+        return transaction.write(*paths)
+
+    def _removeDomTxn(self, transaction, *args):
+        paths = map(lambda x: self.dompath + "/" + x, args)
+        return transaction.remove(*paths)
+
+    def storeDomTxn(self, transaction, *args):
+        paths = map(lambda x: self.dompath + "/" + x, args)
+        return transaction.store(*paths)
+
+
+    def _recreateDom(self):
+        complete(self.dompath, lambda t: self._recreateDomFunc(t))
+
+    def _recreateDomFunc(self, t):
+        t.remove()
+        t.mkdir()
+        t.set_permissions({'dom' : self.domid, 'read' : True})
+        t.write('vm', self.vmpath)
+        # NB. Solaris guests use guest/ and hvmpv/ xenstore directories
+        #     XCP Windows paravirtualized guests use data/
+        for i in [ 'device', 'control', 'error', 'memory', 'guest', \
+                   'hvmpv', 'data' ]:
+            t.mkdir(i)
+            t.set_permissions(i, {'dom' : self.domid})
+
+    def _storeDomDetails(self):
+        to_store = {
+            'domid':              str(self.domid),
+            'vm':                 self.vmpath,
+            'name':               self.info['name_label'],
+            'console/limit':      str(xoptions.get_console_limit() * 1024),
+            'memory/target':      str(self.info['memory_dynamic_max'] / 1024),
+            'description':        str(self.info['description']),
+            }
+
+        def f(n, v):
+            if v is not None:
+                if type(v) == bool:
+                    to_store[n] = v and "1" or "0"
+                else:
+                    to_store[n] = str(v)
+
+        # Figure out if we need to tell xenconsoled to ignore this guest's
+        # console - device model will handle console if it is running
+        constype = "ioemu"
+        if 'device_model' not in self.info['platform']:
+            constype = "xenconsoled"
+
+        f('console/port',     self.console_port)
+        f('console/ring-ref', self.console_mfn)
+        f('console/type',     constype)
+        f('store/port',       self.store_port)
+        f('store/ring-ref',   self.store_mfn)
+
+        f('control/platform-feature-xs_reset_watches', True)
+        if arch.type == "x86":
+            f('control/platform-feature-multiprocessor-suspend', True)
+
+        # elfnotes
+        for n, v in self.info.get_notes().iteritems():
+            n = n.lower().replace('_', '-')
+            if n == 'features':
+                for v in v.split('|'):
+                    v = v.replace('_', '-')
+                    if v.startswith('!'):
+                        f('image/%s/%s' % (n, v[1:]), False)
+                    else:
+                        f('image/%s/%s' % (n, v), True)
+            else:
+                f('image/%s' % n, v)
+
+        if self.info.has_key('security_label'):
+            f('security_label', self.info['security_label'])
+
+        to_store.update(self._vcpuDomDetails())
+
+        log.debug("Storing domain details: %s", scrub_password(to_store))
+
+        self._writeDom(to_store)
+
+    def _vcpuDomDetails(self):
+        def availability(n):
+            if self.info['vcpu_avail'] & (1 << n):
+                return 'online'
+            else:
+                return 'offline'
+
+        result = {}
+        for v in range(0, self.info['VCPUs_max']):
+            result["cpu/%d/availability" % v] = availability(v)
+        return result
+
+    #
+    # xenstore watches
+    #
+
+    def _registerWatches(self):
+        """Register a watch on this VM's entries in the store, and the
+        domain's control/shutdown node, so that when they are changed
+        externally, we keep up to date.  This should only be called by {@link
+        #create}, {@link #recreate}, or {@link #restore}, once the domain's
+        details have been written, but before the new instance is returned."""
+        self.vmWatch = xswatch(self.vmpath, self._storeChanged)
+        self.shutdownWatch = xswatch(self.dompath + '/control/shutdown',
+                                     self._handleShutdownWatch)
+
+    def _storeChanged(self, _):
+        log.trace("XendDomainInfo.storeChanged");
+
+        changed = False
+
+        # Check whether values in the configuration have
+        # changed in Xenstore.
+        
+        cfg_vm = ['name', 'on_poweroff', 'on_reboot', 'on_crash',
+                  'rtc/timeoffset']
+        
+        vm_details = self._readVMDetails([(k,XendConfig.LEGACY_CFG_TYPES[k])
+                                           for k in cfg_vm])
+
+        # convert two lists into a python dictionary
+        vm_details = dict(zip(cfg_vm, vm_details))
+
+        for arg, val in vm_details.items():
+            if arg in XendConfig.LEGACY_CFG_TO_XENAPI_CFG:
+                xapiarg = XendConfig.LEGACY_CFG_TO_XENAPI_CFG[arg]
+                if val != None and val != self.info[xapiarg]:
+                    self.info[xapiarg] = val
+                    changed = True
+            elif arg == "memory":
+                if val != None and val != self.info["static_memory_min"]:
+                    self.info["static_memory_min"] = val
+                    changed = True
+            elif arg == "maxmem":
+                if val != None and val != self.info["static_memory_max"]:
+                    self.info["static_memory_max"] = val
+                    changed = True
+
+        # Check whether image definition has been updated
+        image_sxp = self._readVm('image')
+        if image_sxp and image_sxp != sxp.to_string(self.info.image_sxpr()):
+            self.info.update_with_image_sxp(sxp.from_string(image_sxp))
+            changed = True
+
+        # Update the rtc_timeoffset to be preserved across reboot.
+        # NB. No need to update xenstore domain section.
+        val = int(vm_details.get("rtc/timeoffset", 0))
+        self.info["platform"]["rtc_timeoffset"] = val
+ 
+        if changed:
+            # Update the domain section of the store, as this contains some
+            # parameters derived from the VM configuration.
+            self.refresh_shutdown_lock.acquire()
+            try:
+                state = self._stateGet()
+                if state not in (DOM_STATE_SHUTDOWN, DOM_STATE_HALTED,):
+                    self._storeDomDetails()
+            finally:
+                self.refresh_shutdown_lock.release()
+
+        return 1
+
+    def _handleShutdownWatch(self, _):
+        log.debug('XendDomainInfo.handleShutdownWatch')
+        
+        reason = self.readDom('control/shutdown')
+
+        if reason and reason != 'suspend':
+            sst = self.readDom('xend/shutdown_start_time')
+            now = time.time()
+            if sst:
+                self.shutdownStartTime = float(sst)
+                timeout = float(sst) + SHUTDOWN_TIMEOUT - now
+            else:
+                self.shutdownStartTime = now
+                self.storeDom('xend/shutdown_start_time', now)
+                timeout = SHUTDOWN_TIMEOUT
+
+            log.trace(
+                "Scheduling refreshShutdown on domain %d in %ds.",
+                self.domid, timeout)
+            threading.Timer(timeout, self.refreshShutdown).start()
+            
+        return True
+
+
+    #
+    # Public Attributes for the VM
+    #
+
+
+    def getDomid(self):
+        return self.domid
+
+    def getStubdomDomid(self):
+        dom_list = xstransact.List('/local/domain')
+        for d in dom_list:
+            target = xstransact.Read('/local/domain/' + d + '/target')
+            if target is not None and int(target) == self.domid:
+                return int(d)
+        return None
+
+    def setName(self, name, to_store = True):
+        self._checkName(name)
+        self.info['name_label'] = name
+        if to_store:
+            self.storeVm("name", name)
+
+    def getName(self):
+        return self.info['name_label']
+
+    def getDomainPath(self):
+        return self.dompath
+
+    def getShutdownReason(self):
+        return self.readDom('control/shutdown')
+
+    def getStorePort(self):
+        """For use only by image.py and XendCheckpoint.py."""
+        return self.store_port
+
+    def getConsolePort(self):
+        """For use only by image.py and XendCheckpoint.py"""
+        return self.console_port
+
+    def getFeatures(self):
+        """For use only by image.py."""
+        return self.info['features']
+
+    def getVCpuCount(self):
+        return self.info['VCPUs_max']
+
+    def getVCpuAvail(self):
+        return self.info['vcpu_avail']
+
+    def setVCpuCount(self, vcpus):
+        def vcpus_valid(n):
+            if vcpus <= 0:
+                raise XendError('Zero or less VCPUs is invalid')
+            if self.domid >= 0 and vcpus > self.info['VCPUs_max']:
+                raise XendError('Cannot set vcpus greater than max vcpus on running domain')
+        vcpus_valid(vcpus)
+        
+        self.info['vcpu_avail'] = (1 << vcpus) - 1
+        if self.domid >= 0:
+            self.storeVm('vcpu_avail', self.info['vcpu_avail'])
+            self._writeDom(self._vcpuDomDetails())
+            self.info['VCPUs_live'] = vcpus
+        else:
+            if self.info['VCPUs_max'] > vcpus:
+                # decreasing
+                del self.info['cpus'][vcpus:]
+            elif self.info['VCPUs_max'] < vcpus:
+                # increasing
+                for c in range(self.info['VCPUs_max'], vcpus):
+                    self.info['cpus'].append(list())
+            self.info['VCPUs_max'] = vcpus
+        xen.xend.XendDomain.instance().managed_config_save(self)
+        log.info("Set VCPU count on domain %s to %d", self.info['name_label'],
+                 vcpus)
+
+    def getMemoryTarget(self):
+        """Get this domain's target memory size, in KB."""
+        return self.info['memory_dynamic_max'] / 1024
+
+    def getMemoryMaximum(self):
+        """Get this domain's maximum memory size, in KB."""
+        # remember, info now stores memory in bytes
+        return self.info['memory_static_max'] / 1024
+
+    def getResume(self):
+        return str(self._resume)
+
+    def setResume(self, isresume):
+        self._resume = isresume
+
+    def getCpus(self):
+        return self.info['cpus']
+
+    def setCpus(self, cpumap):
+        self.info['cpus'] = cpumap
+
+    def getCap(self):
+        return self.info['vcpus_params']['cap']
+
+    def setCap(self, cpu_cap):
+        self.info['vcpus_params']['cap'] = cpu_cap
+
+    def getWeight(self):
+        return self.info['vcpus_params']['weight']
+
+    def setWeight(self, cpu_weight):
+        self.info['vcpus_params']['weight'] = cpu_weight
+
+    def getRestartCount(self):
+        return self._readVm('xend/restart_count')
+
+    def refreshShutdown(self, xeninfo = None):
+        """ Checks the domain for whether a shutdown is required.
+
+        Called from XendDomainInfo and also image.py for HVM images.
+        """
+        
+        # If set at the end of this method, a restart is required, with the
+        # given reason.  This restart has to be done out of the scope of
+        # refresh_shutdown_lock.
+        restart_reason = None
+
+        self.refresh_shutdown_lock.acquire()
+        try:
+            if xeninfo is None:
+                xeninfo = dom_get(self.domid)
+                if xeninfo is None:
+                    # The domain no longer exists.  This will occur if we have
+                    # scheduled a timer to check for shutdown timeouts and the
+                    # shutdown succeeded.  It will also occur if someone
+                    # destroys a domain beneath us.  We clean up the domain,
+                    # just in case, but we can't clean up the VM, because that
+                    # VM may have migrated to a different domain on this
+                    # machine.
+                    self.cleanupDomain()
+                    self._stateSet(DOM_STATE_HALTED)
+                    return
+
+            if xeninfo['dying']:
+                # Dying means that a domain has been destroyed, but has not
+                # yet been cleaned up by Xen.  This state could persist
+                # indefinitely if, for example, another domain has some of its
+                # pages mapped.  We might like to diagnose this problem in the
+                # future, but for now all we do is make sure that it's not us
+                # holding the pages, by calling cleanupDomain.  We can't
+                # clean up the VM, as above.
+                self.cleanupDomain()
+                self._stateSet(DOM_STATE_SHUTDOWN)
+                return
+
+            elif xeninfo['crashed']:
+                if self.readDom('xend/shutdown_completed'):
+                    # We've seen this shutdown already, but we are preserving
+                    # the domain for debugging.  Leave it alone.
+                    return
+
+                log.warn('Domain has crashed: name=%s id=%d.',
+                         self.info['name_label'], self.domid)
+                self._writeVm(LAST_SHUTDOWN_REASON, 'crash')
+
+                restart_reason = 'crash'
+                self._stateSet(DOM_STATE_HALTED)
+
+            elif xeninfo['shutdown']:
+                self._stateSet(DOM_STATE_SHUTDOWN)
+                if self.readDom('xend/shutdown_completed'):
+                    # We've seen this shutdown already, but we are preserving
+                    # the domain for debugging.  Leave it alone.
+                    return
+
+                else:
+                    reason = shutdown_reason(xeninfo['shutdown_reason'])
+
+                    log.info('Domain has shutdown: name=%s id=%d reason=%s.',
+                             self.info['name_label'], self.domid, reason)
+                    self._writeVm(LAST_SHUTDOWN_REASON, reason)
+
+                    self._clearRestart()
+
+                    if reason == 'suspend':
+                        self._stateSet(DOM_STATE_SUSPENDED)
+                        # Don't destroy the domain.  XendCheckpoint will do
+                        # this once it has finished.  However, stop watching
+                        # the VM path now, otherwise we will end up with one
+                        # watch for the old domain, and one for the new.
+                        self._unwatchVm()
+                    elif reason in ('poweroff', 'reboot'):
+                        restart_reason = reason
+                    else:
+                        self.destroy()
+
+            elif self.dompath is None:
+                # We have yet to manage to call introduceDomain on this
+                # domain.  This can happen if a restore is in progress, or has
+                # failed.  Ignore this domain.
+                pass
+            else:
+                # Domain is alive.  If we are shutting it down, log a message
+                # if it seems unresponsive.
+                if xeninfo['paused']:
+                    self._stateSet(DOM_STATE_PAUSED)
+                else:
+                    self._stateSet(DOM_STATE_RUNNING)
+                    
+                if self.shutdownStartTime:
+                    timeout = (SHUTDOWN_TIMEOUT - time.time() +
+                               self.shutdownStartTime)
+                    if (timeout < 0 and not self.readDom('xend/unresponsive')):
+                        log.info(
+                            "Domain shutdown timeout expired: name=%s id=%s",
+                            self.info['name_label'], self.domid)
+                        self.storeDom('xend/unresponsive', 'True')
+        finally:
+            self.refresh_shutdown_lock.release()
+
+        if restart_reason and not self.restart_in_progress:
+            self.restart_in_progress = True
+            threading.Thread(target = self._maybeRestart,
+                             args = (restart_reason,)).start()
+
+
+    #
+    # Restart functions - handling whether we come back up on shutdown.
+    #
+
+    def _clearRestart(self):
+        self._removeDom("xend/shutdown_start_time")
+
+    def _maybeDumpCore(self, reason):
+        if reason == 'crash':
+            if xoptions.get_enable_dump() or self.get_on_crash() \
+                   in ['coredump_and_destroy', 'coredump_and_restart']:
+                try:
+                    self.dumpCore()
+                except XendError:
+                    # This error has been logged -- there's nothing more
+                    # we can do in this context.
+                    pass
+
+    def _maybeRestart(self, reason):
+        # Before taking configured action, dump core if configured to do so.
+        #
+        self._maybeDumpCore(reason)
+
+        # Dispatch to the correct method based upon the configured on_{reason}
+        # behaviour.
+        actions =  {"destroy"        : self.destroy,
+                    "restart"        : self._restart,
+                    "preserve"       : self._preserve,
+                    "rename-restart" : self._renameRestart,
+                    "coredump-destroy" : self.destroy,
+                    "coredump-restart" : self._restart}
+
+        action_conf = {
+            'poweroff': 'actions_after_shutdown',
+            'reboot': 'actions_after_reboot',
+            'crash': 'actions_after_crash',
+        }
+
+        action_target = self.info.get(action_conf.get(reason))
+        func = actions.get(action_target, None)
+        if func and callable(func):
+            func()
+        else:
+            self.destroy() # default to destroy
+
+    def _renameRestart(self):
+        self._restart(True)
+
+    def _restart(self, rename = False):
+        """Restart the domain after it has exited.
+
+        @param rename True if the old domain is to be renamed and preserved,
+        False if it is to be destroyed.
+        """
+        from xen.xend import XendDomain
+        
+        if self._readVm(RESTART_IN_PROGRESS):
+            log.error('Xend failed during restart of domain %s.  '
+                      'Refusing to restart to avoid loops.',
+                      str(self.domid))
+            self.destroy()
+            return
+
+        old_domid = self.domid
+        self._writeVm(RESTART_IN_PROGRESS, 'True')
+
+        elapse = time.time() - self.info['start_time']
+        if elapse < MINIMUM_RESTART_TIME:
+            log.error('VM %s restarting too fast (Elapsed time: %f seconds). '
+                      'Refusing to restart to avoid loops.',
+                      self.info['name_label'], elapse)
+            self.destroy()
+            return
+
+        prev_vm_xend = self._listRecursiveVm('xend')
+        new_dom_info = self.info
+        try:
+            if rename:
+                new_dom_info = self._preserveForRestart()
+            else:
+                self._unwatchVm()
+                self.destroy()
+
+            # new_dom's VM will be the same as this domain's VM, except where
+            # the rename flag has instructed us to call preserveForRestart.
+            # In that case, it is important that we remove the
+            # RESTART_IN_PROGRESS node from the new domain, not the old one,
+            # once the new one is available.
+
+            new_dom = None
+            try:
+                new_dom = XendDomain.instance().domain_create_from_dict(
+                    new_dom_info)
+                for x in prev_vm_xend[0][1]:
+                    new_dom._writeVm('xend/%s' % x[0], x[1])
+                new_dom.waitForDevices()
+                new_dom.unpause()
+                rst_cnt = new_dom._readVm('xend/restart_count')
+                rst_cnt = int(rst_cnt) + 1
+                new_dom._writeVm('xend/restart_count', str(rst_cnt))
+                new_dom._removeVm(RESTART_IN_PROGRESS)
+            except:
+                if new_dom:
+                    new_dom._removeVm(RESTART_IN_PROGRESS)
+                    new_dom.destroy()
+                else:
+                    self._removeVm(RESTART_IN_PROGRESS)
+                raise
+        except:
+            log.exception('Failed to restart domain %s.', str(old_domid))
+
+    def _preserveForRestart(self):
+        """Preserve a domain that has been shut down, by giving it a new UUID,
+        cloning the VM details, and giving it a new name.  This allows us to
+        keep this domain for debugging, but restart a new one in its place
+        preserving the restart semantics (name and UUID preserved).
+        """
+        
+        new_uuid = uuid.createString()
+        new_name = 'Domain-%s' % new_uuid
+        log.info("Renaming dead domain %s (%d, %s) to %s (%s).",
+                 self.info['name_label'], self.domid, self.info['uuid'],
+                 new_name, new_uuid)
+        self._unwatchVm()
+        self._releaseDevices()
+        # Remove existing vm node in xenstore
+        self._removeVm()
+        new_dom_info = self.info.copy()
+        new_dom_info['name_label'] = self.info['name_label']
+        new_dom_info['uuid'] = self.info['uuid']
+        self.info['name_label'] = new_name
+        self.info['uuid'] = new_uuid
+        self.vmpath = XS_VMROOT + new_uuid
+        # Write out new vm node to xenstore
+        self._storeVmDetails()
+        self._preserve()
+        return new_dom_info
+
+
+    def _preserve(self):
+        log.info("Preserving dead domain %s (%d).", self.info['name_label'],
+                 self.domid)
+        self._unwatchVm()
+        self.storeDom('xend/shutdown_completed', 'True')
+        self._stateSet(DOM_STATE_HALTED)
+
+    #
+    # Debugging ..
+    #
+
+    def dumpCore(self, corefile = None):
+        """Create a core dump for this domain.
+
+        @raise: XendError if core dumping failed.
+        """
+        
+        if not corefile:
+            # To prohibit directory traversal
+            based_name = os.path.basename(self.info['name_label'])
+            
+            coredir = "/var/xen/dump/%s" % (based_name)
+            if not os.path.exists(coredir):
+                try:
+                    mkdir.parents(coredir, stat.S_IRWXU)
+                except Exception, ex:
+                    log.error("Cannot create directory: %s" % str(ex))
+
+            if not os.path.isdir(coredir):
+                # Use former directory to dump core
+                coredir = '/var/xen/dump'
+
+            this_time = time.strftime("%Y-%m%d-%H%M.%S", time.localtime())
+            corefile = "%s/%s-%s.%s.core" % (coredir, this_time,
+                                             self.info['name_label'], self.domid)
+                
+        if os.path.isdir(corefile):
+            raise XendError("Cannot dump core in a directory: %s" %
+                            corefile)
+
+        try:
+            try:
+                self._writeVm(DUMPCORE_IN_PROGRESS, 'True')
+                xc.domain_dumpcore(self.domid, corefile)
+            except RuntimeError, ex:
+                corefile_incomp = corefile+'-incomplete'
+                try:
+                    os.rename(corefile, corefile_incomp)
+                except:
+                    pass
+
+                log.error("core dump failed: id = %s name = %s: %s",
+                          self.domid, self.info['name_label'], str(ex))
+                raise XendError("Failed to dump core: %s" %  str(ex))
+        finally:
+            self._removeVm(DUMPCORE_IN_PROGRESS)
+
+    #
+    # Device creation/deletion functions
+    #
+
+    def _createDevice(self, deviceClass, devConfig):
+        return self.getDeviceController(deviceClass).createDevice(devConfig)
+
+    def _waitForDevice(self, deviceClass, devid):
+        return self.getDeviceController(deviceClass).waitForDevice(devid)
+
+    def _waitForDeviceUUID(self, dev_uuid):
+        deviceClass, config = self.info['devices'].get(dev_uuid)
+        self._waitForDevice(deviceClass, config['devid'])
+
+    def _waitForDevice_destroy(self, deviceClass, devid, backpath):
+        return self.getDeviceController(deviceClass).waitForDevice_destroy(
+            devid, backpath)
+
+    def _reconfigureDevice(self, deviceClass, devid, devconfig):
+        return self.getDeviceController(deviceClass).reconfigureDevice(
+            devid, devconfig)
+
+    def _createDevices(self):
+        """Create the devices for a vm.
+
+        @raise: VmError for invalid devices
+        """
+        if self.image:
+            self.image.prepareEnvironment()
+
+        vscsi_uuidlist = {}
+        vscsi_devidlist = []
+        ordered_refs = self.info.ordered_device_refs()
+        for dev_uuid in ordered_refs:
+            devclass, config = self.info['devices'][dev_uuid]
+            if devclass in XendDevices.valid_devices() and devclass != 'vscsi':
+                log.info("createDevice: %s : %s" % (devclass, scrub_password(config)))
+                dev_uuid = config.get('uuid')
+
+                if devclass == 'pci':
+                    self.pci_dev_check_assignability_and_do_FLR(config)
+
+                if devclass != 'pci' or not self.info.is_hvm() :
+                    devid = self._createDevice(devclass, config)
+                
+                    # store devid in XendConfig for caching reasons
+                    if dev_uuid in self.info['devices']:
+                        self.info['devices'][dev_uuid][1]['devid'] = devid
+
+            elif devclass == 'vscsi':
+                vscsi_config = config.get('devs', [])[0]
+                devid = vscsi_config.get('devid', '')
+                dev_uuid = config.get('uuid')
+                vscsi_uuidlist[devid] = dev_uuid
+                vscsi_devidlist.append(devid)
+
+        #It is necessary to sorted it for /dev/sdxx in guest. 
+        if len(vscsi_uuidlist) > 0:
+            vscsi_devidlist.sort()
+            for vscsiid in vscsi_devidlist:
+                dev_uuid = vscsi_uuidlist[vscsiid]
+                devclass, config = self.info['devices'][dev_uuid]
+                log.info("createDevice: %s : %s" % (devclass, scrub_password(config)))
+                dev_uuid = config.get('uuid')
+                devid = self._createDevice(devclass, config)
+                # store devid in XendConfig for caching reasons
+                if dev_uuid in self.info['devices']:
+                    self.info['devices'][dev_uuid][1]['devid'] = devid
+
+
+        if self.image:
+            self.image.createDeviceModel()
+
+        #if have pass-through devs, need the virtual pci slots info from qemu
+        self.pci_device_configure_boot()
+
+    def _releaseDevices(self, suspend = False):
+        """Release all domain's devices.  Nothrow guarantee."""
+        if self.image:
+            try:
+                log.debug("Destroying device model")
+                self.image.destroyDeviceModel()
+            except Exception, e:
+                log.exception("Device model destroy failed %s" % str(e))
+        else:
+            log.debug("No device model")
+
+        log.debug("Releasing devices")
+        t = xstransact("%s/device" % self.vmpath)
+        try:
+            for devclass in XendDevices.valid_devices():
+                for dev in t.list(devclass):
+                    try:
+                        log.debug("Removing %s", dev);
+                        self.destroyDevice(devclass, dev, False);
+                    except:
+                        # Log and swallow any exceptions in removal --
+                        # there's nothing more we can do.
+                        log.exception("Device release failed: %s; %s; %s",
+                                      self.info['name_label'],
+                                      devclass, dev)
+        finally:
+            t.abort()
+
+    def getDeviceController(self, name):
+        """Get the device controller for this domain, and if it
+        doesn't exist, create it.
+
+        @param name: device class name
+        @type name: string
+        @rtype: subclass of DevController
+        """
+        if name not in self._deviceControllers:
+            devController = XendDevices.make_controller(name, self)
+            if not devController:
+                raise XendError("Unknown device type: %s" % name)
+            self._deviceControllers[name] = devController
+    
+        return self._deviceControllers[name]
+
+    #
+    # Migration functions (public)
+    # 
+
+    def testMigrateDevices(self, network, dst):
+        """ Notify all device about intention of migration
+        @raise: XendError for a device that cannot be migrated
+        """
+        for (n, c) in self.info.all_devices_sxpr():
+            rc = self.migrateDevice(n, c, network, dst, DEV_MIGRATE_TEST, self.getName())
+            if rc != 0:
+                raise XendError("Device of type '%s' refuses migration." % n)
+
+    def migrateDevices(self, network, dst, step, domName=''):
+        """Notify the devices about migration
+        """
+        ctr = 0
+        try:
+            for (dev_type, dev_conf) in self.info.all_devices_sxpr():
+                self.migrateDevice(dev_type, dev_conf, network, dst,
+                                   step, domName)
+                ctr = ctr + 1
+        except:
+            for dev_type, dev_conf in self.info.all_devices_sxpr():
+                if ctr == 0:
+                    step = step - 1
+                ctr = ctr - 1
+                self._recoverMigrateDevice(dev_type, dev_conf, network,
+                                           dst, step, domName)
+            raise
+
+    def migrateDevice(self, deviceClass, deviceConfig, network, dst,
+                      step, domName=''):
+        return self.getDeviceController(deviceClass).migrate(deviceConfig,
+                                        network, dst, step, domName)
+
+    def _recoverMigrateDevice(self, deviceClass, deviceConfig, network,
+                             dst, step, domName=''):
+        return self.getDeviceController(deviceClass).recover_migrate(
+                     deviceConfig, network, dst, step, domName)
+
+    def setChangeHomeServer(self, chs):
+        if chs is not None:
+            self.info['change_home_server'] = bool(chs)
+        else:
+            if self.info.has_key('change_home_server'):
+                del self.info['change_home_server']
+
+
+    ## private:
+
+    def _constructDomain(self):
+        """Construct the domain.
+
+        @raise: VmError on error
+        """
+
+        log.debug('XendDomainInfo.constructDomain')
+
+        self.shutdownStartTime = None
+        self.restart_in_progress = False
+
+        hap = 0
+        hvm = self.info.is_hvm()
+        if hvm:
+            hap = self.info.is_hap()
+            info = xc.xeninfo()
+            if 'hvm' not in info['xen_caps']:
+                raise VmError("HVM guest support is unavailable: is VT/AMD-V "
+                              "supported by your CPU and enabled in your "
+                              "BIOS?")
+
+        # Hack to pre-reserve some memory for initial domain creation.
+        # There is an implicit memory overhead for any domain creation. This
+        # overhead is greater for some types of domain than others. For
+        # example, an x86 HVM domain will have a default shadow-pagetable
+        # allocation of 4MB. We free up 16MB here to be on the safe side.
+        balloon.free(16*1024, self) # 16MB should be plenty
+
+        ssidref = 0
+        if security.on() == xsconstants.XS_POLICY_USE:
+            ssidref = security.calc_dom_ssidref_from_info(self.info)
+            if security.has_authorization(ssidref) == False:
+                raise VmError("VM is not authorized to run.")
+
+        s3_integrity = 0
+        if self.info.has_key('s3_integrity'):
+            s3_integrity = self.info['s3_integrity']
+
+        oos = self.info['platform'].get('oos', 1)
+        oos_off = 1 - int(oos)
+
+        # look-up pool id to use
+        pool_name = self.info['pool_name']
+        if len(pool_name) == 0:
+            pool_name = "Pool-0"
+
+        pool = XendCPUPool.lookup_pool(pool_name)
+
+        if pool is None:
+            raise VmError("unknown pool %s" % pool_name)
+        pool_id = pool.query_pool_id()
+        if pool_id is None:
+            raise VmError("pool %s not activated" % pool_name)
+
+        flags = (int(hvm) << 0) | (int(hap) << 1) | (int(s3_integrity) << 2) | (int(oos_off) << 3)
+
+        try:
+            self.domid = xc.domain_create(
+                domid = 0,
+                ssidref = ssidref,
+                handle = uuid.fromString(self.info['uuid']),
+                flags = flags,
+                #cpupool = pool_id,
+                target = self.info.target())
+        except Exception, e:
+            # may get here if due to ACM the operation is not permitted
+            if security.on() == xsconstants.XS_POLICY_ACM:
+                raise VmError('Domain in conflict set with running domain?')
+            log.exception(e)
+
+        if not self.domid or self.domid < 0:
+            failmsg = 'Creating domain failed: name=%s' % self.info['name_label']
+            if self.domid:
+                failmsg += ', error=%i' % int(self.domid)
+            raise VmError(failmsg)
+
+        try:
+            xc.cpupool_movedomain(pool_id, self.domid)
+        except Exception, e:
+            raise VmError('Moving domain to target pool failed')
+
+        self.dompath = GetDomainPath(self.domid)
+
+        self._recreateDom()
+
+        # Set TSC mode of domain
+        tsc_mode = self.info["platform"].get("tsc_mode")
+        if arch.type == "x86" and tsc_mode is not None:
+            xc.domain_set_tsc_info(self.domid, int(tsc_mode))
+
+        # Set timer configuration of domain
+        timer_mode = self.info["platform"].get("timer_mode")
+        if hvm and timer_mode is not None:
+            xc.hvm_set_param(self.domid, HVM_PARAM_TIMER_MODE,
+                             long(timer_mode))
+
+        if arch.type == "x86" and hvm:
+            # Set Viridian interface configuration of domain
+            viridian = self.info["platform"].get("viridian")
+            if viridian is not None:
+                xc.hvm_set_param(self.domid, HVM_PARAM_VIRIDIAN, long(viridian))
+            # Set nestedhvm of domain
+            nestedhvm = self.info["platform"].get("nestedhvm")
+            if nestedhvm is not None:
+                xc.hvm_set_param(self.domid, HVM_PARAM_NESTEDHVM, long(nestedhvm))
+
+        # If nomigrate is set, disable migration
+        nomigrate = self.info["platform"].get("nomigrate")
+        if nomigrate is not None and long(nomigrate) != 0:
+            xc.domain_disable_migrate(self.domid)
+
+        # Optionally enable virtual HPET
+        hpet = self.info["platform"].get("hpet")
+        if hvm and hpet is not None:
+            xc.hvm_set_param(self.domid, HVM_PARAM_HPET_ENABLED,
+                             long(hpet))
+
+        # Optionally enable periodic vpt aligning
+        vpt_align = self.info["platform"].get("vpt_align")
+        if hvm and vpt_align is not None:
+            xc.hvm_set_param(self.domid, HVM_PARAM_VPT_ALIGN,
+                             long(vpt_align))
+
+        # Set maximum number of vcpus in domain
+        xc.domain_max_vcpus(self.domid, int(self.info['VCPUs_max']))
+
+        # Check for cpu_{cap|weight} validity for credit scheduler
+        if XendNode.instance().xenschedinfo() == 'credit':
+            cap = self.getCap()
+            weight = self.getWeight()
+
+            assert type(weight) == int
+            assert type(cap) == int
+
+            if weight < 1 or weight > 65535:
+                raise VmError("Cpu weight out of range, valid values are within range from 1 to 65535")
+
+            if cap < 0 or cap > self.getVCpuCount() * 100:
+                raise VmError("Cpu cap out of range, valid range is from 0 to %s for specified number of vcpus" %
+                              (self.getVCpuCount() * 100))
+
+        # Test whether the devices can be assigned with VT-d
+        self.info.update_platform_pci()
+        pci = self.info["platform"].get("pci")
+        pci_str = ''
+        if pci and len(pci) > 0:
+            pci = map(lambda x: x[0:4], pci)  # strip options 
+            pci_str = str(pci)
+
+        # This test is done for both pv and hvm guest.
+        for p in pci:
+            pci_name = '%04x:%02x:%02x.%x' % \
+                (parse_hex(p[0]), parse_hex(p[1]), parse_hex(p[2]), parse_hex(p[3]))
+            try:
+                pci_device = PciDevice(parse_pci_name(pci_name))
+            except Exception, e:
+                raise VmError("pci: failed to locate device and "+
+                    "parse its resources - "+str(e))
+            if pci_device.driver!='pciback' and pci_device.driver!='pci-stub':
+                raise VmError(("pci: PCI Backend and pci-stub don't own device %s")\
+                                %pci_device.name)
+            if pci_name in get_all_assigned_pci_devices():
+                raise VmError("failed to assign device %s that has"
+                              " already been assigned to other domain." % pci_name)
+
+        if hvm and pci_str != '':
+            bdf = xc.test_assign_device(0, pci_str)
+            if bdf != 0:
+                if bdf == -1:
+                    raise VmError("failed to assign device: maybe the platform"
+                                  " doesn't support VT-d, or VT-d isn't enabled"
+                                  " properly?")
+                bus = (bdf >> 16) & 0xff
+                devfn = (bdf >> 8) & 0xff
+                dev = (devfn >> 3) & 0x1f
+                func = devfn & 0x7
+                raise VmError("failed to assign device %02x:%02x.%x: maybe it has"
+                              " already been assigned to other domain, or maybe"
+                              " it doesn't exist." % (bus, dev, func))
+
+        # register the domain in the list 
+        from xen.xend import XendDomain
+        XendDomain.instance().add_domain(self)
+
+    def _introduceDomain(self):
+        assert self.domid is not None
+        assert self.store_mfn is not None
+        assert self.store_port is not None
+
+        try:
+            IntroduceDomain(self.domid, self.store_mfn, self.store_port)
+        except RuntimeError, exn:
+            raise XendError(str(exn))
+
+    def _setTarget(self, target):
+        assert self.domid is not None
+
+        try:
+            SetTarget(self.domid, target)
+            self.storeDom('target', target)
+        except RuntimeError, exn:
+            raise XendError(str(exn))
+
+
+    def _setCPUAffinity(self):
+        """ Repin domain vcpus if a restricted cpus list is provided.
+            Returns the choosen node number.
+        """
+
+        def has_cpus():
+            if self.info['cpus'] is not None:
+                for c in self.info['cpus']:
+                    if c:
+                        return True
+            return False
+
+        def has_cpumap():
+            if self.info.has_key('vcpus_params'):
+                for k, v in self.info['vcpus_params'].items():
+                    if k.startswith('cpumap'):
+                        return True
+            return False
+
+        index = 0
+        if has_cpumap():
+            for v in range(0, self.info['VCPUs_max']):
+                if self.info['vcpus_params'].has_key('cpumap%i' % v):
+                    cpumask = map(int, self.info['vcpus_params']['cpumap%i' % v].split(','))
+                    xc.vcpu_setaffinity(self.domid, v, cpumask)
+        elif has_cpus():
+            for v in range(0, self.info['VCPUs_max']):
+                if self.info['cpus'][v]:
+                    xc.vcpu_setaffinity(self.domid, v, self.info['cpus'][v])
+        else:
+            def find_relaxed_node(node_list):
+                import sys
+                nr_nodes = info['max_node_index'] + 1
+                if node_list is None:
+                    node_list = range(0, nr_nodes)
+                nodeload = [0]
+                nodeload = nodeload * nr_nodes
+                from xen.xend import XendDomain
+                doms = XendDomain.instance().list('all')
+                for dom in filter (lambda d: d.domid != self.domid, doms):
+                    cpuinfo = dom.getVCPUInfo()
+                    for vcpu in sxp.children(cpuinfo, 'vcpu'):
+                        if sxp.child_value(vcpu, 'online') == 0: continue
+                        cpumap = list(sxp.child_value(vcpu,'cpumap'))
+                        for i in range(0, nr_nodes):
+                            node_cpumask = node_to_cpu[i]
+                            for j in node_cpumask:
+                                if j in cpumap:
+                                    nodeload[i] += 1
+                                    break
+                for i in range(0, nr_nodes):
+                    if len(node_to_cpu[i]) == 0:
+                        nodeload[i] += 8
+                    else:
+                        nodeload[i] = int(nodeload[i] * 16 / len(node_to_cpu[i]))
+                        if i not in node_list:
+                            nodeload[i] += 8
+                return map(lambda x: x[0], sorted(enumerate(nodeload), key=lambda x:x[1]))
+
+            info = xc.numainfo()
+            if info['max_node_index'] > 0 and  XendCPUPool.number_of_pools() < 2:
+                node_memory_list = info['node_memfree']
+                node_to_cpu = []
+                for i in range(0, info['max_node_index'] + 1):
+                    node_to_cpu.append([])
+                for cpu, node in enumerate(xc.topologyinfo()['cpu_to_node']):
+                    node_to_cpu[node].append(cpu)
+                needmem = self.image.getRequiredAvailableMemory(self.info['memory_dynamic_max']) / 1024
+                candidate_node_list = []
+                for i in range(0, info['max_node_index'] + 1):
+                    if node_memory_list[i] >= needmem and len(node_to_cpu[i]) > 0:
+                        candidate_node_list.append(i)
+                best_node = find_relaxed_node(candidate_node_list)[0]
+                cpumask = node_to_cpu[best_node]
+                best_nodes = find_relaxed_node(filter(lambda x: x != best_node, range(0,info['max_node_index']+1)))
+                for node_idx in best_nodes:
+                    if len(cpumask) >= self.info['VCPUs_max']:
+                        break
+                    cpumask = cpumask + node_to_cpu[node_idx]
+                    log.debug("allocating additional NUMA node %d", node_idx)
+                for v in range(0, self.info['VCPUs_max']):
+                    xc.vcpu_setaffinity(self.domid, v, cpumask)
+        return index
+
+    def _freeDMAmemory(self, node):
+
+        # If we are PV and have PCI devices the guest will
+        # turn on a SWIOTLB. The SWIOTLB _MUST_ be located in the DMA32
+        # zone (under 4GB). To do so, we need to balloon down Dom0 to where
+        # there is enough (64MB) memory under the 4GB mark. This balloon-ing
+        # might take more memory out than just 64MB thought :-(
+        if not self.info.is_pv_and_has_pci():
+            return
+
+        retries = 2000
+        ask_for_mem = 0
+        need_mem = 0
+        try:
+            while (retries > 0):
+                physinfo = xc.physinfo()
+                free_mem = physinfo['free_memory']
+                max_node_id = physinfo['max_node_id']
+                node_to_dma32_mem = physinfo['node_to_dma32_mem']
+                if (node > max_node_id):
+                    return
+                # Extra 2MB above 64GB seems to do the trick.
+                need_mem = 64 * 1024 + 2048 - node_to_dma32_mem[node]
+                # our starting point. We ask just for the difference to
+                # be have an extra 64MB under 4GB.
+                ask_for_mem = max(need_mem, ask_for_mem);
+                if (need_mem > 0):
+                    log.debug('_freeDMAmemory (%d) Need %dKiB DMA memory. '
+                              'Asking for %dKiB', retries, need_mem,
+                              ask_for_mem)
+
+                    balloon.free(ask_for_mem, self)
+                    ask_for_mem = ask_for_mem + 2048
+                else:
+                    # OK. We got enough DMA memory.
+                    break
+                retries = retries - 1
+        except:
+            # This is best-try after all.
+            need_mem = max(1, need_mem)
+            pass
+
+        if (need_mem > 0):
+            log.warn('We tried our best to balloon down DMA memory to '
+                     'accomodate your PV guest. We need %dKiB extra memory.',
+                     need_mem)
+
+    def _setSchedParams(self):
+        if XendNode.instance().xenschedinfo() == 'credit':
+            from xen.xend import XendDomain
+            XendDomain.instance().domain_sched_credit_set(self.getDomid(),
+                                                          self.getWeight(),
+                                                          self.getCap())
+        elif XendNode.instance().xenschedinfo() == 'credit2':
+            from xen.xend import XendDomain
+            XendDomain.instance().domain_sched_credit2_set(self.getDomid(),
+                                                           self.getWeight())
+
+    def _initDomain(self):
+        log.debug('XendDomainInfo.initDomain: %s %s',
+                  self.domid,
+                  self.info['vcpus_params']['weight'])
+
+        self._configureBootloader()
+
+        try:
+            self.image = image.create(self, self.info)
+
+            # repin domain vcpus if a restricted cpus list is provided
+            # this is done prior to memory allocation to aide in memory
+            # distribution for NUMA systems.
+            node = self._setCPUAffinity()
+
+            # Set scheduling parameters.
+            self._setSchedParams()
+
+            # Use architecture- and image-specific calculations to determine
+            # the various headrooms necessary, given the raw configured
+            # values. maxmem, memory, and shadow are all in KiB.
+            # but memory_static_max etc are all stored in bytes now.
+            memory = self.image.getRequiredAvailableMemory(
+                self.info['memory_dynamic_max'] / 1024)
+            maxmem = self.image.getRequiredAvailableMemory(
+                self.info['memory_static_max'] / 1024)
+            shadow = self.image.getRequiredShadowMemory(
+                self.info['shadow_memory'] * 1024,
+                self.info['memory_static_max'] / 1024)
+
+            log.debug("_initDomain:shadow_memory=0x%x, memory_static_max=0x%x, memory_static_min=0x%x.", self.info['shadow_memory'], self.info['memory_static_max'], self.info['memory_static_min'],)
+            # Round shadow up to a multiple of a MiB, as shadow_mem_control
+            # takes MiB and we must not round down and end up under-providing.
+            shadow = ((shadow + 1023) / 1024) * 1024
+
+            # set memory limit
+            xc.domain_setmaxmem(self.domid, maxmem)
+
+            vtd_mem = 0
+            info = xc.physinfo()
+            if 'hvm_directio' in info['virt_caps']:
+                # Reserve 1 page per MiB of RAM for separate VT-d page table.
+                vtd_mem = 4 * (self.info['memory_static_max'] / 1024 / 1024)
+                # Round vtd_mem up to a multiple of a MiB.
+                vtd_mem = ((vtd_mem + 1023) / 1024) * 1024
+
+            self.guest_bitsize = self.image.getBitSize()
+            # Make sure there's enough RAM available for the domain
+            balloon.free(memory + shadow + vtd_mem, self)
+
+            # Set up the shadow memory
+            shadow_cur = xc.shadow_mem_control(self.domid, shadow / 1024)
+            self.info['shadow_memory'] = shadow_cur
+
+            # machine address size
+            if self.info.has_key('machine_address_size'):
+                log.debug("_initDomain: setting maximum machine address size %d" % self.info['machine_address_size'])
+                xc.domain_set_machine_address_size(self.domid, self.info['machine_address_size'])
+
+            if self.info.has_key('suppress_spurious_page_faults') and self.info['suppress_spurious_page_faults']:
+                log.debug("_initDomain: suppressing spurious page faults")
+                xc.domain_suppress_spurious_page_faults(self.domid)
+                
+            self._createChannels()
+
+            channel_details = self.image.createImage()
+
+            self.store_mfn = channel_details['store_mfn']
+            if 'console_mfn' in channel_details:
+                self.console_mfn = channel_details['console_mfn']
+            if 'notes' in channel_details:
+                self.info.set_notes(channel_details['notes'])
+            if 'native_protocol' in channel_details:
+                self.native_protocol = channel_details['native_protocol'];
+
+            self._introduceDomain()
+            if self.info.target():
+                self._setTarget(self.info.target())
+
+            self._freeDMAmemory(node)
+
+            self._createDevices()
+
+            self.image.cleanupTmpImages()
+
+            self.info['start_time'] = time.time()
+
+            self._stateSet(DOM_STATE_RUNNING)
+        except VmError, exn:
+            log.exception("XendDomainInfo.initDomain: exception occurred")
+            if self.image:
+                self.image.cleanupTmpImages()
+            raise exn
+        except RuntimeError, exn:
+            log.exception("XendDomainInfo.initDomain: exception occurred")
+            if self.image:
+                self.image.cleanupTmpImages()
+            raise VmError(str(exn))
+
+
+    def cleanupDomain(self):
+        """Cleanup domain resources; release devices.  Idempotent.  Nothrow
+        guarantee."""
+
+        self.refresh_shutdown_lock.acquire()
+        try:
+            self.unwatchShutdown()
+            self._releaseDevices()
+            bootloader_tidy(self)
+
+            if self.image:
+                self.image = None
+
+            try:
+                self._removeDom()
+            except:
+                log.exception("Removing domain path failed.")
+
+            self._stateSet(DOM_STATE_HALTED)
+            self.domid = None  # Do not push into _stateSet()!
+        finally:
+            self.refresh_shutdown_lock.release()
+
+
+    def unwatchShutdown(self):
+        """Remove the watch on the domain's control/shutdown node, if any.
+        Idempotent.  Nothrow guarantee.  Expects to be protected by the
+        refresh_shutdown_lock."""
+
+        try:
+            try:
+                if self.shutdownWatch:
+                    self.shutdownWatch.unwatch()
+            finally:
+                self.shutdownWatch = None
+        except:
+            log.exception("Unwatching control/shutdown failed.")
+
+    def waitForShutdown(self):
+        self.state_updated.acquire()
+        try:
+            while self._stateGet() in (DOM_STATE_RUNNING,DOM_STATE_PAUSED):
+                self.state_updated.wait(timeout=1.0)
+        finally:
+            self.state_updated.release()
+
+    def waitForSuspend(self):
+        """Wait for the guest to respond to a suspend request by
+        shutting down.  If the guest hasn't re-written control/shutdown
+        after a certain amount of time, it's obviously not listening and
+        won't suspend, so we give up.  HVM guests with no PV drivers
+        should already be shutdown.
+        """
+        state = "suspend"
+        nr_tries = 60
+
+        self.state_updated.acquire()
+        try:
+            while self._stateGet() in (DOM_STATE_RUNNING,DOM_STATE_PAUSED):
+                self.state_updated.wait(1.0)
+                if state == "suspend":
+                    if nr_tries == 0:
+                        msg = ('Timeout waiting for domain %s to suspend'
+                            % self.domid)
+                        self._writeDom('control/shutdown', '')
+                        raise XendError(msg)
+                    state = self.readDom('control/shutdown')
+                    nr_tries -= 1
+        finally:
+            self.state_updated.release()
+
+    #
+    # TODO: recategorise - called from XendCheckpoint
+    # 
+
+    def completeRestore(self, store_mfn, console_mfn):
+
+        log.debug("XendDomainInfo.completeRestore")
+
+        self.store_mfn = store_mfn
+        self.console_mfn = console_mfn
+
+        self._introduceDomain()
+        self.image = image.create(self, self.info)
+        if self.image:
+            self.image.createDeviceModel(True)
+        self._storeDomDetails()
+        self._registerWatches()
+        self.refreshShutdown()
+
+        log.debug("XendDomainInfo.completeRestore done")
+
+
+    def _endRestore(self):
+        self.setResume(False)
+
+    #
+    # VM Destroy
+    # 
+
+    def _prepare_phantom_paths(self):
+        # get associated devices to destroy
+        # build list of phantom devices to be removed after normal devices
+        plist = []
+        if self.domid is not None:
+            t = xstransact("%s/device/vbd" % GetDomainPath(self.domid))
+            try:
+                for dev in t.list():
+                    backend_phantom_vbd = xstransact.Read("%s/device/vbd/%s/phantom_vbd" \
+                                          % (self.dompath, dev))
+                    if backend_phantom_vbd is not None:
+                        frontend_phantom_vbd =  xstransact.Read("%s/frontend" \
+                                          % backend_phantom_vbd)
+                        plist.append(backend_phantom_vbd)
+                        plist.append(frontend_phantom_vbd)
+            finally:
+                t.abort()
+        return plist
+
+    def _cleanup_phantom_devs(self, plist):
+        # remove phantom devices
+        if not plist == []:
+            time.sleep(2)
+        for paths in plist:
+            if paths.find('backend') != -1:
+                # Modify online status /before/ updating state (latter is watched by
+                # drivers, so this ordering avoids a race).
+                xstransact.Write(paths, 'online', "0")
+                xstransact.Write(paths, 'state', str(xenbusState['Closing']))
+            # force
+            xstransact.Remove(paths)
+
+    def destroy(self):
+        """Cleanup VM and destroy domain.  Nothrow guarantee."""
+
+        if self.domid is None:
+            return
+        from xen.xend import XendDomain
+        log.debug("XendDomainInfo.destroy: domid=%s", str(self.domid))
+
+        paths = self._prepare_phantom_paths()
+
+        if self.dompath is not None:
+            try:
+                xc.domain_destroy_hook(self.domid)
+                xc.domain_pause(self.domid)
+                do_FLR(self.domid, self.info.is_hvm())
+                xc.domain_destroy(self.domid)
+                for state in DOM_STATES_OLD:
+                    self.info[state] = 0
+                self._stateSet(DOM_STATE_HALTED)
+            except:
+                log.exception("XendDomainInfo.destroy: domain destruction failed.")
+
+            XendDomain.instance().remove_domain(self)
+            self.cleanupDomain()
+
+        if self.info.is_hvm() or self.guest_bitsize != 32:
+            if self.alloc_mem:
+                import MemoryPool 
+                log.debug("%s KiB need to add to Memory pool" %self.alloc_mem)
+                MemoryPool.instance().increase_memory(self.alloc_mem)
+
+        self._cleanup_phantom_devs(paths)
+        self._cleanupVm()
+
+        if ("transient" in self.info["other_config"] and \
+            bool(self.info["other_config"]["transient"])) or \
+           ("change_home_server" in self.info and \
+            bool(self.info["change_home_server"])):
+            XendDomain.instance().domain_delete_by_dominfo(self)
+
+
+    def resetDomain(self):
+        log.debug("XendDomainInfo.resetDomain(%s)", str(self.domid))
+
+        old_domid = self.domid
+        prev_vm_xend = self._listRecursiveVm('xend')
+        new_dom_info = self.info
+        try:
+            self._unwatchVm()
+            self.destroy()
+
+            new_dom = None
+            try:
+                from xen.xend import XendDomain
+                new_dom_info['domid'] = None
+                new_dom = XendDomain.instance().domain_create_from_dict(
+                    new_dom_info)
+                for x in prev_vm_xend[0][1]:
+                    new_dom._writeVm('xend/%s' % x[0], x[1])
+                new_dom.waitForDevices()
+                new_dom.unpause()
+            except:
+                if new_dom:
+                    new_dom.destroy()
+                raise
+        except:
+            log.exception('Failed to reset domain %s.', str(old_domid))
+
+
+    def resumeDomain(self):
+        log.debug("XendDomainInfo.resumeDomain(%s)", str(self.domid))
+
+        # resume a suspended domain (e.g. after live checkpoint, or after
+        # a later error during save or migate); checks that the domain
+        # is currently suspended first so safe to call from anywhere
+
+        xeninfo = dom_get(self.domid)
+        if xeninfo is None: 
+            return
+        if not xeninfo['shutdown']:
+            return
+        reason = shutdown_reason(xeninfo['shutdown_reason'])
+        if reason != 'suspend':
+            return
+
+        try:
+            # could also fetch a parsed note from xenstore
+            fast = self.info.get_notes().get('SUSPEND_CANCEL') and 1 or 0
+            if not fast:
+                self._releaseDevices()
+                self.testDeviceComplete()
+                self.testvifsComplete()
+                log.debug("XendDomainInfo.resumeDomain: devices released")
+
+                self._resetChannels()
+
+                self._removeDom('control/shutdown')
+                self._removeDom('device-misc/vif/nextDeviceID')
+
+                self._createChannels()
+                self._introduceDomain()
+                self._storeDomDetails()
+
+                self._createDevices()
+                log.debug("XendDomainInfo.resumeDomain: devices created")
+
+            xc.domain_resume(self.domid, fast)
+            ResumeDomain(self.domid)
+        except:
+            log.exception("XendDomainInfo.resume: xc.domain_resume failed on domain %s." % (str(self.domid)))
+        self.image.resumeDeviceModel()
+        log.debug("XendDomainInfo.resumeDomain: completed")
+
+
+    #
+    # Channels for xenstore and console
+    # 
+
+    def _createChannels(self):
+        """Create the channels to the domain.
+        """
+        self.store_port = self._createChannel()
+        self.console_port = self._createChannel()
+
+
+    def _createChannel(self):
+        """Create an event channel to the domain.
+        """
+        try:
+            if self.domid != None:
+                return xc.evtchn_alloc_unbound(domid = self.domid,
+                                               remote_dom = 0)
+        except:
+            log.exception("Exception in alloc_unbound(%s)", str(self.domid))
+            raise
+
+    def _resetChannels(self):
+        """Reset all event channels in the domain.
+        """
+        try:
+            if self.domid != None:
+                return xc.evtchn_reset(dom = self.domid)
+        except:
+            log.exception("Exception in evtcnh_reset(%s)", str(self.domid))
+            raise
+
+
+    #
+    # Bootloader configuration
+    #
+
+    def _configureBootloader(self):
+        """Run the bootloader if we're configured to do so."""
+
+        blexec          = self.info['PV_bootloader']
+        bootloader_args = self.info['PV_bootloader_args']
+        kernel          = self.info['PV_kernel']
+        ramdisk         = self.info['PV_ramdisk']
+        args            = self.info['PV_args']
+        boot            = self.info['HVM_boot_policy']
+
+        if boot:
+            # HVM booting.
+            pass
+        elif not blexec and kernel:
+            # Boot from dom0.  Nothing left to do -- the kernel and ramdisk
+            # will be picked up by image.py.
+            pass
+        else:
+            # Boot using bootloader
+            if not blexec or blexec == 'pygrub':
+                blexec = auxbin.pathTo('pygrub')
+
+            blcfg = None
+            disks = [x for x in self.info['vbd_refs']
+                     if self.info['devices'][x][1]['bootable']]
+
+            if not disks:
+                msg = "Had a bootloader specified, but no disks are bootable"
+                log.error(msg)
+                raise VmError(msg)
+
+            devinfo = self.info['devices'][disks[0]]
+            devtype = devinfo[0]
+            disk = devinfo[1]['uname']
+
+            (fn, types) = parse_uname(disk)
+            def _shouldMount(types):
+                if types[0] in ('file', 'phy'):
+                    return False
+                if types[0] in ('tap', 'tap2'):
+                    if types[1] in ('aio', 'sync'):
+                        return False
+                    else:
+                        return True
+                return os.access('/etc/xen/scripts/block-%s' % types[0], os.X_OK)
+
+            mounted = _shouldMount(types)
+            mounted_vbd_uuid = 0
+            if mounted:
+                # This is a file, not a device.  pygrub can cope with a
+                # file if it's raw, but if it's QCOW or other such formats
+                # used through blktap, then we need to mount it first.
+
+                log.info("Mounting %s on %s." %
+                         (fn, BOOTLOADER_LOOPBACK_DEVICE))
+
+                vbd = {
+                    'mode': 'RO',
+                    'device': BOOTLOADER_LOOPBACK_DEVICE,
+                    }
+
+                from xen.xend import XendDomain
+                dom0 = XendDomain.instance().privilegedDomain()
+                mounted_vbd_uuid = dom0.create_vbd(vbd, disk);
+                dom0._waitForDeviceUUID(mounted_vbd_uuid)
+                fn = BOOTLOADER_LOOPBACK_DEVICE
+
+            try:
+                blcfg = bootloader(blexec, fn, self, False,
+                                   bootloader_args, kernel, ramdisk, args)
+            finally:
+                if mounted:
+                    log.info("Unmounting %s from %s." %
+                             (fn, BOOTLOADER_LOOPBACK_DEVICE))
+                    _, vbd_info = dom0.info['devices'][mounted_vbd_uuid]
+                    dom0.destroyDevice(dom0.getBlockDeviceClass(vbd_info['devid']), 
+                                       BOOTLOADER_LOOPBACK_DEVICE, force = True)
+
+            if blcfg is None:
+                msg = "Had a bootloader specified, but can't find disk"
+                log.error(msg)
+                raise VmError(msg)
+        
+            self.info.update_with_image_sxp(blcfg, True)
+
+
+    # 
+    # VM Functions
+    #
+
+    def _readVMDetails(self, params):
+        """Read the specified parameters from the store.
+        """
+        try:
+            return self._gatherVm(*params)
+        except ValueError:
+            # One of the int/float entries in params has a corresponding store
+            # entry that is invalid.  We recover, because older versions of
+            # Xend may have put the entry there (memory/target, for example),
+            # but this is in general a bad situation to have reached.
+            log.exception(
+                "Store corrupted at %s!  Domain %d's configuration may be "
+                "affected.", self.vmpath, self.domid)
+            return []
+
+    def _cleanupVm(self):
+        """Cleanup VM resources.  Idempotent.  Nothrow guarantee."""
+
+        self._unwatchVm()
+
+        try:
+            self._removeVm()
+        except:
+            log.exception("Removing VM path failed.")
+
+
+    def checkLiveMigrateMemory(self):
+        """ Make sure there's enough memory to migrate this domain """
+        overhead_kb = 0
+        if arch.type == "x86":
+            # 1MB per vcpu plus 4Kib/Mib of RAM.  This is higher than 
+            # the minimum that Xen would allocate if no value were given.
+            overhead_kb = self.info['VCPUs_max'] * 1024 + \
+                          (self.info['memory_static_max'] / 1024 / 1024) * 4
+            overhead_kb = ((overhead_kb + 1023) / 1024) * 1024
+            # The domain might already have some shadow memory
+            overhead_kb -= xc.shadow_mem_control(self.domid) * 1024
+        if overhead_kb > 0:
+            balloon.free(overhead_kb, self)
+
+    def _unwatchVm(self):
+        """Remove the watch on the VM path, if any.  Idempotent.  Nothrow
+        guarantee."""
+        try:
+            try:
+                if self.vmWatch:
+                    self.vmWatch.unwatch()
+            finally:
+                self.vmWatch = None
+        except:
+            log.exception("Unwatching VM path failed.")
+
+    def testDeviceComplete(self):
+        """ For Block IO migration safety we must ensure that
+        the device has shutdown correctly, i.e. all blocks are
+        flushed to disk
+        """
+        start = time.time()
+        while True:
+            test = 0
+            diff = time.time() - start
+            vbds = self.getDeviceController('vbd').deviceIDs()
+            taps = self.getDeviceController('tap').deviceIDs()
+            tap2s = self.getDeviceController('tap2').deviceIDs()
+            for i in vbds + taps + tap2s:
+                test = 1
+                log.info("Dev %s still active, looping...", i)
+                time.sleep(0.1)
+                
+            if test == 0:
+                break
+            if diff >= MIGRATE_TIMEOUT:
+                log.info("Dev still active but hit max loop timeout")
+                break
+
+    def testvifsComplete(self):
+        """ In case vifs are released and then created for the same
+        domain, we need to wait the device shut down.
+        """
+        start = time.time()
+        while True:
+            test = 0
+            diff = time.time() - start
+            for i in self.getDeviceController('vif').deviceIDs():
+                test = 1
+                log.info("Dev %s still active, looping...", i)
+                time.sleep(0.1)
+                
+            if test == 0:
+                break
+            if diff >= MIGRATE_TIMEOUT:
+                log.info("Dev still active but hit max loop timeout")
+                break
+
+    def _storeVmDetails(self):
+        to_store = {}
+
+        for key in XendConfig.LEGACY_XENSTORE_VM_PARAMS:
+            info_key = XendConfig.LEGACY_CFG_TO_XENAPI_CFG.get(key, key)
+            if self._infoIsSet(info_key):
+                to_store[key] = str(self.info[info_key])
+
+        if self._infoIsSet("static_memory_min"):
+            to_store["memory"] = str(self.info["static_memory_min"])
+        if self._infoIsSet("static_memory_max"):
+            to_store["maxmem"] = str(self.info["static_memory_max"])
+
+        image_sxpr = self.info.image_sxpr()
+        if image_sxpr:
+            to_store['image'] = sxp.to_string(image_sxpr)
+
+        if not self._readVm('xend/restart_count'):
+            to_store['xend/restart_count'] = str(0)
+
+        log.debug("Storing VM details: %s", scrub_password(to_store))
+
+        self._writeVm(to_store)
+        self._setVmPermissions()
+
+    def _setVmPermissions(self):
+        """Allow the guest domain to read its UUID.  We don't allow it to
+        access any other entry, for security."""
+        xstransact.SetPermissions('%s/uuid' % self.vmpath,
+                                  { 'dom' : self.domid,
+                                    'read' : True,
+                                    'write' : False })
+
+    #
+    # Utility functions
+    #
+
+    def __getattr__(self, name):
+         if name == "state":
+             log.warn("Somebody tried to read XendDomainInfo.state... should us _stateGet()!!!")
+             log.warn("".join(traceback.format_stack()))
+             return self._stateGet()
+         else:
+             raise AttributeError(name)
+
+    def __setattr__(self, name, value):
+        if name == "state":
+            log.warn("Somebody tried to set XendDomainInfo.state... should us _stateGet()!!!")
+            log.warn("".join(traceback.format_stack()))
+            self._stateSet(value)
+        else:
+            self.__dict__[name] = value
+
+    def _stateSet(self, state):
+        self.state_updated.acquire()
+        try:
+            # TODO Not sure this is correct...
+            # _stateGet is live now. Why not fire event
+            # even when it hasn't changed?
+            if self._stateGet() != state:
+                self.state_updated.notifyAll()
+                import XendAPI
+                XendAPI.event_dispatch('mod', 'VM', self.info['uuid'],
+                                       'power_state')
+        finally:
+            self.state_updated.release()
+
+    def _stateGet(self):
+        # Lets try and reconsitute the state from xc
+        # first lets try and get the domain info
+        # from xc - this will tell us if the domain
+        # exists
+        info = dom_get(self.getDomid())
+        if info is None or info['shutdown']:
+            # We are either HALTED or SUSPENDED
+            # check saved image exists
+            from xen.xend import XendDomain
+            managed_config_path = \
+                XendDomain.instance()._managed_check_point_path( \
+                    self.get_uuid())
+            if os.path.exists(managed_config_path):
+                return XEN_API_VM_POWER_STATE_SUSPENDED
+            else:
+                return XEN_API_VM_POWER_STATE_HALTED
+        elif info['crashed']:
+            # Crashed
+            return XEN_API_VM_POWER_STATE_CRASHED
+        else:
+            # We are either RUNNING or PAUSED
+            if info['paused']:
+                return XEN_API_VM_POWER_STATE_PAUSED
+            else:
+                return XEN_API_VM_POWER_STATE_RUNNING
+
+    def _infoIsSet(self, name):
+        return name in self.info and self.info[name] is not None
+
+    def _checkName(self, name):
+        """Check if a vm name is valid. Valid names contain alphabetic
+        characters, digits, or characters in '_-.:+'.
+        The same name cannot be used for more than one vm at the same time.
+
+        @param name: name
+        @raise: VmError if invalid
+        """
+        from xen.xend import XendDomain
+        
+        if name is None or name == '':
+            raise VmError('Missing VM Name')
+
+        if not re.search(r'^[A-Za-z0-9_\-\.\:\+]+$', name):
+            raise VmError('Invalid VM Name')
+
+        dom =  XendDomain.instance().domain_lookup_nr(name)
+        if dom and dom.info['uuid'] != self.info['uuid']:
+            raise VmError("VM name '%s' already exists%s" %
+                          (name,
+                           dom.domid is not None and
+                           (" as domain %s" % str(dom.domid)) or ""))
+        
+
+    def update(self, info = None, refresh = True, transaction = None):
+        """Update with info from xc.domain_getinfo().
+        """
+        log.trace("XendDomainInfo.update(%s) on domain %s", info,
+                  str(self.domid))
+        
+        if not info:
+            info = dom_get(self.domid)
+            if not info:
+                return
+
+        if info["maxmem_kb"] < 0:
+            info["maxmem_kb"] = XendNode.instance() \
+                                .physinfo_dict()['total_memory'] * 1024
+
+        # make sure state is reset for info
+        # TODO: we should eventually get rid of old_dom_states
+
+        self.info.update_config(info)
+        self._update_consoles(transaction)
+        
+        if refresh:
+            self.refreshShutdown(info)
+
+        log.trace("XendDomainInfo.update done on domain %s: %s",
+                  str(self.domid), self.info)
+
+    def sxpr(self, ignore_store = False, legacy_only = True):
+        result = self.info.to_sxp(domain = self,
+                                  ignore_devices = ignore_store,
+                                  legacy_only = legacy_only)
+
+        return result
+
+    # Xen API
+    # ----------------------------------------------------------------
+
+    def get_uuid(self):
+        dom_uuid = self.info.get('uuid')
+        if not dom_uuid: # if it doesn't exist, make one up
+            dom_uuid = uuid.createString()
+            self.info['uuid'] = dom_uuid
+        return dom_uuid
+    
+    def get_memory_static_max(self):
+        return self.info.get('memory_static_max', 0)
+    def get_memory_static_min(self):
+        return self.info.get('memory_static_min', 0)
+    def get_memory_dynamic_max(self):
+        return self.info.get('memory_dynamic_max', 0)
+    def get_memory_dynamic_min(self):
+        return self.info.get('memory_dynamic_min', 0)
+
+    # only update memory-related config values if they maintain sanity 
+    def _safe_set_memory(self, key, newval):
+        oldval = self.info.get(key, 0)
+        try:
+            self.info[key] = newval
+            self.info._memory_sanity_check()
+        except Exception, ex:
+            self.info[key] = oldval
+            raise 
+    
+    def set_memory_static_max(self, val):
+        self._safe_set_memory('memory_static_max', val)
+    def set_memory_static_min(self, val):
+        self._safe_set_memory('memory_static_min', val)
+    def set_memory_dynamic_max(self, val):
+        self._safe_set_memory('memory_dynamic_max', val)
+    def set_memory_dynamic_min(self, val):
+        self._safe_set_memory('memory_dynamic_min', val)
+    
+    def get_vcpus_params(self):
+        if self.getDomid() is None:
+            return self.info['vcpus_params']
+
+        retval = xc.sched_credit_domain_get(self.getDomid())
+        return retval
+    def get_cpu_pool(self):
+        if self.getDomid() is None:
+            return None
+        xeninfo = dom_get(self.domid)
+        return xeninfo['cpupool']
+    def get_power_state(self):
+        return XEN_API_VM_POWER_STATE[self._stateGet()]
+    def get_platform(self):
+        return self.info.get('platform', {})    
+    def get_pci_bus(self):
+        return self.info.get('pci_bus', '')
+    def get_tools_version(self):
+        return self.info.get('tools_version', {})
+    def get_metrics(self):
+        return self.metrics.get_uuid();
+
+
+    def get_security_label(self, xspol=None):
+        import xen.util.xsm.xsm as security
+        label = security.get_security_label(self, xspol)
+        return label
+
+    def set_security_label(self, seclab, old_seclab, xspol=None,
+                           xspol_old=None):
+        """
+           Set the security label of a domain from its old to
+           a new value.
+           @param seclab  New security label formatted in the form
+                          <policy type>:<policy name>:<vm label>
+           @param old_seclab  The current security label that the
+                          VM must have.
+           @param xspol   An optional policy under which this
+                          update should be done. If not given,
+                          then the current active policy is used.
+           @param xspol_old The old policy; only to be passed during
+                           the updating of a policy
+           @return Returns return code, a string with errors from
+                   the hypervisor's operation, old label of the
+                   domain
+        """
+        rc = 0
+        errors = ""
+        old_label = ""
+        new_ssidref = 0
+        domid = self.getDomid()
+        res_labels = None
+        is_policy_update = (xspol_old != None)
+
+        from xen.xend.XendXSPolicyAdmin import XSPolicyAdminInstance
+
+        state = self._stateGet()
+        # Relabel only HALTED or RUNNING or PAUSED domains
+        if domid != 0 and \
+           state not in \
+              [ DOM_STATE_HALTED, DOM_STATE_RUNNING, DOM_STATE_PAUSED, \
+                DOM_STATE_SUSPENDED ]:
+            log.warn("Relabeling domain not possible in state '%s'" %
+                     DOM_STATES[state])
+            return (-xsconstants.XSERR_VM_WRONG_STATE, "", "", 0)
+
+        # Remove security label. Works only for halted or suspended domains
+        if not seclab or seclab == "":
+            if state not in [ DOM_STATE_HALTED, DOM_STATE_SUSPENDED ]:
+                return (-xsconstants.XSERR_VM_WRONG_STATE, "", "", 0)
+
+            if self.info.has_key('security_label'):
+                old_label = self.info['security_label']
+                # Check label against expected one.
+                if old_label != old_seclab:
+                    return (-xsconstants.XSERR_BAD_LABEL, "", "", 0)
+                del self.info['security_label']
+                xen.xend.XendDomain.instance().managed_config_save(self)
+                return (xsconstants.XSERR_SUCCESS, "", "", 0)
+
+        tmp = seclab.split(":")
+        if len(tmp) != 3:
+            return (-xsconstants.XSERR_BAD_LABEL_FORMAT, "", "", 0)
+        typ, policy, label = tmp
+
+        poladmin = XSPolicyAdminInstance()
+        if not xspol:
+            xspol = poladmin.get_policy_by_name(policy)
+
+        try:
+            xen.xend.XendDomain.instance().policy_lock.acquire_writer()
+
+            if state in [ DOM_STATE_RUNNING, DOM_STATE_PAUSED ]:
+                #if domain is running or paused try to relabel in hypervisor
+                if not xspol:
+                    return (-xsconstants.XSERR_POLICY_NOT_LOADED, "", "", 0)
+
+                if typ != xspol.get_type_name() or \
+                   policy != xspol.get_name():
+                    return (-xsconstants.XSERR_BAD_LABEL, "", "", 0)
+
+                if typ == xsconstants.ACM_POLICY_ID:
+                    new_ssidref = xspol.vmlabel_to_ssidref(label)
+                    if new_ssidref == xsconstants.INVALID_SSIDREF:
+                        return (-xsconstants.XSERR_BAD_LABEL, "", "", 0)
+
+                    # Check that all used resources are accessible under the
+                    # new label
+                    if not is_policy_update and \
+                       not security.resources_compatible_with_vmlabel(xspol,
+                              self, label):
+                        return (-xsconstants.XSERR_BAD_LABEL, "", "", 0)
+
+                    #Check label against expected one. Can only do this
+                    # if the policy hasn't changed underneath in the meantime
+                    if xspol_old == None:
+                        old_label = self.get_security_label()
+                        if old_label != old_seclab:
+                            log.info("old_label != old_seclab: %s != %s" %
+                                     (old_label, old_seclab))
+                            return (-xsconstants.XSERR_BAD_LABEL, "", "", 0)
+
+                    # relabel domain in the hypervisor
+                    rc, errors = security.relabel_domains([[domid, new_ssidref]])
+                    log.info("rc from relabeling in HV: %d" % rc)
+                else:
+                    return (-xsconstants.XSERR_POLICY_TYPE_UNSUPPORTED, "", "", 0)
+
+            if rc == 0:
+                # HALTED, RUNNING or PAUSED
+                if domid == 0:
+                    if xspol:
+                        self.info['security_label'] = seclab
+                        ssidref = poladmin.set_domain0_bootlabel(xspol, label)
+                    else:
+                        return (-xsconstants.XSERR_POLICY_NOT_LOADED, "", "", 0)
+                else:
+                    if self.info.has_key('security_label'):
+                        old_label = self.info['security_label']
+                        # Check label against expected one, unless wildcard
+                        if old_label != old_seclab:
+                            return (-xsconstants.XSERR_BAD_LABEL, "", "", 0)
+
+                    self.info['security_label'] = seclab
+
+                    try:
+                        xen.xend.XendDomain.instance().managed_config_save(self)
+                    except:
+                        pass
+            return (rc, errors, old_label, new_ssidref)
+        finally:
+            xen.xend.XendDomain.instance().policy_lock.release()
+
+    def get_on_shutdown(self):
+        after_shutdown = self.info.get('actions_after_shutdown')
+        if not after_shutdown or after_shutdown not in XEN_API_ON_NORMAL_EXIT:
+            return XEN_API_ON_NORMAL_EXIT[-1]
+        return after_shutdown
+
+    def get_on_reboot(self):
+        after_reboot = self.info.get('actions_after_reboot')
+        if not after_reboot or after_reboot not in XEN_API_ON_NORMAL_EXIT:
+            return XEN_API_ON_NORMAL_EXIT[-1]
+        return after_reboot
+
+    def get_on_suspend(self):
+        # TODO: not supported        
+        after_suspend = self.info.get('actions_after_suspend') 
+        if not after_suspend or after_suspend not in XEN_API_ON_NORMAL_EXIT:
+            return XEN_API_ON_NORMAL_EXIT[-1]
+        return after_suspend        
+
+    def get_on_crash(self):
+        after_crash = self.info.get('actions_after_crash')
+        if not after_crash or after_crash not in \
+               XEN_API_ON_CRASH_BEHAVIOUR + restart_modes:
+            return XEN_API_ON_CRASH_BEHAVIOUR[0]
+        return XEN_API_ON_CRASH_BEHAVIOUR_FILTER[after_crash]
+
+    def get_dev_config_by_uuid(self, dev_class, dev_uuid):
+        """ Get's a device configuration either from XendConfig or
+        from the DevController.
+
+        @param dev_class: device class, either, 'vbd' or 'vif'
+        @param dev_uuid: device UUID
+
+        @rtype: dictionary
+        """
+        dev_type, dev_config = self.info['devices'].get(dev_uuid, (None, None))
+
+        # shortcut if the domain isn't started because
+        # the devcontrollers will have no better information
+        # than XendConfig.
+        if self._stateGet() in (XEN_API_VM_POWER_STATE_HALTED,
+                                XEN_API_VM_POWER_STATE_SUSPENDED):
+            if dev_config:
+                return copy.deepcopy(dev_config)
+            return None
+
+        # instead of using dev_class, we use the dev_type
+        # that is from XendConfig.
+        controller = self.getDeviceController(dev_type)
+        if not controller:
+            return None
+            
+        all_configs = controller.getAllDeviceConfigurations()
+        if not all_configs:
+            return None
+
+        updated_dev_config = copy.deepcopy(dev_config)
+        for _devid, _devcfg in all_configs.items():
+            if _devcfg.get('uuid') == dev_uuid:
+                updated_dev_config.update(_devcfg)
+                updated_dev_config['id'] = _devid
+                return updated_dev_config
+
+        return updated_dev_config
+                    
+    def get_dev_xenapi_config(self, dev_class, dev_uuid):
+        config = self.get_dev_config_by_uuid(dev_class, dev_uuid)
+        if not config:
+            return {}
+        
+        config['VM'] = self.get_uuid()
+        
+        if dev_class == 'vif':
+            if not config.has_key('name'):
+                config['name'] = config.get('vifname', '')
+            if not config.has_key('MAC'):
+                config['MAC'] = config.get('mac', '')
+            if not config.has_key('type'):
+                config['type'] = 'paravirtualised'
+            if not config.has_key('device'):
+                devid = config.get('id')
+                if devid != None:
+                    config['device'] = 'eth%s' % devid
+                else:
+                    config['device'] = ''
+
+            if not config.has_key('network'):
+                try:
+                    bridge = config.get('bridge', None)
+                    if bridge is None:
+                        from xen.util import Brctl
+                        if_to_br = dict([(i,b)
+                            for (b,ifs) in Brctl.get_state().items()
+                                for i in ifs])
+                        vifname = "vif%s.%s" % (self.getDomid(),
+                                                config.get('id'))
+                        bridge = if_to_br.get(vifname, None)
+                    config['network'] = \
+                        XendNode.instance().bridge_to_network(
+                        config.get('bridge')).get_uuid()
+                except Exception:
+                    log.exception('bridge_to_network')
+                    # Ignore this for now -- it may happen if the device
+                    # has been specified using the legacy methods, but at
+                    # some point we're going to have to figure out how to
+                    # handle that properly.
+
+            config['MTU'] = 1500 # TODO
+            
+            if self._stateGet() not in (XEN_API_VM_POWER_STATE_HALTED,):
+                xennode = XendNode.instance()
+                rx_bps, tx_bps = xennode.get_vif_util(self.domid, devid)
+                config['io_read_kbs'] = rx_bps/1024
+                config['io_write_kbs'] = tx_bps/1024
+                rx, tx = xennode.get_vif_stat(self.domid, devid)
+                config['io_total_read_kbs'] = rx/1024
+                config['io_total_write_kbs'] = tx/1024
+            else:
+                config['io_read_kbs'] = 0.0
+                config['io_write_kbs'] = 0.0          
+                config['io_total_read_kbs'] = 0.0
+                config['io_total_write_kbs'] = 0.0
+
+            config['security_label'] = config.get('security_label', '')
+
+        if dev_class == 'vbd':
+
+            if self._stateGet() not in (XEN_API_VM_POWER_STATE_HALTED,):
+                controller = self.getDeviceController(dev_class)
+                devid, _1, _2 = controller.getDeviceDetails(config)
+                xennode = XendNode.instance()
+                rd_blkps, wr_blkps = xennode.get_vbd_util(self.domid, devid)
+                config['io_read_kbs'] = rd_blkps
+                config['io_write_kbs'] = wr_blkps
+            else:
+                config['io_read_kbs'] = 0.0
+                config['io_write_kbs'] = 0.0                
+            
+            config['VDI'] = config.get('VDI', '')
+            config['device'] = config.get('dev', '')
+            if config['device'].startswith('ioemu:'):
+                _, vbd_device = config['device'].split(':', 1)
+                config['device'] = vbd_device
+            if ':' in config['device']:
+                vbd_name, vbd_type = config['device'].split(':', 1)
+                config['device'] = vbd_name
+                if vbd_type == 'cdrom':
+                    config['type'] = XEN_API_VBD_TYPE[0]
+                else:
+                    config['type'] = XEN_API_VBD_TYPE[1]
+
+            config['driver'] = 'paravirtualised' # TODO
+            config['image'] = config.get('uname', '')
+
+            if config.get('mode', 'r') == 'r':
+                config['mode'] = 'RO'
+            else:
+                config['mode'] = 'RW'
+
+        return config
+
+    def get_dev_property(self, dev_class, dev_uuid, field):
+        config = self.get_dev_xenapi_config(dev_class, dev_uuid)
+        try:
+            return config[field]
+        except KeyError:
+            raise XendError('Invalid property for device: %s' % field)
+
+    def set_dev_property(self, dev_class, dev_uuid, field, value):
+        self.info['devices'][dev_uuid][1][field] = value
+
+    def get_vcpus_util(self):
+        vcpu_util = {}
+        xennode = XendNode.instance()
+        if 'VCPUs_max' in self.info and self.domid != None:
+            for i in range(0, self.info['VCPUs_max']):
+                util = xennode.get_vcpu_util(self.domid, i)
+                vcpu_util[str(i)] = util
+                
+        return vcpu_util
+
+    def get_consoles(self):
+        return self.info.get('console_refs', [])
+
+    def get_vifs(self):
+        return self.info.get('vif_refs', [])
+
+    def get_vbds(self):
+        return self.info.get('vbd_refs', [])
+
+    def get_dpcis(self):
+        return XendDPCI.get_by_VM(self.info.get('uuid'))
+
+    def get_dscsis(self):
+        return XendDSCSI.get_by_VM(self.info.get('uuid'))
+
+    def get_dscsi_HBAs(self):
+        return XendDSCSI_HBA.get_by_VM(self.info.get('uuid'))
+
+    def create_vbd(self, xenapi_vbd, vdi_image_path):
+        """Create a VBD using a VDI from XendStorageRepository.
+
+        @param xenapi_vbd: vbd struct from the Xen API
+        @param vdi_image_path: VDI UUID
+        @rtype: string
+        @return: uuid of the device
+        """
+        xenapi_vbd['image'] = vdi_image_path
+        if vdi_image_path.startswith('tap'):
+            dev_uuid = self.info.device_add('tap2', cfg_xenapi = xenapi_vbd)
+        else:
+            dev_uuid = self.info.device_add('vbd', cfg_xenapi = xenapi_vbd)
+            
+        if not dev_uuid:
+            raise XendError('Failed to create device')
+
+        if self._stateGet() in (XEN_API_VM_POWER_STATE_RUNNING,
+                                XEN_API_VM_POWER_STATE_PAUSED):
+            _, config = self.info['devices'][dev_uuid]
+            
+            if vdi_image_path.startswith('tap'):
+                dev_control = self.getDeviceController('tap2')
+            else:
+                dev_control = self.getDeviceController('vbd')
+
+            try:
+                devid = dev_control.createDevice(config)
+                dev_type = self.getBlockDeviceClass(devid)
+                self._waitForDevice(dev_type, devid)
+                self.info.device_update(dev_uuid,
+                                        cfg_xenapi = {'devid': devid})
+            except Exception, exn:
+                log.exception(exn)
+                del self.info['devices'][dev_uuid]
+                self.info['vbd_refs'].remove(dev_uuid)
+                raise
+            
+        return dev_uuid
+
+    def create_phantom_vbd_with_vdi(self, xenapi_vbd, vdi_image_path):
+        """Create a VBD using a VDI from XendStorageRepository.
+
+        @param xenapi_vbd: vbd struct from the Xen API
+        @param vdi_image_path: VDI UUID
+        @rtype: string
+        @return: uuid of the device
+        """
+        xenapi_vbd['image'] = vdi_image_path
+        dev_uuid = self.info.phantom_device_add('tap', cfg_xenapi = xenapi_vbd)
+        if not dev_uuid:
+            raise XendError('Failed to create device')
+
+        if self._stateGet() == XEN_API_VM_POWER_STATE_RUNNING:
+            _, config = self.info['devices'][dev_uuid]
+            config['devid'] = self.getDeviceController('tap').createDevice(config)
+
+        return config['devid']
+
+    def create_vif(self, xenapi_vif):
+        """Create VIF device from the passed struct in Xen API format.
+
+        @param xenapi_vif: Xen API VIF Struct.
+        @rtype: string
+        @return: UUID
+        """
+        dev_uuid = self.info.device_add('vif', cfg_xenapi = xenapi_vif)
+        if not dev_uuid:
+            raise XendError('Failed to create device')
+        
+        if self._stateGet() in (XEN_API_VM_POWER_STATE_RUNNING,
+                                XEN_API_VM_POWER_STATE_PAUSED):
+
+            _, config = self.info['devices'][dev_uuid]
+            dev_control = self.getDeviceController('vif')
+
+            try:
+                devid = dev_control.createDevice(config)
+                dev_control.waitForDevice(devid)
+                self.info.device_update(dev_uuid,
+                                        cfg_xenapi = {'devid': devid})
+            except Exception, exn:
+                log.exception(exn)
+                del self.info['devices'][dev_uuid]
+                self.info['vif_refs'].remove(dev_uuid)
+                raise            
+ 
+        return dev_uuid
+
+    def create_console(self, xenapi_console):
+        """ Create a console device from a Xen API struct.
+
+        @return: uuid of device
+        @rtype: string
+        """
+        if self._stateGet() not in (DOM_STATE_HALTED,):
+            raise VmError("Can only add console to a halted domain.")
+
+        dev_uuid = self.info.device_add('console', cfg_xenapi = xenapi_console)
+        if not dev_uuid:
+            raise XendError('Failed to create device')
+
+        return dev_uuid
+
+    def set_console_other_config(self, console_uuid, other_config):
+        self.info.console_update(console_uuid, 'other_config', other_config)
+
+    def create_dpci(self, xenapi_pci):
+        """Create pci device from the passed struct in Xen API format.
+
+        @param xenapi_pci: DPCI struct from Xen API
+        @rtype: bool
+        #@rtype: string
+        @return: True if successfully created device
+        #@return: UUID
+        """
+
+        dpci_uuid = uuid.createString()
+
+        dpci_opts = []
+        opts_dict = xenapi_pci.get('options')
+        for k in opts_dict.keys():
+            dpci_opts.append([k, opts_dict[k]])
+        opts_sxp = pci_opts_list_to_sxp(dpci_opts)
+
+        # Convert xenapi to sxp
+        ppci = XendAPIStore.get(xenapi_pci.get('PPCI'), 'PPCI')
+
+        dev_sxp = ['dev',
+                   ['domain', '0x%02x' % ppci.get_domain()],
+                   ['bus', '0x%02x' % ppci.get_bus()],
+                   ['slot', '0x%02x' % ppci.get_slot()],
+                   ['func', '0x%1x' % ppci.get_func()],
+                   ['vdevfn', '0x%02x' % xenapi_pci.get('hotplug_slot')],
+                   ['key', xenapi_pci['key']],
+                   ['uuid', dpci_uuid]]
+        dev_sxp = sxp.merge(dev_sxp, opts_sxp)
+
+        target_pci_sxp = ['pci', dev_sxp, ['state', 'Initialising'] ]
+
+        if self._stateGet() != XEN_API_VM_POWER_STATE_RUNNING:
+
+            old_pci_sxp = self._getDeviceInfo_pci(0)
+
+            if old_pci_sxp is None:
+                dev_uuid = self.info.device_add('pci', cfg_sxp = target_pci_sxp)
+                if not dev_uuid:
+                    raise XendError('Failed to create device')
+
+            else:
+                new_pci_sxp = ['pci']
+                for existing_dev in sxp.children(old_pci_sxp, 'dev'):
+                    new_pci_sxp.append(existing_dev)
+                new_pci_sxp.append(sxp.child0(target_pci_sxp, 'dev'))
+
+                dev_uuid = sxp.child_value(old_pci_sxp, 'uuid')
+                self.info.device_update(dev_uuid, new_pci_sxp)
+
+            xen.xend.XendDomain.instance().managed_config_save(self)
+
+        else:
+            try:
+                self.device_configure(target_pci_sxp)
+
+            except Exception, exn:
+                raise XendError('Failed to create device')
+
+        return dpci_uuid
+
+    def create_dscsi(self, xenapi_dscsi):
+        """Create scsi device from the passed struct in Xen API format.
+
+        @param xenapi_dscsi: DSCSI struct from Xen API
+        @rtype: string
+        @return: UUID
+        """
+
+        dscsi_uuid = uuid.createString()
+
+        # Convert xenapi to sxp
+        pscsi = XendAPIStore.get(xenapi_dscsi.get('PSCSI'), 'PSCSI')
+        devid = int(xenapi_dscsi.get('virtual_HCTL').split(':')[0])
+        target_vscsi_sxp = \
+            ['vscsi', 
+                ['dev',
+                    ['devid', devid],
+                    ['p-devname', pscsi.get_dev_name()],
+                    ['p-dev', pscsi.get_physical_HCTL()],
+                    ['v-dev', xenapi_dscsi.get('virtual_HCTL')],
+                    ['state', xenbusState['Initialising']],
+                    ['uuid', dscsi_uuid]
+                ],
+                ['feature-host', 0]
+            ]
+
+        if self._stateGet() != XEN_API_VM_POWER_STATE_RUNNING:
+
+            cur_vscsi_sxp = self._getDeviceInfo_vscsi(devid)
+
+            if cur_vscsi_sxp is None:
+                dev_uuid = self.info.device_add('vscsi', cfg_sxp = target_vscsi_sxp)
+                if not dev_uuid:
+                    raise XendError('Failed to create device')
+
+            else:
+                new_vscsi_sxp = ['vscsi', ['feature-host', 0]]
+                for existing_dev in sxp.children(cur_vscsi_sxp, 'dev'):
+                    new_vscsi_sxp.append(existing_dev)
+                new_vscsi_sxp.append(sxp.child0(target_vscsi_sxp, 'dev'))
+
+                dev_uuid = sxp.child_value(cur_vscsi_sxp, 'uuid')
+                self.info.device_update(dev_uuid, new_vscsi_sxp)
+
+            xen.xend.XendDomain.instance().managed_config_save(self)
+
+        else:
+            try:
+                self.device_configure(target_vscsi_sxp)
+            except Exception, exn:
+                log.exception('create_dscsi: %s', exn)
+                raise XendError('Failed to create device')
+
+        return dscsi_uuid
+
+    def create_dscsi_HBA(self, xenapi_dscsi):
+        """Create scsi devices from the passed struct in Xen API format.
+
+        @param xenapi_dscsi: DSCSI_HBA struct from Xen API
+        @rtype: string
+        @return: UUID
+        """
+
+        dscsi_HBA_uuid = uuid.createString()
+
+        # Convert xenapi to sxp
+        feature_host = xenapi_dscsi.get('assignment_mode', 'HOST') == 'HOST' and 1 or 0
+        target_vscsi_sxp = \
+            ['vscsi',
+                ['feature-host', feature_host],
+                ['uuid', dscsi_HBA_uuid],
+            ]
+        pscsi_HBA = XendAPIStore.get(xenapi_dscsi.get('PSCSI_HBA'), 'PSCSI_HBA')
+        devid = pscsi_HBA.get_physical_host()
+        for pscsi_uuid in pscsi_HBA.get_PSCSIs():
+            pscsi = XendAPIStore.get(pscsi_uuid, 'PSCSI')
+            pscsi_HCTL = pscsi.get_physical_HCTL()
+            dscsi_uuid = uuid.createString()
+            dev = \
+                ['dev',
+                    ['devid', devid],
+                    ['p-devname', pscsi.get_dev_name()],
+                    ['p-dev', pscsi_HCTL],
+                    ['v-dev', pscsi_HCTL],
+                    ['state', xenbusState['Initialising']],
+                    ['uuid', dscsi_uuid]
+                ]
+            target_vscsi_sxp.append(dev)
+
+        if self._stateGet() != XEN_API_VM_POWER_STATE_RUNNING:
+            if not self.info.device_add('vscsi', cfg_sxp = target_vscsi_sxp):
+                raise XendError('Failed to create device')
+            xen.xend.XendDomain.instance().managed_config_save(self)
+        else:
+            try:
+                self.device_configure(target_vscsi_sxp)
+            except Exception, exn:
+                log.exception('create_dscsi_HBA: %s', exn)
+                raise XendError('Failed to create device')
+
+        return dscsi_HBA_uuid
+
+
+    def change_vdi_of_vbd(self, xenapi_vbd, vdi_image_path):
+        """Change current VDI with the new VDI.
+
+        @param xenapi_vbd: vbd struct from the Xen API
+        @param vdi_image_path: path of VDI
+        """
+        dev_uuid = xenapi_vbd['uuid']
+        if dev_uuid not in self.info['devices']:
+            raise XendError('Device does not exist')
+
+        # Convert xenapi to sxp
+        if vdi_image_path.startswith('tap'):
+            dev_class = 'tap'
+        else:
+            dev_class = 'vbd'
+        dev_sxp = [
+            dev_class,
+            ['uuid',  dev_uuid],
+            ['uname', vdi_image_path],
+            ['dev',   '%s:cdrom' % xenapi_vbd['device']],
+            ['mode',  'r'],
+            ['VDI',   xenapi_vbd['VDI']]
+        ]
+
+        if self._stateGet() in (XEN_API_VM_POWER_STATE_RUNNING,
+                                XEN_API_VM_POWER_STATE_PAUSED):
+            self.device_configure(dev_sxp)
+        else:
+            self.info.device_update(dev_uuid, dev_sxp)
+
+
+    def destroy_device_by_uuid(self, dev_type, dev_uuid):
+        if dev_uuid not in self.info['devices']:
+            raise XendError('Device does not exist')
+
+        try:
+            if self._stateGet() in (XEN_API_VM_POWER_STATE_RUNNING,
+                                    XEN_API_VM_POWER_STATE_PAUSED):
+                _, config = self.info['devices'][dev_uuid]
+                devid = config.get('devid')
+                if devid != None:
+                    self.getDeviceController(dev_type).destroyDevice(devid, force = False)
+                else:
+                    raise XendError('Unable to get devid for device: %s:%s' %
+                                    (dev_type, dev_uuid))
+        finally:
+            del self.info['devices'][dev_uuid]
+            self.info['%s_refs' % dev_type].remove(dev_uuid)
+
+    def destroy_vbd(self, dev_uuid):
+        self.destroy_device_by_uuid('vbd', dev_uuid)
+
+    def destroy_vif(self, dev_uuid):
+        self.destroy_device_by_uuid('vif', dev_uuid)
+
+    def destroy_dpci(self, dev_uuid):
+
+        dpci = XendAPIStore.get(dev_uuid, 'DPCI')
+        ppci = XendAPIStore.get(dpci.get_PPCI(), 'PPCI')
+
+        old_pci_sxp = self._getDeviceInfo_pci(0)
+        dev_uuid = sxp.child_value(old_pci_sxp, 'uuid')
+        target_dev = None
+        new_pci_sxp = ['pci']
+        for dev in sxp.children(old_pci_sxp, 'dev'):
+            pci_dev = {}
+            pci_dev['domain'] = sxp.child_value(dev, 'domain')
+            pci_dev['bus'] = sxp.child_value(dev, 'bus')
+            pci_dev['slot'] = sxp.child_value(dev, 'slot')
+            pci_dev['func'] = sxp.child_value(dev, 'func')
+            if ppci.get_name() == pci_dict_to_bdf_str(pci_dev):
+                target_dev = dev
+            else:
+                new_pci_sxp.append(dev)
+
+        if target_dev is None:
+            raise XendError('Failed to destroy device')
+
+        target_pci_sxp = ['pci', target_dev, ['state', 'Closing']]
+
+        if self._stateGet() != XEN_API_VM_POWER_STATE_RUNNING:
+
+            self.info.device_update(dev_uuid, new_pci_sxp)
+            if len(sxp.children(new_pci_sxp, 'dev')) == 0:
+                del self.info['devices'][dev_uuid]
+            xen.xend.XendDomain.instance().managed_config_save(self)
+
+        else:
+            try:
+                self.device_configure(target_pci_sxp)
+
+            except Exception, exn:
+                raise XendError('Failed to destroy device')
+
+    def destroy_dscsi(self, dev_uuid):
+        dscsi = XendAPIStore.get(dev_uuid, 'DSCSI')
+        devid = dscsi.get_virtual_host()
+        vHCTL = dscsi.get_virtual_HCTL()
+        cur_vscsi_sxp = self._getDeviceInfo_vscsi(devid)
+        dev_uuid = sxp.child_value(cur_vscsi_sxp, 'uuid')
+
+        target_dev = None
+        new_vscsi_sxp = ['vscsi', ['feature-host', 0]]
+        for dev in sxp.children(cur_vscsi_sxp, 'dev'):
+            if vHCTL == sxp.child_value(dev, 'v-dev'):
+                target_dev = dev
+            else:
+                new_vscsi_sxp.append(dev)
+
+        if target_dev is None:
+            raise XendError('Failed to destroy device')
+
+        target_dev.append(['state', xenbusState['Closing']])
+        target_vscsi_sxp = ['vscsi', target_dev, ['feature-host', 0]]
+
+        if self._stateGet() != XEN_API_VM_POWER_STATE_RUNNING:
+
+            self.info.device_update(dev_uuid, new_vscsi_sxp)
+            if len(sxp.children(new_vscsi_sxp, 'dev')) == 0:
+                del self.info['devices'][dev_uuid]
+            xen.xend.XendDomain.instance().managed_config_save(self)
+
+        else:
+            try:
+                self.device_configure(target_vscsi_sxp)
+            except Exception, exn:
+                log.exception('destroy_dscsi: %s', exn)
+                raise XendError('Failed to destroy device')
+
+    def destroy_dscsi_HBA(self, dev_uuid):
+        dscsi_HBA = XendAPIStore.get(dev_uuid, 'DSCSI_HBA')
+        devid = dscsi_HBA.get_virtual_host()
+        cur_vscsi_sxp = self._getDeviceInfo_vscsi(devid)
+        feature_host = sxp.child_value(cur_vscsi_sxp, 'feature-host')
+
+        if self._stateGet() != XEN_API_VM_POWER_STATE_RUNNING:
+            new_vscsi_sxp = ['vscsi', ['feature-host', feature_host]]
+            self.info.device_update(dev_uuid, new_vscsi_sxp)
+            del self.info['devices'][dev_uuid]
+            xen.xend.XendDomain.instance().managed_config_save(self)
+        else:
+            # If feature_host is 1, all devices are destroyed by just
+            # one reconfiguration.
+            # If feature_host is 0, we should reconfigure all devices
+            # one-by-one to destroy all devices.
+            # See reconfigureDevice@VSCSIController. 
+            for dev in sxp.children(cur_vscsi_sxp, 'dev'):
+                target_vscsi_sxp = [
+                    'vscsi',
+                    dev + [['state', xenbusState['Closing']]],
+                    ['feature-host', feature_host]
+                ]
+                try:
+                    self.device_configure(target_vscsi_sxp)
+                except Exception, exn:
+                    log.exception('destroy_dscsi_HBA: %s', exn)
+                    raise XendError('Failed to destroy device')
+                if feature_host:
+                    break
+
+    def destroy_xapi_instances(self):
+        """Destroy Xen-API instances stored in XendAPIStore.
+        """
+        # Xen-API classes based on XendBase have their instances stored
+        # in XendAPIStore. Cleanup these instances here, if they are supposed
+        # to be destroyed when the parent domain is dead.
+        #
+        # Most of the virtual devices (vif, vbd, vfb, etc) are not based on
+        # XendBase and there's no need to remove them from XendAPIStore.
+
+        from xen.xend import XendDomain
+        if XendDomain.instance().is_valid_vm(self.info.get('uuid')):
+            # domain still exists.
+            return
+
+        # Destroy the VMMetrics instance.
+        if XendAPIStore.get(self.metrics.get_uuid(), self.metrics.getClass()) \
+                is not None:
+            self.metrics.destroy()
+
+        # Destroy DPCI instances.
+        for dpci_uuid in XendDPCI.get_by_VM(self.info.get('uuid')):
+            XendAPIStore.deregister(dpci_uuid, "DPCI")
+            
+        # Destroy DSCSI instances.
+        for dscsi_uuid in XendDSCSI.get_by_VM(self.info.get('uuid')):
+            XendAPIStore.deregister(dscsi_uuid, "DSCSI")
+            
+        # Destroy DSCSI_HBA instances.
+        for dscsi_HBA_uuid in XendDSCSI_HBA.get_by_VM(self.info.get('uuid')):
+            XendAPIStore.deregister(dscsi_HBA_uuid, "DSCSI_HBA")
+            
+    def has_device(self, dev_class, dev_uuid):
+        return (dev_uuid in self.info['%s_refs' % dev_class.lower()])
+
+    def __str__(self):
+        return '<domain id=%s name=%s memory=%s state=%s>' % \
+               (str(self.domid), self.info['name_label'],
+                str(self.info['memory_dynamic_max']), DOM_STATES[self._stateGet()])
+
+    __repr__ = __str__
+
diff -Naur xen/tools/python/xen/xend/image.py xen-b/tools/python/xen/xend/image.py
--- xen/tools/python/xen/xend/image.py	2013-05-08 21:21:22.268147770 -0600
+++ xen-b/tools/python/xen/xend/image.py	2013-05-12 06:30:26.771481103 -0600
@@ -122,6 +122,10 @@
         self.vm.permissionsVm("image/cmdline", { 'dom': self.vm.getDomid(), 'read': True } )
 
         self.device_model = vmConfig['platform'].get('device_model')
+        self.actmem = str(vmConfig['platform'].get('actmem'))
+        self.xenpaging_file = str(vmConfig['platform'].get('xenpaging_file'))
+        self.xenpaging_extra = vmConfig['platform'].get('xenpaging_extra')
+        self.xenpaging_pid = None
 
         self.display = vmConfig['platform'].get('display')
         self.xauthority = vmConfig['platform'].get('xauthority')
@@ -392,6 +396,87 @@
         sentinel_fifos_inuse[sentinel_path_fifo] = 1
         self.sentinel_path_fifo = sentinel_path_fifo
 
+    def createXenPaging(self):
+        if not self.vm.info.is_hvm():
+            return
+        if self.actmem == "0":
+            return
+        if self.xenpaging_pid:
+            return
+        xenpaging_bin = auxbin.pathTo("xenpaging")
+        args = [xenpaging_bin]
+        args = args + ([ "-f", "/var/lib/xen/xenpaging/%s.%d.paging" % (str(self.vm.info['name_label']), self.vm.getDomid())])
+        if self.xenpaging_extra:
+            args = args + (self.xenpaging_extra)
+        args = args + ([ "-d", "%d" % self.vm.getDomid()])
+        self.xenpaging_logfile = "/var/log/xen/xenpaging-%s.log" %  str(self.vm.info['name_label'])
+        logfile_mode = os.O_WRONLY|os.O_CREAT|os.O_APPEND|os.O_TRUNC
+        null = os.open("/dev/null", os.O_RDONLY)
+        try:
+            os.unlink(self.xenpaging_logfile)
+        except:
+            pass
+        logfd = os.open(self.xenpaging_logfile, logfile_mode, 0644)
+        sys.stderr.flush()
+        contract = osdep.prefork("%s:%d" % (self.vm.getName(), self.vm.getDomid()))
+        xenpaging_pid = os.fork()
+        if xenpaging_pid == 0: #child
+            try:
+                osdep.postfork(contract)
+                os.dup2(null, 0)
+                os.dup2(logfd, 1)
+                os.dup2(logfd, 2)
+                try:
+                    env = dict(os.environ)
+                    log.info("starting %s" % args)
+                    os.execve(xenpaging_bin, args, env)
+                except Exception, e:
+                    log.warn('failed to execute xenpaging: %s' % utils.exception_string(e))
+                    os._exit(126)
+            except:
+                log.warn("starting xenpaging failed")
+                os._exit(127)
+        else:
+            osdep.postfork(contract, abandon=True)
+            self.xenpaging_pid = xenpaging_pid
+            os.close(null)
+            os.close(logfd)
+        self.vm.storeDom("xenpaging/xenpaging-pid", self.xenpaging_pid)
+        self.vm.storeDom("memory/target-tot_pages", int(self.actmem) * 1024)
+
+    def destroyXenPaging(self):
+        if self.actmem == "0":
+            return
+        if self.xenpaging_pid:
+            try:
+                os.kill(self.xenpaging_pid, signal.SIGHUP)
+            except OSError, exn:
+                log.exception(exn)
+            for i in xrange(100):
+                try:
+                    (p, rv) = os.waitpid(self.xenpaging_pid, os.WNOHANG)
+                    if p == self.xenpaging_pid:
+                        break
+                except OSError:
+                    # This is expected if Xend has been restarted within
+                    # the life of this domain.  In this case, we can kill
+                    # the process, but we can't wait for it because it's
+                    # not our child. We continue this loop, and after it is
+                    # terminated make really sure the process is going away
+                    # (SIGKILL).
+                    pass
+                time.sleep(0.1)
+            else:
+                log.warning("xenpaging %d took more than 10s "
+                            "to terminate: sending SIGKILL" % self.xenpaging_pid)
+                try:
+                    os.kill(self.xenpaging_pid, signal.SIGKILL)
+                    os.waitpid(self.xenpaging_pid, 0)
+                except OSError:
+                    # This happens if the process doesn't exist.
+                    pass
+        self.xenpaging_pid = None
+
     def createDeviceModel(self, restore = False):
         if self.device_model is None:
             return
@@ -828,6 +913,7 @@
 
         self.apic = int(vmConfig['platform'].get('apic', 0))
         self.acpi = int(vmConfig['platform'].get('acpi', 0))
+        self.extid = int(vmConfig['platform'].get('extid', 0))
         self.guest_os_type = vmConfig['platform'].get('guest_os_type')
         self.memory_sharing = int(vmConfig['memory_sharing'])
         try:
@@ -855,7 +941,8 @@
 
         dmargs = [ 'boot', 'fda', 'fdb', 'soundhw',
                    'localtime', 'serial', 'stdvga', 'isa',
-                   'acpi', 'usb', 'usbdevice', 'gfx_passthru' ]
+                   'acpi', 'usb', 'usbdevice', 'gfx_passthru',
+                   'watchdog', 'watchdog_action' ]
 
         for a in dmargs:
             v = vmConfig['platform'].get(a)
@@ -863,6 +950,7 @@
             # python doesn't allow '-' in variable names
             if a == 'stdvga': a = 'std-vga'
             if a == 'keymap': a = 'k'
+            if a == 'watchdog_action': a = 'watchdog-action'
 
             # Handle booleans gracefully
             if a in ['localtime', 'std-vga', 'isa', 'usb', 'acpi']:
@@ -1036,7 +1124,7 @@
 
     def configure(self, vmConfig):
         HVMImageHandler.configure(self, vmConfig)
-        self.pae = int(vmConfig['platform'].get('pae',  0))
+        self.pae = int(vmConfig['platform'].get('pae',  1))
         self.vramsize = int(vmConfig['platform'].get('videoram',4)) * 1024
 
     def buildDomain(self):
diff -Naur xen/tools/python/xen/xend/server/BlktapController.py xen-b/tools/python/xen/xend/server/BlktapController.py
--- xen/tools/python/xen/xend/server/BlktapController.py	2013-05-08 21:21:22.268147770 -0600
+++ xen-b/tools/python/xen/xend/server/BlktapController.py	2013-05-12 06:30:26.771481103 -0600
@@ -15,6 +15,7 @@
     'ram',
     'qcow',
     'qcow2',
+    'cdrom',
     'ioemu',
     ]
 
diff -Naur xen/tools/python/xen/xend/server/DevController.py xen-b/tools/python/xen/xend/server/DevController.py
--- xen/tools/python/xen/xend/server/DevController.py	2013-05-08 21:21:22.271481103 -0600
+++ xen-b/tools/python/xen/xend/server/DevController.py	2013-05-12 06:30:26.771481103 -0600
@@ -149,7 +149,10 @@
         (status, err) = self.waitForBackend(devid)
 
         if status == Timeout:
-            self.destroyDevice(devid, False)
+            #Clean timeout backend resource
+            dev = self.convertToDeviceNumber(devid)
+            self.writeBackend(dev, HOTPLUG_STATUS_NODE, HOTPLUG_STATUS_ERROR)
+            self.destroyDevice(devid, True)
             raise VmError("Device %s (%s) could not be connected. "
                           "Hotplug scripts not working." %
                           (devid, self.deviceClass))
@@ -554,7 +557,17 @@
 
             xswatch(statusPath, hotplugStatusCallback, ev, result)
 
-            ev.wait(DEVICE_CREATE_TIMEOUT)
+            for i in range(1, 50):
+                ev.wait(DEVICE_CREATE_TIMEOUT/50)
+                status = xstransact.Read(statusPath)
+                if status is not None:
+                    if status == HOTPLUG_STATUS_ERROR:
+                        result['status'] = Error
+                    elif status == HOTPLUG_STATUS_BUSY:
+                        result['status'] = Busy
+                    else:
+                        result['status'] = Connected
+                    break
 
             err = xstransact.Read(backpath, HOTPLUG_ERROR_NODE)
 
@@ -571,7 +584,12 @@
 
         xswatch(statusPath, deviceDestroyCallback, ev, result)
 
-        ev.wait(DEVICE_DESTROY_TIMEOUT)
+        for i in range(1, 50):
+            ev.wait(DEVICE_DESTROY_TIMEOUT/50)
+            status = xstransact.Read(statusPath)
+            if status is None:
+                result['status'] = Disconnected
+                break 
 
         return result['status']
 
diff -Naur xen/tools/python/xen/xm/cpupool.py xen-b/tools/python/xen/xm/cpupool.py
--- xen/tools/python/xen/xm/cpupool.py	2013-05-08 21:21:22.278147769 -0600
+++ xen-b/tools/python/xen/xm/cpupool.py	2013-05-12 06:30:26.774814436 -0600
@@ -157,9 +157,17 @@
             #    ["0,2","1,3"]       -> [[0,2],[1,3]]
             #    ["0-3,^1","1-4,^2"] -> [[0,2,3],[1,3,4]]
             try:
-                for c in cfg_cpus:
-                    cpus = cnv(c)
-                    cpus_list.append(cpus)
+                cpus_str = ""
+                list_len = len(cfg_cpus)
+                n = 0
+                while n < list_len:
+                    if type(cfg_cpus[n]) != str:
+                        raise SyntaxError('cpus = %s' % cfg_cpus)
+                    cpus_str += cfg_cpus[n]
+                    n += 1
+                    if n < list_len:
+                        cpus_str += ', '
+                cpus_list = cnv(cpus_str)
             except ValueError, e:
                 raise err('cpus = %s: %s' % (cfg_cpus, e))
     else:
diff -Naur xen/tools/python/xen/xm/create.py xen-b/tools/python/xen/xm/create.py
--- xen/tools/python/xen/xm/create.py	2013-05-08 21:21:22.278147769 -0600
+++ xen-b/tools/python/xen/xm/create.py	2013-05-12 06:30:26.774814436 -0600
@@ -36,7 +36,7 @@
 from xen.util import blkif
 from xen.util import vscsi_util
 import xen.util.xsm.xsm as security
-from xen.xm.main import serverType, SERVER_XEN_API, get_single_vm
+from xen.xm.main import serverType, SERVER_XEN_API, SERVER_LEGACY_XMLRPC, get_single_vm
 from xen.util import utils, auxbin
 from xen.util.pci import dev_dict_to_sxp, \
                          parse_pci_name_extended, PciDeviceParseError
@@ -242,6 +242,10 @@
           use="""Expose Viridian interface to x86 HVM guest?
           (Default is 0).""")
 
+gopts.var('extid', val='EXTID',
+          fn=set_int, default=0,
+          use="Specify extention ID for a HVM domain.")
+
 gopts.var('acpi', val='ACPI',
           fn=set_int, default=1,
           use="Disable or enable ACPI of HVM domain.")
@@ -473,6 +477,18 @@
           fn=set_value, default=None,
           use="Set the path of the root NFS directory.")
 
+gopts.var('actmem', val='NUM',
+          fn=set_value, default='0',
+          use="Number of pages to swap.")
+
+gopts.var('xenpaging_file', val='PATH',
+          fn=set_value, default=None,
+          use="pagefile to use (optional)")
+
+gopts.var('xenpaging_extra', val='string1,string2',
+          fn=append_value, default=[],
+          use="additional args for xenpaging (optional)")
+
 gopts.var('device_model', val='FILE',
           fn=set_value, default=None,
           use="Path to device model program.")
@@ -517,6 +533,21 @@
           fn=set_value, default='',
           use="Name of USB device to add?")
 
+gopts.var('watchdog', val='NAME',
+          fn=set_value, default='',
+          use="Watchdog device to use. May be ib700 or i6300esb")
+
+gopts.var('watchdog_action', val='reset|shutdown|poweroff|pause|none|dump',
+          fn=set_value, default="reset",
+          use="""Action when watchdog timer expires:
+          - reset:     Default, forcefully reset the guest;
+          - shutdown:  Gracefully shutdown the guest (not recommended);
+          - poweroff:  Forcefully power off the guest;
+          - pause:     Pause the guest;
+          - none:      Do nothing;
+          - dump:      Automatically dump the guest;
+          """)
+
 gopts.var('description', val='NAME',
           fn=set_value, default='',
           use="Description of a domain")
@@ -1032,6 +1063,9 @@
     args = [ 'acpi', 'apic',
              'boot',
              'cpuid', 'cpuid_check',
+             'actmem',
+             'xenpaging_file',
+             'xenpaging_extra',
              'device_model', 'display',
              'fda', 'fdb',
              'gfx_passthru', 'guest_os_type',
@@ -1047,7 +1081,7 @@
              'timer_mode',
              'usb', 'usbdevice',
              'vcpus', 'vnc', 'vncconsole', 'vncdisplay', 'vnclisten',
-             'vncunused', 'viridian', 'vpt_align',
+             'vncunused', 'vpt_align',
              'xauthority', 'xen_extended_power_mgmt', 'xen_platform_pci',
              'memory_sharing' ]
 
@@ -1056,6 +1090,10 @@
             config_image.append([a, vals.__dict__[a]])
     if vals.vncpasswd is not None:
         config_image.append(['vncpasswd', vals.vncpasswd])
+    if vals.extid and vals.extid == 1:
+        config_image.append(['viridian', vals.extid])
+    elif vals.viridian:
+        config_image.append(['viridian', vals.viridian])
 
 
 def make_config(vals):
@@ -1072,6 +1110,7 @@
         if hasattr(vals, 'vcpus'):
             vcpus = getattr(vals, 'vcpus')
 
+             'watchdog', 'watchdog_action',
         if maxvcpus and not vcpus:
             config.append(['vcpus', maxvcpus])
         if maxvcpus and vcpus:
@@ -1465,7 +1504,7 @@
             except IOError, exn:
                 raise OptionError("Cannot read file %s: %s" % (config, exn[1]))
         
-        if serverType == SERVER_XEN_API:
+        if serverType == SERVER_XEN_API or serverType == SERVER_LEGACY_XMLRPC:
             from xen.xm.xenapi_create import sxp2xml
             sxp2xml_inst = sxp2xml()
             doc = sxp2xml_inst.convert_sxp_to_xml(config, transient=True)
@@ -1473,7 +1512,7 @@
         if opts.vals.dryrun and not opts.is_xml:
             SXPPrettyPrint.prettyprint(config)
 
-        if opts.vals.xmldryrun and serverType == SERVER_XEN_API:
+        if opts.vals.xmldryrun:
             print doc.toprettyxml()
 
     if opts.vals.dryrun or opts.vals.xmldryrun:
diff -Naur xen/tools/python/xen/xm/main.py xen-b/tools/python/xen/xm/main.py
--- xen/tools/python/xen/xm/main.py	2013-05-08 21:21:22.278147769 -0600
+++ xen-b/tools/python/xen/xm/main.py	2013-05-12 06:30:26.774814436 -0600
@@ -114,6 +114,8 @@
                      'Set the maximum amount reservation for a domain.'),
     'mem-set'     : ('<Domain> <Mem>',
                      'Set the current memory usage for a domain.'),
+    'mem-swap-target' : ('<Domain> <Mem>',
+                     'Set the memory usage for a domain.'),
     'migrate'     : ('<Domain> <Host>',
                      'Migrate a domain to another machine.'),
     'pause'       : ('<Domain>', 'Pause execution of a domain.'),
@@ -121,7 +123,7 @@
     'reset'       : ('<Domain>', 'Reset a domain.'),
     'restore'     : ('<CheckpointFile> [-p]',
                      'Restore a domain from a saved state.'),
-    'save'        : ('[-c] <Domain> <CheckpointFile>',
+    'save'        : ('[-c|-f] <Domain> <CheckpointFile>',
                      'Save a domain state to restore later.'),
     'shutdown'    : ('<Domain> [-waRH]', 'Shutdown a domain.'),
     'top'         : ('', 'Monitor a host and the domains in real time.'),
@@ -341,6 +343,7 @@
     ),
     'save': (
        ('-c', '--checkpoint', 'Leave domain running after creating snapshot'),
+       ('-f', '--force', 'Force to overwrite exist file'),
     ),
     'restore': (
        ('-p', '--paused', 'Do not unpause domain after restoring it'),
@@ -862,18 +865,21 @@
 
 def xm_save(args):
 
-    arg_check(args, "save", 2, 3)
+    arg_check(args, "save", 2, 4)
     
     try:
-        (options, params) = getopt.gnu_getopt(args, 'c', ['checkpoint'])
+        (options, params) = getopt.gnu_getopt(args, 'cf', ['checkpoint', 'force'])
     except getopt.GetoptError, opterr:
         err(opterr)
         usage('save')
 
     checkpoint = False
+    force = False
     for (k, v) in options:
         if k in ['-c', '--checkpoint']:
             checkpoint = True
+        if k in ['-f', '--force']:
+            force = True
 
     if len(params) != 2:
         err("Wrong number of parameters")
@@ -1580,6 +1586,17 @@
         mem_target = int_unit(args[1], 'm')
         server.xend.domain.setMemoryTarget(dom, mem_target)
 
+def xm_mem_swap_target(args):
+    arg_check(args, "mem-swap-target", 2)
+
+    dom = args[0]
+
+    if serverType == SERVER_XEN_API:
+        err("xenapi not supported")
+    else:
+        swap_target = int_unit(args[1], 'm')
+        server.xend.domain.swaptarget_set(dom, swap_target)
+
 def xm_usb_add(args):
     arg_check(args, "usb-add", 2)
     server.xend.domain.usb_add(args[0],args[1])
@@ -3782,6 +3799,7 @@
     # memory commands
     "mem-max": xm_mem_max,
     "mem-set": xm_mem_set,
+    "mem-swap-target": xm_mem_swap_target,
     # cpu commands
     "vcpu-pin": xm_vcpu_pin,
     "vcpu-list": xm_vcpu_list,
diff -Naur xen/tools/python/xen/xm/xenapi_create.py xen-b/tools/python/xen/xm/xenapi_create.py
--- xen/tools/python/xen/xm/xenapi_create.py	2013-05-08 21:21:22.281481102 -0600
+++ xen-b/tools/python/xen/xm/xenapi_create.py	2013-05-12 06:30:26.774814436 -0600
@@ -1046,6 +1046,9 @@
             'acpi',
             'apic',
             'boot',
+            'actmem',
+            'xenpaging_file',
+            'xenpaging_extra',
             'device_model',
             'loader',
             'fda',
@@ -1074,7 +1077,9 @@
             'xen_platform_pci',
             'tsc_mode'
             'description',
-            'nomigrate'
+            'nomigrate',
+            'watchdog',
+            'watchdog_action'
         ]
 
         platform_configs = []
diff -Naur xen/tools/tests/mce-test/tools/Makefile xen-b/tools/tests/mce-test/tools/Makefile
--- xen/tools/tests/mce-test/tools/Makefile	2013-05-08 21:21:22.281481102 -0600
+++ xen-b/tools/tests/mce-test/tools/Makefile	2013-05-12 06:30:26.774814436 -0600
@@ -1,7 +1,7 @@
 XEN_ROOT=$(CURDIR)/../../../..
 include $(XEN_ROOT)/tools/Rules.mk
 
-CFLAGS += -Werror
+CFLAGS +=
 CFLAGS += $(CFLAGS_libxenctrl)
 CFLAGS += $(CFLAGS_libxenguest)
 CFLAGS += $(CFLAGS_libxenstore) 
diff -Naur xen/tools/tests/mem-sharing/Makefile xen-b/tools/tests/mem-sharing/Makefile
--- xen/tools/tests/mem-sharing/Makefile	2013-05-08 21:21:22.281481102 -0600
+++ xen-b/tools/tests/mem-sharing/Makefile	2013-05-12 06:30:26.774814436 -0600
@@ -1,7 +1,7 @@
 XEN_ROOT=$(CURDIR)/../../..
 include $(XEN_ROOT)/tools/Rules.mk
 
-CFLAGS += -Werror
+CFLAGS +=
 
 CFLAGS += $(CFLAGS_libxenctrl)
 CFLAGS += $(CFLAGS_xeninclude)
diff -Naur xen/tools/tests/xen-access/Makefile xen-b/tools/tests/xen-access/Makefile
--- xen/tools/tests/xen-access/Makefile	2013-05-08 21:21:22.284814436 -0600
+++ xen-b/tools/tests/xen-access/Makefile	2013-05-12 06:30:26.774814436 -0600
@@ -1,7 +1,7 @@
 XEN_ROOT=$(CURDIR)/../../..
 include $(XEN_ROOT)/tools/Rules.mk
 
-CFLAGS += -Werror
+CFLAGS +=
 
 CFLAGS += $(CFLAGS_libxenctrl)
 CFLAGS += $(CFLAGS_libxenguest)
diff -Naur xen/tools/xenstat/xentop/Makefile xen-b/tools/xenstat/xentop/Makefile
--- xen/tools/xenstat/xentop/Makefile	2013-05-08 21:21:22.288147770 -0600
+++ xen-b/tools/xenstat/xentop/Makefile	2013-05-12 06:30:26.774814436 -0600
@@ -18,7 +18,7 @@
 all install xentop:
 else
 
-CFLAGS += -DGCC_PRINTF -Wall -Werror $(CFLAGS_libxenstat)
+CFLAGS += -DGCC_PRINTF -Wall $(CFLAGS_libxenstat)
 LDLIBS += $(LDLIBS_libxenstat) $(CURSES_LIBS) $(SOCKET_LIBS)
 CFLAGS += -DHOST_$(XEN_OS)
 
diff -Naur xen/tools/xenstore/xenstore.h xen-b/tools/xenstore/xenstore.h
--- xen/tools/xenstore/xenstore.h	2013-05-08 21:21:22.291481103 -0600
+++ xen-b/tools/xenstore/xenstore.h	2013-05-12 06:30:26.774814436 -0600
@@ -26,6 +26,7 @@
 
 #define XS_OPEN_READONLY	1UL<<0
 #define XS_OPEN_SOCKETONLY      1UL<<1
+#define XS_OPEN_DOMAINONLY      1UL<<2
 
 /*
  * Setting XS_UNWATCH_FILTER arranges that after xs_unwatch, no
diff -Naur xen/tools/xenstore/xenstore_client.c xen-b/tools/xenstore/xenstore_client.c
--- xen/tools/xenstore/xenstore_client.c	2013-05-08 21:21:22.291481103 -0600
+++ xen-b/tools/xenstore/xenstore_client.c	2013-05-12 06:30:26.774814436 -0600
@@ -629,7 +629,7 @@
 	    max_width = ws.ws_col - 2;
     }
 
-    xsh = xs_open(socket ? XS_OPEN_SOCKETONLY : 0);
+    xsh = xs_open(socket ? XS_OPEN_SOCKETONLY : XS_OPEN_DOMAINONLY);
     if (xsh == NULL) err(1, "xs_open");
 
 again:
diff -Naur xen/tools/xenstore/xs.c xen-b/tools/xenstore/xs.c
--- xen/tools/xenstore/xs.c	2013-05-08 21:21:22.291481103 -0600
+++ xen-b/tools/xenstore/xs.c	2013-05-12 06:30:26.778147769 -0600
@@ -278,17 +278,19 @@
 
 struct xs_handle *xs_domain_open(void)
 {
-	return xs_open(0);
+	return xs_open(XS_OPEN_DOMAINONLY);
 }
 
 struct xs_handle *xs_open(unsigned long flags)
 {
 	struct xs_handle *xsh = NULL;
 
+	if (!(flags & XS_OPEN_DOMAINONLY)) {
 	if (flags & XS_OPEN_READONLY)
 		xsh = get_handle(xs_daemon_socket_ro());
 	else
 		xsh = get_handle(xs_daemon_socket());
+	}
 
 	if (!xsh && !(flags & XS_OPEN_SOCKETONLY))
 		xsh = get_handle(xs_domain_dev());
diff -Naur xen/unmodified_drivers/linux-2.6/Module.supported xen-b/unmodified_drivers/linux-2.6/Module.supported
--- xen/unmodified_drivers/linux-2.6/Module.supported	1969-12-31 17:00:00.000000000 -0700
+++ xen-b/unmodified_drivers/linux-2.6/Module.supported	2013-05-12 06:30:26.778147769 -0600
@@ -0,0 +1,6 @@
+xen-vbd
+xen-platform-pci
+xen-vnif
+xenbus
+xen-balloon
+xen-scsi
diff -Naur xen/unmodified_drivers/linux-2.6/platform-pci/evtchn.c xen-b/unmodified_drivers/linux-2.6/platform-pci/evtchn.c
--- xen/unmodified_drivers/linux-2.6/platform-pci/evtchn.c	2013-05-08 21:21:22.311481104 -0600
+++ xen-b/unmodified_drivers/linux-2.6/platform-pci/evtchn.c	2013-05-12 06:30:26.778147769 -0600
@@ -40,7 +40,9 @@
 #include <xen/platform-compat.h>
 #endif
 
+#ifndef shared_info_area
 void *shared_info_area;
+#endif
 
 #define is_valid_evtchn(x)	((x) != 0)
 #define evtchn_from_irq(x)	(irq_evtchn[irq].evtchn)
diff -Naur xen/unmodified_drivers/linux-2.6/platform-pci/platform-pci.c xen-b/unmodified_drivers/linux-2.6/platform-pci/platform-pci.c
--- xen/unmodified_drivers/linux-2.6/platform-pci/platform-pci.c	2013-05-08 21:21:22.311481104 -0600
+++ xen-b/unmodified_drivers/linux-2.6/platform-pci/platform-pci.c	2013-05-12 06:30:26.778147769 -0600
@@ -27,6 +27,7 @@
 #include <linux/pci.h>
 #include <linux/init.h>
 #include <linux/version.h>
+#include <linux/dmi.h>
 #include <linux/interrupt.h>
 #include <linux/vmalloc.h>
 #include <linux/mm.h>
@@ -76,7 +77,6 @@
 static int __devinit init_xen_info(void)
 {
 	struct xen_add_to_physmap xatp;
-	extern void *shared_info_area;
 
 #ifdef __ia64__
 	xencomm_initialize();
@@ -84,6 +84,7 @@
 
 	setup_xen_features();
 
+#ifndef shared_info_area
 	shared_info_frame = alloc_xen_mmio(PAGE_SIZE) >> PAGE_SHIFT;
 	xatp.domid = DOMID_SELF;
 	xatp.idx = 0;
@@ -96,6 +97,11 @@
 		ioremap(shared_info_frame << PAGE_SHIFT, PAGE_SIZE);
 	if (shared_info_area == NULL)
 		panic("can't map shared info\n");
+#else
+	shared_info_frame = __pa(shared_info_area) >> PAGE_SHIFT;
+	printk(KERN_INFO "Using kernel provided shared info (pfn=%lx)\n",
+	       shared_info_frame);
+#endif
 
 	return 0;
 }
@@ -469,6 +475,18 @@
 
 MODULE_DEVICE_TABLE(pci, platform_pci_tbl);
 
+static const struct dmi_system_id platform_dmi_tbl[] = {
+	{
+		.ident = "Xen PV-on-HVM",
+		.matches = {
+			DMI_MATCH(DMI_SYS_VENDOR, "Xen"),
+			DMI_MATCH(DMI_PRODUCT_NAME, "HVM domU"),
+		},
+	},
+	{ },
+};
+MODULE_DEVICE_TABLE(dmi, platform_dmi_tbl);
+
 static struct pci_driver platform_driver = {
 	name:     DRV_NAME,
 	probe:    platform_pci_init,
diff -Naur xen/unmodified_drivers/linux-2.6/platform-pci/platform-pci.h xen-b/unmodified_drivers/linux-2.6/platform-pci/platform-pci.h
--- xen/unmodified_drivers/linux-2.6/platform-pci/platform-pci.h	2013-05-08 21:21:22.311481104 -0600
+++ xen-b/unmodified_drivers/linux-2.6/platform-pci/platform-pci.h	2013-05-12 06:30:26.778147769 -0600
@@ -27,6 +27,11 @@
 unsigned long alloc_xen_mmio(unsigned long len);
 void platform_pci_resume(void);
 
+#ifdef CONFIG_ENLIGHTEN_SPINLOCKS
+#define shared_info_area xen_shared_info
+#endif
+extern void *shared_info_area;
+
 extern struct pci_dev *xen_platform_pdev;
 
 #endif /* _XEN_PLATFORM_PCI_H */
diff -Naur xen/xen/Makefile xen-b/xen/Makefile
--- xen/xen/Makefile	2013-05-08 21:21:22.311481104 -0600
+++ xen-b/xen/Makefile	2013-05-12 06:30:26.778147769 -0600
@@ -13,6 +13,8 @@
 export XEN_ROOT := $(BASEDIR)/..
 
 EFI_MOUNTPOINT ?= /boot/efi
+EFI_VENDOR=fedora
+LD_EFI ?= $(LD)
 
 .PHONY: default
 default: build
diff -Naur xen/xen/arch/arm/Rules.mk xen-b/xen/arch/arm/Rules.mk
--- xen/xen/arch/arm/Rules.mk	2013-05-08 21:21:22.311481104 -0600
+++ xen-b/xen/arch/arm/Rules.mk	2013-05-12 06:30:26.778147769 -0600
@@ -11,7 +11,7 @@
 HAS_ARM_HDLCD := y
 
 CFLAGS += -fno-builtin -fno-common -Wredundant-decls
-CFLAGS += -iwithprefix include -Werror -Wno-pointer-arith -pipe
+CFLAGS += -iwithprefix include -Wno-pointer-arith -pipe
 CFLAGS += -I$(BASEDIR)/include
 
 $(call cc-options-add,CFLAGS,CC,$(EMBEDDED_EXTRA_CFLAGS))
diff -Naur xen/xen/arch/arm/gic.c xen-b/xen/arch/arm/gic.c
--- xen/xen/arch/arm/gic.c	2013-05-08 21:21:22.314814436 -0600
+++ xen-b/xen/arch/arm/gic.c	2013-05-12 06:30:26.778147769 -0600
@@ -26,7 +26,6 @@
 #include <xen/errno.h>
 #include <xen/softirq.h>
 #include <xen/list.h>
-#include <xen/device_tree.h>
 #include <asm/p2m.h>
 #include <asm/domain.h>
 
@@ -43,7 +42,6 @@
     paddr_t dbase;       /* Address of distributor registers */
     paddr_t cbase;       /* Address of CPU interface registers */
     paddr_t hbase;       /* Address of virtual interface registers */
-    paddr_t vbase;       /* Address of virtual cpu interface registers */
     unsigned int lines;  /* Number of interrupts (SPIs + PPIs + SGIs) */
     unsigned int cpus;
     spinlock_t lock;
@@ -339,10 +337,10 @@
          (early_info.gic.gic_vcpu_addr & ~PAGE_MASK) )
         panic("GIC interfaces not page aligned.\n");
 
-    gic.dbase = early_info.gic.gic_dist_addr;
-    gic.cbase = early_info.gic.gic_cpu_addr;
-    gic.hbase = early_info.gic.gic_hyp_addr;
-    gic.vbase = early_info.gic.gic_vcpu_addr;
+    /* XXX FIXME get this from devicetree */
+    gic.dbase = GIC_BASE_ADDRESS + GIC_DR_OFFSET;
+    gic.cbase = GIC_BASE_ADDRESS + GIC_CR_OFFSET;
+    gic.hbase = GIC_BASE_ADDRESS + GIC_HR_OFFSET;
     set_fixmap(FIXMAP_GICD, gic.dbase >> PAGE_SHIFT, DEV_SHARED);
     BUILD_BUG_ON(FIXMAP_ADDR(FIXMAP_GICC1) !=
                  FIXMAP_ADDR(FIXMAP_GICC2)-PAGE_SIZE);
@@ -716,9 +714,9 @@
 {
     /* map the gic virtual cpu interface in the gic cpu interface region of
      * the guest */
-    return map_mmio_regions(d, gic.cbase,
-                        gic.cbase + (2 * PAGE_SIZE) - 1,
-                        gic.vbase);
+    return map_mmio_regions(d, GIC_BASE_ADDRESS + GIC_CR_OFFSET,
+                        GIC_BASE_ADDRESS + GIC_CR_OFFSET + (2 * PAGE_SIZE) - 1,
+                        GIC_BASE_ADDRESS + GIC_VR_OFFSET);
 }
 
 static void gic_irq_eoi(void *info)
diff -Naur xen/xen/arch/x86/Rules.mk xen-b/xen/arch/x86/Rules.mk
--- xen/xen/arch/x86/Rules.mk	2013-05-08 21:21:22.318147768 -0600
+++ xen-b/xen/arch/x86/Rules.mk	2013-05-12 06:30:26.778147769 -0600
@@ -26,7 +26,7 @@
 endif
 
 CFLAGS += -fno-builtin -fno-common -Wredundant-decls
-CFLAGS += -iwithprefix include -Werror -Wno-pointer-arith -pipe
+CFLAGS += -iwithprefix include -Wno-pointer-arith -pipe
 CFLAGS += -I$(BASEDIR)/include 
 CFLAGS += -I$(BASEDIR)/include/asm-x86/mach-generic
 CFLAGS += -I$(BASEDIR)/include/asm-x86/mach-default
diff -Naur xen/xen/arch/x86/hvm/stdvga.c xen-b/xen/arch/x86/hvm/stdvga.c
--- xen/xen/arch/x86/hvm/stdvga.c	2013-05-08 21:21:22.331481104 -0600
+++ xen-b/xen/arch/x86/hvm/stdvga.c	2013-05-12 06:30:26.778147769 -0600
@@ -135,7 +135,10 @@
 
     /* When in standard vga mode, emulate here all writes to the vram buffer
      * so we can immediately satisfy reads without waiting for qemu. */
-    s->stdvga = (s->sr[7] == 0x00);
+    s->stdvga =
+        (s->sr[7] == 0x00) &&  /* standard vga mode */
+        (s->gr[6] == 0x05);    /* misc graphics register w/ MemoryMapSelect=1
+                                * 0xa0000-0xaffff (64k region), AlphaDis=1 */
 
     if ( !prev_stdvga && s->stdvga )
     {
diff -Naur xen/xen/arch/x86/io_apic.c xen-b/xen/arch/x86/io_apic.c
--- xen/xen/arch/x86/io_apic.c	2013-05-08 21:21:22.334814437 -0600
+++ xen-b/xen/arch/x86/io_apic.c	2013-05-12 06:30:26.781481103 -0600
@@ -1995,7 +1995,10 @@
         io_apic_irqs = ~PIC_IRQS;
 
     printk("ENABLING IO-APIC IRQs\n");
-    printk(" -> Using %s ACK method\n", ioapic_ack_new ? "new" : "old");
+    if (!directed_eoi_enabled && !ioapic_ack_forced) {
+        ioapic_ack_new = (nr_ioapics > 1);
+        printk(" -> Using %s ACK method\n", ioapic_ack_new ? "new" : "old");
+    }
 
     if (ioapic_ack_new) {
         ioapic_level_type.ack = irq_complete_move;
diff -Naur xen/xen/arch/x86/platform_hypercall.c xen-b/xen/arch/x86/platform_hypercall.c
--- xen/xen/arch/x86/platform_hypercall.c	2013-05-08 21:21:22.348147769 -0600
+++ xen-b/xen/arch/x86/platform_hypercall.c	2013-05-12 06:30:26.781481103 -0600
@@ -25,7 +25,7 @@
 #include <xen/irq.h>
 #include <asm/current.h>
 #include <public/platform.h>
-#include <acpi/cpufreq/processor_perf.h>
+#include <acpi/cpufreq/cpufreq.h>
 #include <asm/edd.h>
 #include <asm/mtrr.h>
 #include <asm/io_apic.h>
@@ -597,6 +597,41 @@
     }
     break;
 
+    case XENPF_get_cpu_freq:
+    case XENPF_get_cpu_freq_min:
+    case XENPF_get_cpu_freq_max:
+    {
+        struct vcpu *v;
+        const struct cpufreq_policy *policy;
+
+        if ( op->u.get_cpu_freq.vcpu >= current->domain->max_vcpus ||
+             !(v = current->domain->vcpu[op->u.get_cpu_freq.vcpu]) )
+        {
+            ret = -EINVAL;
+            break;
+        }
+
+        policy = per_cpu(cpufreq_cpu_policy, v->processor);
+        switch ( op->cmd & -!!policy )
+        {
+        case XENPF_get_cpu_freq:
+            op->u.get_cpu_freq.freq = policy->cur;
+            break;
+        case XENPF_get_cpu_freq_min:
+            op->u.get_cpu_freq.freq = policy->min;
+            break;
+        case XENPF_get_cpu_freq_max:
+            op->u.get_cpu_freq.freq = policy->max;
+            break;
+        default:
+            op->u.get_cpu_freq.freq = 0;
+            break;
+        }
+        if ( copy_field_to_guest(u_xenpf_op, op, u.get_cpu_freq.freq) )
+            ret = -EFAULT;
+    }
+    break;
+
     default:
         ret = -ENOSYS;
         break;
diff -Naur xen/xen/arch/x86/x86_64/entry.S xen-b/xen/arch/x86/x86_64/entry.S
--- xen/xen/arch/x86/x86_64/entry.S	2013-05-08 21:21:22.351481103 -0600
+++ xen-b/xen/arch/x86/x86_64/entry.S	2013-05-12 06:30:26.781481103 -0600
@@ -433,22 +433,35 @@
         jz    domain_crash_synchronous
         movq  %rax,UREGS_rip+8(%rsp)
         ret
-        _ASM_EXTABLE(.Lft2,  domain_crash_synchronous)
-        _ASM_EXTABLE(.Lft3,  domain_crash_synchronous)
-        _ASM_EXTABLE(.Lft4,  domain_crash_synchronous)
-        _ASM_EXTABLE(.Lft5,  domain_crash_synchronous)
-        _ASM_EXTABLE(.Lft6,  domain_crash_synchronous)
-        _ASM_EXTABLE(.Lft7,  domain_crash_synchronous)
-        _ASM_EXTABLE(.Lft8,  domain_crash_synchronous)
-        _ASM_EXTABLE(.Lft9,  domain_crash_synchronous)
-        _ASM_EXTABLE(.Lft10, domain_crash_synchronous)
-        _ASM_EXTABLE(.Lft11, domain_crash_synchronous)
-        _ASM_EXTABLE(.Lft12, domain_crash_synchronous)
-        _ASM_EXTABLE(.Lft13, domain_crash_synchronous)
+        _ASM_EXTABLE(.Lft2,  domain_crash_page_fault_32)
+        _ASM_EXTABLE(.Lft3,  domain_crash_page_fault_24)
+        _ASM_EXTABLE(.Lft4,  domain_crash_page_fault_8)
+        _ASM_EXTABLE(.Lft5,  domain_crash_page_fault_16)
+        _ASM_EXTABLE(.Lft6,  domain_crash_page_fault)
+        _ASM_EXTABLE(.Lft7,  domain_crash_page_fault)
+        _ASM_EXTABLE(.Lft8,  domain_crash_page_fault_24)
+        _ASM_EXTABLE(.Lft9,  domain_crash_page_fault_16)
+        _ASM_EXTABLE(.Lft10, domain_crash_page_fault_8)
+        _ASM_EXTABLE(.Lft11, domain_crash_page_fault)
+        _ASM_EXTABLE(.Lft12, domain_crash_page_fault_8)
+        _ASM_EXTABLE(.Lft13, domain_crash_page_fault)
 
+.section .rodata, "a", @progbits
 domain_crash_synchronous_string:
         .asciz "domain_crash_sync called from entry.S\n"
+.previous
 
+domain_crash_page_fault_32:
+        addq  $8,%rsi
+domain_crash_page_fault_24:
+        addq  $8,%rsi
+domain_crash_page_fault_16:
+        addq  $8,%rsi
+domain_crash_page_fault_8:
+        addq  $8,%rsi
+domain_crash_page_fault:
+        movq  %rsi,%rdi
+        call  show_page_walk
 ENTRY(domain_crash_synchronous)
         # Get out of the guest-save area of the stack.
         GET_STACK_BASE(%rax)
diff -Naur xen/xen/include/Makefile xen-b/xen/include/Makefile
--- xen/xen/include/Makefile	2013-05-08 21:21:22.378147769 -0600
+++ xen-b/xen/include/Makefile	2013-05-12 06:30:26.781481103 -0600
@@ -78,7 +78,7 @@
 all: headers.chk
 
 headers.chk: $(filter-out public/arch-% public/%ctl.h public/xsm/% public/%hvm/save.h, $(wildcard public/*.h public/*/*.h) $(public-y)) Makefile
-	for i in $(filter %.h,$^); do $(CC) -ansi -include stdint.h -Wall -W -Werror -S -o /dev/null -xc $$i || exit 1; echo $$i; done >$@.new
+	for i in $(filter %.h,$^); do $(CC) -ansi -include stdint.h -Wall -W -S -o /dev/null -xc $$i || exit 1; echo $$i; done >$@.new
 	mv $@.new $@
 
 endif
diff -Naur xen/xen/include/public/io/blkif.h xen-b/xen/include/public/io/blkif.h
--- xen/xen/include/public/io/blkif.h	2013-05-08 21:21:22.401481102 -0600
+++ xen-b/xen/include/public/io/blkif.h	2013-05-12 06:30:26.781481103 -0600
@@ -439,7 +439,7 @@
  * Used in SLES sources for device specific command packet
  * contained within the request. Reserved for that purpose.
  */
-#define BLKIF_OP_RESERVED_1        4
+#define BLKIF_OP_PACKET        4
 /*
  * Indicate to the backend device that a region of storage is no longer in
  * use, and may be discarded at any time without impact to the client.  If
diff -Naur xen/xen/include/public/io/cdromif.h xen-b/xen/include/public/io/cdromif.h
--- xen/xen/include/public/io/cdromif.h	1969-12-31 17:00:00.000000000 -0700
+++ xen-b/xen/include/public/io/cdromif.h	2013-05-12 06:30:26.781481103 -0600
@@ -0,0 +1,122 @@
+/******************************************************************************
+ * cdromif.h
+ *
+ * Shared definitions between backend driver and Xen guest Virtual CDROM
+ * block device.
+ *
+ * Copyright (c) 2008, Pat Campell  plc@novell.com
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this source file (the "Software"), to deal in the Software without
+ * restriction, including without limitation the rights to use, copy, modify,
+ * merge, publish, distribute, sublicense, and/or sell copies of the Software,
+ * and to permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
+ * IN THE SOFTWARE.
+ */
+
+#ifndef __XEN_PUBLIC_IO_CDROMIF_H__
+#define __XEN_PUBLIC_IO_CDROMIF_H__
+
+#include <linux/cdrom.h>
+
+/*
+ * Queries backend for CDROM support
+ */
+#define XEN_TYPE_CDROM_SUPPORT         _IO('c', 1)
+
+struct xen_cdrom_support
+{
+	uint32_t type;
+	int8_t ret;                  /* returned, 0 succeded, -1 error */
+	int8_t err;                  /* returned, backend errno */
+	int8_t supported;            /* returned, 1 supported */
+};
+
+/*
+ * Opens backend device, returns drive geometry or
+ * any encountered errors
+ */
+#define XEN_TYPE_CDROM_OPEN            _IO('c', 2)
+
+struct xen_cdrom_open
+{
+	uint32_t type;
+	int8_t ret;
+	int8_t err;
+	int8_t pad;
+	int8_t media_present;        /* returned */
+	uint32_t sectors;            /* returned */
+	uint32_t sector_size;        /* returned */
+	int32_t payload_offset;      /* offset to backend node name payload */
+};
+
+/*
+ * Queries backend for media changed status
+ */
+#define XEN_TYPE_CDROM_MEDIA_CHANGED   _IO('c', 3)
+
+struct xen_cdrom_media_changed
+{
+	uint32_t type;
+	int8_t ret;
+	int8_t err;
+	int8_t media_changed;        /* returned */
+};
+
+/*
+ * Sends vcd generic CDROM packet to backend, followed
+ * immediately by the vcd_generic_command payload
+ */
+#define XEN_TYPE_CDROM_PACKET          _IO('c', 4)
+
+struct xen_cdrom_packet
+{
+	uint32_t type;
+	int8_t ret;
+	int8_t err;
+	int8_t pad[2];
+	int32_t payload_offset;      /* offset to struct vcd_generic_command payload */
+};
+
+/* CDROM_PACKET_COMMAND, payload for XEN_TYPE_CDROM_PACKET */
+struct vcd_generic_command
+{
+	uint8_t  cmd[CDROM_PACKET_SIZE];
+	uint8_t  pad[4];
+	uint32_t buffer_offset;
+	uint32_t buflen;
+	int32_t  stat;
+	uint32_t sense_offset;
+	uint8_t  data_direction;
+	uint8_t  pad1[3];
+	int32_t  quiet;
+	int32_t  timeout;
+};
+
+union xen_block_packet
+{
+	uint32_t type;
+	struct xen_cdrom_support xcs;
+	struct xen_cdrom_open xco;
+	struct xen_cdrom_media_changed xcmc;
+	struct xen_cdrom_packet xcp;
+};
+
+#define PACKET_PAYLOAD_OFFSET (sizeof(struct xen_cdrom_packet))
+#define PACKET_SENSE_OFFSET (PACKET_PAYLOAD_OFFSET + sizeof(struct vcd_generic_command))
+#define PACKET_BUFFER_OFFSET (PACKET_SENSE_OFFSET + sizeof(struct request_sense))
+#define MAX_PACKET_DATA (PAGE_SIZE - sizeof(struct xen_cdrom_packet) - \
+            sizeof(struct vcd_generic_command) - sizeof(struct request_sense))
+
+#endif
diff -Naur xen/xen/include/public/platform.h xen-b/xen/include/public/platform.h
--- xen/xen/include/public/platform.h	2013-05-08 21:21:22.401481102 -0600
+++ xen-b/xen/include/public/platform.h	2013-05-12 06:30:26.781481103 -0600
@@ -527,6 +527,16 @@
 typedef struct xenpf_core_parking xenpf_core_parking_t;
 DEFINE_XEN_GUEST_HANDLE(xenpf_core_parking_t);
 
+#define XENPF_get_cpu_freq        ('N' << 24)
+#define XENPF_get_cpu_freq_min    (XENPF_get_cpu_freq + 1)
+#define XENPF_get_cpu_freq_max    (XENPF_get_cpu_freq_min + 1)
+struct xenpf_get_cpu_freq {
+    /* IN variables */
+    uint32_t vcpu;
+    /* OUT variables */
+    uint32_t freq; /* in kHz */
+};
+
 /*
  * ` enum neg_errnoval
  * ` HYPERVISOR_platform_op(const struct xen_platform_op*);
@@ -553,6 +563,7 @@
         struct xenpf_cpu_hotadd        cpu_add;
         struct xenpf_mem_hotadd        mem_add;
         struct xenpf_core_parking      core_parking;
+        struct xenpf_get_cpu_freq      get_cpu_freq;
         uint8_t                        pad[128];
     } u;
 };
